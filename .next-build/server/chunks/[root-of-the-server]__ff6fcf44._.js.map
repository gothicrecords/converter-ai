{"version":3,"sources":["../../../lib/openai.js","../../../lib/documentAI.js","../../../pages/api/chat/message.js","../../../node_modules/next/src/build/templates/pages-api.ts"],"sourcesContent":["// OpenAI API integration with official SDK\r\nimport OpenAI from 'openai';\r\n\r\nconst openai = new OpenAI({\r\n  apiKey: process.env.OPENAI_API_KEY,\r\n});\r\n\r\n// Generate embeddings for text\r\nexport async function generateEmbedding(text) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const response = await openai.embeddings.create({\r\n      model: 'text-embedding-3-small',\r\n      input: text.substring(0, 8000), // Limit input size\r\n    });\r\n\r\n    return response.data[0].embedding;\r\n  } catch (error) {\r\n    console.error('Error generating embedding:', error);\r\n    throw new Error(`Failed to generate embedding: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Generate embeddings in batch for an array of texts\r\nexport async function generateEmbeddingsBatch(texts) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  if (!Array.isArray(texts) || texts.length === 0) return [];\r\n\r\n  try {\r\n    const response = await openai.embeddings.create({\r\n      model: 'text-embedding-3-small',\r\n      input: texts.map(t => (t || '').toString().substring(0, 8000)),\r\n    });\r\n\r\n    return response.data.map(d => d.embedding);\r\n  } catch (error) {\r\n    console.error('Error generating batch embeddings:', error);\r\n    throw new Error(`Failed to generate batch embeddings: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Chat completion using OpenAI GPT models\r\nexport async function chatCompletion(messages, options = {}) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const response = await openai.chat.completions.create({\r\n      model: options.model || 'gpt-4o-mini', // Fast and affordable\r\n      messages: messages,\r\n      temperature: options.temperature || 0.7,\r\n      max_tokens: options.max_tokens || 1000,\r\n      top_p: options.top_p || 1,\r\n      frequency_penalty: options.frequency_penalty || 0,\r\n      presence_penalty: options.presence_penalty || 0,\r\n    });\r\n\r\n    return response.choices[0].message.content;\r\n  } catch (error) {\r\n    console.error('Error in chat completion:', error);\r\n    \r\n    // Handle specific OpenAI errors\r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 500) {\r\n      throw new Error('Errore del server OpenAI. Riprova più tardi.');\r\n    }\r\n    \r\n    throw new Error(`Errore nella comunicazione con OpenAI: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Generate summary\r\nexport async function generateSummary(text, maxLength = 200) {\r\n  const messages = [\r\n    {\r\n      role: 'system',\r\n      content: 'You are a helpful assistant that creates concise summaries.',\r\n    },\r\n    {\r\n      role: 'user',\r\n      content: `Summarize the following text in ${maxLength} words or less:\\n\\n${text}`,\r\n    },\r\n  ];\r\n\r\n  return await chatCompletion(messages, { temperature: 0.5, max_tokens: 300 });\r\n}\r\n\r\n// Generate tags\r\nexport async function generateTags(text, count = 5) {\r\n  const messages = [\r\n    {\r\n      role: 'system',\r\n      content: 'You are a helpful assistant that generates relevant tags for documents. Return only comma-separated tags, no explanations.',\r\n    },\r\n    {\r\n      role: 'user',\r\n      content: `Generate ${count} relevant tags for this document:\\n\\n${text.substring(0, 2000)}`,\r\n    },\r\n  ];\r\n\r\n  const response = await chatCompletion(messages, { temperature: 0.3, max_tokens: 100 });\r\n  \r\n  return response\r\n    .split(',')\r\n    .map(tag => tag.trim().toLowerCase())\r\n    .filter(tag => tag.length > 0)\r\n    .slice(0, count);\r\n}\r\n\r\n// Classify document\r\nexport async function classifyDocument(text) {\r\n  const categories = [\r\n    'contract', 'invoice', 'report', 'presentation', \r\n    'spreadsheet', 'image', 'code', 'email', 'article', 'other'\r\n  ];\r\n\r\n  const messages = [\r\n    {\r\n      role: 'system',\r\n      content: `You are a document classifier. Classify the document into one or more of these categories: ${categories.join(', ')}. Return only category names, comma-separated.`,\r\n    },\r\n    {\r\n      role: 'user',\r\n      content: `Classify this document:\\n\\n${text.substring(0, 1000)}`,\r\n    },\r\n  ];\r\n\r\n  const response = await chatCompletion(messages, { temperature: 0.2, max_tokens: 50 });\r\n  \r\n  return response\r\n    .split(',')\r\n    .map(cat => cat.trim().toLowerCase())\r\n    .filter(cat => categories.includes(cat));\r\n}\r\n\r\n// Vision API - Analizza immagini come ChatGPT\r\nexport async function analyzeImageWithVision(imageBuffer, imageMimeType, query = 'Cosa contiene questa immagine? Descrivi tutto ciò che vedi.') {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    // Converti il buffer in base64\r\n    const base64Image = imageBuffer.toString('base64');\r\n    \r\n    const response = await openai.chat.completions.create({\r\n      model: 'gpt-4o', // GPT-4o supporta vision\r\n      messages: [\r\n        {\r\n          role: 'system',\r\n          content: 'Sei un assistente AI esperto nell\\'analisi di immagini. Descrivi in dettaglio tutto ciò che vedi nell\\'immagine, inclusi testo, oggetti, persone, scene, colori e qualsiasi altro dettaglio rilevante. Rispondi sempre in italiano.'\r\n        },\r\n        {\r\n          role: 'user',\r\n          content: [\r\n            {\r\n              type: 'text',\r\n              text: query\r\n            },\r\n            {\r\n              type: 'image_url',\r\n              image_url: {\r\n                url: `data:${imageMimeType};base64,${base64Image}`,\r\n                detail: 'high'\r\n              }\r\n            }\r\n          ]\r\n        }\r\n      ],\r\n      max_tokens: 2000,\r\n      temperature: 0.2\r\n    });\r\n\r\n    return response.choices[0].message.content;\r\n  } catch (error) {\r\n    console.error('Error in vision API:', error);\r\n    \r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 400 && error.message?.includes('image')) {\r\n      throw new Error('Formato immagine non supportato o immagine troppo grande.');\r\n    }\r\n    \r\n    throw new Error(`Errore nell'analisi dell'immagine: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Estrazione testo da PDF con OpenAI Responses API (gpt-4o) usando input_file\r\n// Ritorna SOLO la stringa di testo estratto (no IDs, no oggetti)\r\nexport async function extractTextFromPdfWithOpenAI(filePath) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  const fs = await import('fs');\r\n  \r\n  let uploadedFile = null;\r\n  try {\r\n    console.log('Caricamento PDF su OpenAI (Responses API):', filePath);\r\n    \r\n    // 1) Carica il file su OpenAI come user_data\r\n    uploadedFile = await openai.files.create({\r\n      file: fs.createReadStream(filePath),\r\n      purpose: 'user_data'\r\n    });\r\n\r\n    console.log('File caricato su OpenAI:', uploadedFile.id);\r\n\r\n    // 2) Richiesta al modello GPT-4o per estrazione testo dal file caricato\r\n    const response = await openai.responses.create({\r\n      model: 'gpt-4o',\r\n      input: [\r\n        {\r\n          role: 'user',\r\n          content: [\r\n            { type: 'input_text', text: 'Estrai tutto il testo e le informazioni rilevanti da questo documento. Rispondi SOLO con il testo estratto, senza commenti.' },\r\n            { type: 'input_file', file_id: uploadedFile.id }\r\n          ]\r\n        }\r\n      ],\r\n      max_output_tokens: 8000,\r\n      temperature: 0.1\r\n    });\r\n\r\n    // 3) Prendi solo testo\r\n    const extractedText = (response.output_text || '').toString().trim();\r\n    console.log(`Testo estratto da PDF: ${extractedText.length} caratteri`);\r\n    \r\n    if (!extractedText) {\r\n      throw new Error('Nessun testo estratto dal PDF');\r\n    }\r\n\r\n    return extractedText;\r\n\r\n  } catch (error) {\r\n    console.error('Error in PDF text extraction (Responses API):', error);\r\n    \r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 400) {\r\n      throw new Error('Errore nell\\'analisi del PDF con Responses API. Il file potrebbe essere troppo grande o danneggiato.');\r\n    }\r\n    \r\n    throw new Error(`Errore nell'estrazione del testo PDF: ${error.message}`);\r\n  } finally {\r\n    // 4) Prova a rimuovere il file caricato (se l'SDK lo supporta)\r\n    try {\r\n      if (uploadedFile && uploadedFile.id) {\r\n        if (openai.files?.delete) {\r\n          await openai.files.delete(uploadedFile.id);\r\n        } else if (openai.files?.del) {\r\n          await openai.files.del(uploadedFile.id);\r\n        }\r\n        console.log('File rimosso da OpenAI:', uploadedFile.id);\r\n      }\r\n    } catch (delError) {\r\n      console.warn('Errore rimozione file da OpenAI (ignorato):', delError?.message || delError);\r\n    }\r\n  }\r\n}\r\n\r\n// DALL-E 3 - Get image URL only (faster, for streaming)\r\nexport async function getImageUrlFromDALLE(prompt, options = {}) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const size = options.size || '1024x1024';\r\n    const quality = options.quality || 'standard';\r\n    const style = options.style || 'vivid';\r\n\r\n    const response = await openai.images.generate({\r\n      model: 'dall-e-3',\r\n      prompt: prompt,\r\n      size: size,\r\n      quality: quality,\r\n      style: style,\r\n      n: 1,\r\n    });\r\n\r\n    const imageUrl = response.data[0]?.url;\r\n    if (!imageUrl) {\r\n      throw new Error('Nessuna immagine generata da DALL-E');\r\n    }\r\n\r\n    return imageUrl;\r\n  } catch (error) {\r\n    console.error('Error getting image URL from DALL-E:', error);\r\n    console.error('Error details:', {\r\n      status: error.status,\r\n      statusText: error.statusText,\r\n      message: error.message,\r\n      code: error.code,\r\n      response: error.response?.data || error.response\r\n    });\r\n    \r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 400) {\r\n      const errorMessage = error.message || error.response?.data?.error?.message || 'Prompt non valido o contenuto non consentito';\r\n      throw new Error(`Errore nella generazione: ${errorMessage}`);\r\n    } else if (error.code === 'ENOTFOUND' || error.code === 'ECONNREFUSED') {\r\n      throw new Error('Errore di connessione con OpenAI. Verifica la tua connessione internet.');\r\n    }\r\n    \r\n    throw new Error(`Errore nella generazione dell'immagine: ${error.message || 'Errore sconosciuto'}`);\r\n  }\r\n}\r\n\r\n// DALL-E 3 - Generazione immagini (download completo, per backward compatibility)\r\nexport async function generateImageWithDALLE(prompt, options = {}) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const imageUrl = await getImageUrlFromDALLE(prompt, options);\r\n\r\n    // Download the image and return as buffer\r\n    const imageResponse = await fetch(imageUrl);\r\n    if (!imageResponse.ok) {\r\n      const errorText = await imageResponse.text().catch(() => 'Unknown error');\r\n      throw new Error(`Errore nel download dell'immagine generata: ${imageResponse.status} ${imageResponse.statusText}. ${errorText}`);\r\n    }\r\n\r\n    const arrayBuffer = await imageResponse.arrayBuffer();\r\n    return Buffer.from(arrayBuffer);\r\n  } catch (error) {\r\n    // Re-throw errors from getImageUrlFromDALLE\r\n    throw error;\r\n  }\r\n}\r\n\r\n// DALL-E 3 - Upscale/Miglioramento immagine usando variante\r\nexport async function upscaleImageWithDALLE(imageBuffer, imageMimeType, enhancementPrompt = null) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    // 1. Analizza l'immagine con Vision API per creare un prompt descrittivo\r\n    const analysisPrompt = enhancementPrompt || 'Descrivi in dettaglio questa immagine, includendo tutti i dettagli visivi, colori, composizione, stile e qualità. La descrizione sarà usata per creare una versione migliorata ad alta risoluzione.';\r\n    \r\n    const imageDescription = await analyzeImageWithVision(\r\n      imageBuffer, \r\n      imageMimeType, \r\n      analysisPrompt\r\n    );\r\n\r\n    // 2. Crea un prompt per DALL-E che migliora l'immagine\r\n    const enhancementPromptText = `Crea una versione migliorata e ad alta risoluzione di questa immagine: ${imageDescription}. Mantieni fedeltà ai dettagli originali ma migliora la qualità, la nitidezza e la risoluzione.`;\r\n\r\n    // 3. Genera immagine migliorata con DALL-E 3 in alta risoluzione\r\n    const enhancedImageBuffer = await generateImageWithDALLE(enhancementPromptText, {\r\n      size: '1792x1024', // Formato landscape per alta risoluzione\r\n      quality: 'hd',\r\n      style: 'natural'\r\n    });\r\n\r\n    return enhancedImageBuffer;\r\n  } catch (error) {\r\n    console.error('Error upscaling image with DALL-E:', error);\r\n    throw new Error(`Errore nel miglioramento dell'immagine: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Enhance existing image quality using AI analysis + sharp processing\r\nexport async function enhanceImageQualityWithAI(imageBuffer, imageMimeType) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    // Use Vision API to analyze image quality issues\r\n    const analysisPrompt = `Analyze this image and identify specific quality issues that need improvement. Focus on:\r\n1. Noise level (low/medium/high)\r\n2. Sharpness (blurry/sharp)\r\n3. Color accuracy (washed out/vibrant)\r\n4. Artifacts (compression artifacts, pixelation)\r\n5. Overall quality issues\r\n\r\nRespond with a JSON object: {\"noise\": \"low|medium|high\", \"sharpness\": \"blurry|moderate|sharp\", \"color\": \"washed|normal|vibrant\", \"artifacts\": \"none|minor|major\", \"recommendations\": \"brief description\"}`;\r\n    \r\n    const analysisResult = await analyzeImageWithVision(\r\n      imageBuffer, \r\n      imageMimeType, \r\n      analysisPrompt\r\n    );\r\n\r\n    // Parse analysis result\r\n    let analysis = {\r\n      noise: 'medium',\r\n      sharpness: 'moderate',\r\n      color: 'normal',\r\n      artifacts: 'none'\r\n    };\r\n\r\n    try {\r\n      // Try to parse JSON from analysis\r\n      const jsonMatch = analysisResult.match(/\\{[\\s\\S]*\\}/);\r\n      if (jsonMatch) {\r\n        const parsed = JSON.parse(jsonMatch[0]);\r\n        analysis = { ...analysis, ...parsed };\r\n      }\r\n    } catch (parseError) {\r\n      console.warn('Could not parse AI analysis, using defaults');\r\n    }\r\n\r\n    // Apply targeted enhancements using sharp based on AI analysis\r\n    const sharp = (await import('sharp')).default;\r\n    let enhanced = sharp(imageBuffer, { sequentialRead: true });\r\n\r\n    // Apply denoising if needed\r\n    if (analysis.noise === 'high' || analysis.noise === 'medium') {\r\n      enhanced = enhanced.median(analysis.noise === 'high' ? 3 : 2);\r\n    }\r\n\r\n    // Apply sharpening based on analysis\r\n    if (analysis.sharpness === 'blurry') {\r\n      enhanced = enhanced.sharpen({\r\n        sigma: 2.0,\r\n        m1: 1.0,\r\n        m2: 0.5,\r\n        x1: 3,\r\n        y2: 3,\r\n        y3: 3\r\n      });\r\n    } else if (analysis.sharpness === 'moderate') {\r\n      enhanced = enhanced.sharpen({\r\n        sigma: 1.0,\r\n        m1: 0.7,\r\n        m2: 0.4\r\n      });\r\n    }\r\n\r\n    // Enhance color if needed\r\n    if (analysis.color === 'washed') {\r\n      enhanced = enhanced.modulate({\r\n        saturation: 1.15,\r\n        brightness: 1.05\r\n      }).linear(1.05, -(128 * 0.05)); // Slight contrast boost\r\n    }\r\n\r\n    // Remove compression artifacts\r\n    if (analysis.artifacts === 'major' || analysis.artifacts === 'minor') {\r\n      enhanced = enhanced.png({\r\n        quality: 100,\r\n        compressionLevel: 6,\r\n        adaptiveFiltering: true\r\n      });\r\n    } else {\r\n      // Keep original format but with high quality\r\n      if (imageMimeType === 'image/jpeg' || imageMimeType === 'image/jpg') {\r\n        enhanced = enhanced.jpeg({\r\n          quality: 98,\r\n          mozjpeg: true,\r\n          trellisQuantisation: true,\r\n          overshootDeringing: true\r\n        });\r\n      } else {\r\n        enhanced = enhanced.png({\r\n          quality: 100,\r\n          compressionLevel: 6\r\n        });\r\n      }\r\n    }\r\n\r\n    const enhancedBuffer = await enhanced.toBuffer();\r\n    return enhancedBuffer;\r\n  } catch (error) {\r\n    console.error('Error enhancing image quality with AI:', error);\r\n    // Return original buffer if enhancement fails\r\n    return imageBuffer;\r\n  }\r\n}\r\n","// Sistema AI completo per analisi documenti con OpenAI GPT-4\r\nimport mammoth from 'mammoth';\r\nimport * as XLSX from 'xlsx';\r\nimport { chatCompletion } from './openai.js';\r\n\r\n// pdf-parse ha problemi ESM/CJS con Turbopack, usiamo solo pdfjs-dist\r\n\r\n// Storage in-memory per i documenti caricati (in produzione si può usare database)\r\nconst documentStore = new Map(); // { fileId: { text, chunks, metadata } }\r\n\r\n/**\r\n * Estrae testo da un documento\r\n * @param {Buffer} buffer - Buffer del file\r\n * @param {string} mimeType - Tipo MIME del file\r\n * @param {string} filename - Nome del file\r\n * @param {string} [filepath] - Percorso opzionale del file (utile per OCR)\r\n */\r\nexport async function extractTextFromDocument(buffer, mimeType, filename, filepath = null) {\r\n  try {\r\n    let text = '';\r\n    let metadata = {\r\n      filename,\r\n      mimeType,\r\n      pages: 0,\r\n      wordCount: 0,\r\n    };\r\n\r\n    if (mimeType === 'application/pdf' || filename.toLowerCase().endsWith('.pdf')) {\r\n      // PDF: usa OpenAI file upload + GPT extraction (tutto lato server OpenAI)\r\n      const { extractTextFromPdfWithOpenAI } = await import('./openai.js');\r\n      console.log(`Analizzando PDF con OpenAI file upload: ${filename}`);\r\n      \r\n      // Salva temporaneamente il file per l'upload\r\n      const fs = await import('fs');\r\n      const path = await import('path');\r\n      const os = await import('os');\r\n      \r\n      const tempDir = os.tmpdir();\r\n      const tempFilePath = path.join(tempDir, `temp_${Date.now()}_${filename}`);\r\n      \r\n      try {\r\n        // Scrivi il buffer su file temporaneo\r\n        fs.writeFileSync(tempFilePath, buffer);\r\n        \r\n        // Estrai testo con OpenAI (file upload -> GPT risponde con SOLO testo)\r\n        text = await extractTextFromPdfWithOpenAI(tempFilePath);\r\n        \r\n        // Assicurati che sia una stringa pulita\r\n        text = (text || \"\").toString().trim();\r\n        metadata.analysisMethod = 'openai-file-upload';\r\n        \r\n        if (!text || text.length === 0) {\r\n          throw new Error('Nessun testo estratto dal PDF tramite OpenAI');\r\n        }\r\n        \r\n        console.log(`PDF analizzato con OpenAI: ${text.length} caratteri estratti`);\r\n      } finally {\r\n        // Pulisci file temporaneo\r\n        try {\r\n          if (fs.existsSync(tempFilePath)) {\r\n            fs.unlinkSync(tempFilePath);\r\n          }\r\n        } catch (cleanupError) {\r\n          console.warn('Errore pulizia file temporaneo:', cleanupError);\r\n        }\r\n      }\r\n    }\r\n    else if (mimeType.includes('wordprocessingml') || filename.toLowerCase().endsWith('.docx')) {\r\n      const result = await mammoth.extractRawText({ buffer });\r\n      text = result.value;\r\n      \r\n      // Pulisci il testo\r\n      text = text.replace(/\\s+/g, ' ').trim();\r\n    }\r\n    else if (mimeType.includes('spreadsheet') || filename.toLowerCase().match(/\\.(xlsx|xls|csv)$/i)) {\r\n      const workbook = XLSX.read(buffer, { type: 'buffer' });\r\n      const sheets = workbook.SheetNames;\r\n      \r\n      // Estrai testo da tutte le celle\r\n      const allText = [];\r\n      for (const sheetName of sheets) {\r\n        const sheet = workbook.Sheets[sheetName];\r\n        const sheetData = XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' });\r\n        \r\n        for (const row of sheetData) {\r\n          if (Array.isArray(row)) {\r\n            const rowText = row.filter(cell => cell && cell.toString().trim()).join(' ');\r\n            if (rowText.trim()) {\r\n              allText.push(`[${sheetName}] ${rowText}`);\r\n            }\r\n          }\r\n        }\r\n      }\r\n      \r\n      text = allText.join('\\n');\r\n    }\r\n    else if (mimeType.startsWith('text/') || filename.toLowerCase().endsWith('.txt')) {\r\n      text = buffer.toString('utf-8');\r\n    }\r\n    else if (mimeType.startsWith('image/') || filename.toLowerCase().match(/\\.(png|jpg|jpeg|gif|webp|bmp|tif|tiff|heic|heif)$/i)) {\r\n      // Usa OpenAI Vision API come ChatGPT (più intelligente) + OCR come fallback\r\n      try {\r\n        const { analyzeImageWithVision } = await import('./openai.js');\r\n        console.log(`Analizzando immagine con OpenAI Vision API: ${filename}`);\r\n        \r\n        try {\r\n          // Prova prima con OpenAI Vision API (come ChatGPT)\r\n          const visionText = await analyzeImageWithVision(\r\n            buffer, \r\n            mimeType,\r\n            'Analizza questa immagine in dettaglio. Descrivi tutto ciò che vedi, incluso qualsiasi testo presente, oggetti, persone, scene, colori e dettagli rilevanti. Se c\\'è del testo, trascrivilo accuratamente.'\r\n          );\r\n          \r\n          text = visionText;\r\n          console.log(`Vision API completato: ${text.length} caratteri estratti`);\r\n          \r\n          // Aggiungi metadata per indicare che è stato usato Vision API\r\n          metadata.analysisMethod = 'openai-vision';\r\n        } catch (visionError) {\r\n          console.log('Vision API fallito, provo con OCR:', visionError.message);\r\n          \r\n          // Fallback a OCR tradizionale\r\n          const Tesseract = (await import('tesseract.js')).default;\r\n          const imageSource = filepath || buffer;\r\n          \r\n          try {\r\n            const result = await Tesseract.recognize(imageSource, 'ita+eng', {\r\n              logger: (m) => {\r\n                if (m.status === 'recognizing text') {\r\n                  console.log(`OCR Progress: ${Math.round(m.progress * 100)}%`);\r\n                }\r\n              }\r\n            });\r\n            \r\n            text = result.data.text.trim();\r\n            metadata.analysisMethod = 'ocr-tesseract';\r\n          } catch (ocrError) {\r\n            // Se anche OCR fallisce, prova con createWorker\r\n            console.log('OCR semplice fallito, provo con createWorker:', ocrError.message);\r\n            \r\n            const worker = await Tesseract.createWorker('ita+eng', 1, {\r\n              logger: (m) => {\r\n                if (m.status === 'recognizing text') {\r\n                  console.log(`OCR Progress: ${Math.round(m.progress * 100)}%`);\r\n                }\r\n              }\r\n            });\r\n            \r\n            try {\r\n              const result = await worker.recognize(imageSource);\r\n              text = result.data.text.trim();\r\n              metadata.analysisMethod = 'ocr-tesseract-worker';\r\n            } finally {\r\n              await worker.terminate();\r\n            }\r\n          }\r\n        }\r\n        \r\n        if (!text || text.length === 0) {\r\n          throw new Error('Nessun contenuto estratto dall\\'immagine. L\\'immagine potrebbe essere vuota o non contenere testo leggibile.');\r\n        }\r\n        \r\n        console.log(`Analisi immagine completata: ${text.length} caratteri estratti (metodo: ${metadata.analysisMethod || 'unknown'})`);\r\n      } catch (imageError) {\r\n        console.error('Errore analisi immagine completo:', imageError);\r\n        throw new Error(`Errore nell'analisi dell'immagine: ${imageError.message}`);\r\n      }\r\n    }\r\n    else {\r\n      throw new Error(`Tipo di file non supportato: ${mimeType}`);\r\n    }\r\n\r\n    if (!text || text.trim().length === 0) {\r\n      throw new Error('Nessun testo estratto dal documento');\r\n    }\r\n\r\n    metadata.wordCount = text.split(/\\s+/).length;\r\n\r\n    return { text, metadata };\r\n  } catch (error) {\r\n    console.error('Errore estrazione testo:', error);\r\n    throw new Error(`Errore nell'estrazione del testo: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Divide il testo in chunk intelligenti per la ricerca semantica\r\n * Genera anche embeddings per ogni chunk (ricerca semantica vera)\r\n */\r\nexport async function createTextChunks(text, chunkSize = 1000, overlap = 200) {\r\n  const sentences = text.split(/[.!?]+\\s+/).filter(s => s.trim().length > 10);\r\n  const chunks = [];\r\n  \r\n  let currentChunk = '';\r\n  let currentLength = 0;\r\n\r\n  for (const sentence of sentences) {\r\n    const sentenceLength = sentence.length;\r\n    \r\n    if (currentLength + sentenceLength > chunkSize && currentChunk.trim()) {\r\n      // Salva il chunk corrente\r\n      chunks.push({\r\n        text: currentChunk.trim(),\r\n        startIndex: text.indexOf(currentChunk.trim()),\r\n        endIndex: text.indexOf(currentChunk.trim()) + currentChunk.length,\r\n      });\r\n\r\n      // Crea nuovo chunk con overlap (ultime parole del chunk precedente)\r\n      const words = currentChunk.split(/\\s+/);\r\n      const overlapWords = words.slice(-Math.floor(overlap / 10));\r\n      currentChunk = overlapWords.join(' ') + ' ' + sentence + ' ';\r\n      currentLength = currentChunk.length;\r\n    } else {\r\n      currentChunk += sentence + '. ';\r\n      currentLength += sentenceLength + 2;\r\n    }\r\n  }\r\n\r\n  // Aggiungi l'ultimo chunk\r\n  if (currentChunk.trim()) {\r\n    chunks.push({\r\n      text: currentChunk.trim(),\r\n      startIndex: text.indexOf(currentChunk.trim()),\r\n      endIndex: text.length,\r\n    });\r\n  }\r\n\r\n  const finalChunks = chunks.length > 0 ? chunks : [{ text: text.trim(), startIndex: 0, endIndex: text.length }];\r\n  \r\n  // Genera embeddings per i chunk in batch per ridurre latenza\r\n  const { generateEmbeddingsBatch } = await import('./openai.js');\r\n\r\n  try {\r\n    // Processa in lotti per evitare payload troppo grandi\r\n    const BATCH_SIZE = 16;\r\n    for (let i = 0; i < finalChunks.length; i += BATCH_SIZE) {\r\n      const batch = finalChunks.slice(i, i + BATCH_SIZE);\r\n      const embeddings = await generateEmbeddingsBatch(batch.map(c => c.text));\r\n      embeddings.forEach((emb, idx) => {\r\n        batch[idx].embedding = emb;\r\n      });\r\n    }\r\n  } catch (embError) {\r\n    console.warn('Batch embeddings failed, falling back to per-chunk:', embError.message);\r\n    const { generateEmbedding } = await import('./openai.js');\r\n    for (const chunk of finalChunks) {\r\n      try {\r\n        chunk.embedding = await generateEmbedding(chunk.text);\r\n      } catch (err) {\r\n        console.warn('Errore generazione embedding per chunk:', err.message);\r\n        chunk.embedding = null;\r\n      }\r\n    }\r\n  }\r\n  \r\n  return finalChunks;\r\n}\r\n\r\n/**\r\n * Calcola cosine similarity tra due vettori di embedding\r\n */\r\nfunction cosineSimilarity(vecA, vecB) {\r\n  if (!vecA || !vecB || vecA.length !== vecB.length) return 0;\r\n  \r\n  const dot = vecA.reduce((sum, val, i) => sum + val * vecB[i], 0);\r\n  const magA = Math.sqrt(vecA.reduce((sum, val) => sum + val * val, 0));\r\n  const magB = Math.sqrt(vecB.reduce((sum, val) => sum + val * val, 0));\r\n  \r\n  return dot / (magA * magB);\r\n}\r\n\r\n/**\r\n * Calcola TF-IDF per ricerca semantica semplice (fallback se embedding non disponibile)\r\n */\r\nfunction calculateTFIDF(text, query) {\r\n  const textWords = text.toLowerCase().split(/\\W+/).filter(w => w.length > 2);\r\n  const queryWords = query.toLowerCase().split(/\\W+/).filter(w => w.length > 2);\r\n  \r\n  if (queryWords.length === 0) return 0;\r\n\r\n  let score = 0;\r\n  const textWordCount = {};\r\n  textWords.forEach(word => {\r\n    textWordCount[word] = (textWordCount[word] || 0) + 1;\r\n  });\r\n\r\n  queryWords.forEach(queryWord => {\r\n    const wordCount = textWordCount[queryWord] || 0;\r\n    if (wordCount > 0) {\r\n      // TF: frequenza del termine nel documento\r\n      const tf = wordCount / textWords.length;\r\n      // IDF: inversa della frequenza (più raro = più importante)\r\n      const idf = Math.log(textWords.length / (wordCount + 1)) + 1;\r\n      score += tf * idf;\r\n    }\r\n  });\r\n\r\n  return score / queryWords.length;\r\n}\r\n\r\n/**\r\n * Ricerca semantica nel documento usando embeddings (cosine similarity)\r\n * Fallback a TF-IDF se embeddings non disponibili\r\n */\r\nexport async function semanticSearch(documentText, chunks, query, topK = 5) {\r\n  if (!chunks || chunks.length === 0) {\r\n    return [];\r\n  }\r\n\r\n  // Genera embedding per la query\r\n  const { generateEmbedding } = await import('./openai.js');\r\n  let queryEmbedding = null;\r\n  \r\n  try {\r\n    queryEmbedding = await generateEmbedding(query);\r\n  } catch (embError) {\r\n    console.warn('Errore generazione embedding query, uso TF-IDF:', embError);\r\n  }\r\n\r\n  // Calcola score per ogni chunk\r\n  const scoredChunks = chunks.map((chunk, index) => {\r\n    let semanticScore = 0;\r\n    \r\n    // Usa cosine similarity se embeddings disponibili\r\n    if (queryEmbedding && chunk.embedding) {\r\n      semanticScore = cosineSimilarity(queryEmbedding, chunk.embedding);\r\n    } else {\r\n      // Fallback a TF-IDF\r\n      semanticScore = calculateTFIDF(chunk.text, query) / 10; // Normalizza per essere simile a cosine\r\n    }\r\n    \r\n    // Bonus per match esatti\r\n    const lowerChunk = chunk.text.toLowerCase();\r\n    const lowerQuery = query.toLowerCase();\r\n    let exactMatchBonus = 0;\r\n    if (lowerChunk.includes(lowerQuery)) {\r\n      exactMatchBonus = 0.1;\r\n    }\r\n    \r\n    // Bonus per parole chiave comuni\r\n    const queryWords = query.toLowerCase().split(/\\W+/).filter(w => w.length > 2);\r\n    const matchingWords = queryWords.filter(word => lowerChunk.includes(word)).length;\r\n    const keywordBonus = (matchingWords / queryWords.length) * 0.05;\r\n\r\n    const totalScore = semanticScore + exactMatchBonus + keywordBonus;\r\n\r\n    return {\r\n      ...chunk,\r\n      score: totalScore,\r\n      index,\r\n    };\r\n  });\r\n\r\n  // Ordina per score e ritorna i top K (anche con score bassi)\r\n  const sortedChunks = scoredChunks\r\n    .sort((a, b) => b.score - a.score)\r\n    .slice(0, topK);\r\n  \r\n  console.log('Top chunk scores:', sortedChunks.map(c => c.score.toFixed(4)));\r\n  \r\n  // Ritorna anche risultati con score bassi (meglio di niente)\r\n  return sortedChunks.filter(chunk => chunk.score >= 0);\r\n}\r\n\r\n/**\r\n * Genera risposta intelligente basata sul contenuto del documento usando OpenAI GPT-4\r\n * @param {string} query - Domanda dell'utente\r\n * @param {Array} relevantChunks - Chunk rilevanti dal documento\r\n * @param {string} documentText - Testo completo del documento\r\n * @param {string} conversationContext - Contesto della conversazione (opzionale)\r\n */\r\nexport async function generateAnswer(query, relevantChunks, documentText, conversationContext = '', documentMetadata = {}) {\r\n  if (!relevantChunks || relevantChunks.length === 0) {\r\n    return {\r\n      answer: \"Non ho trovato informazioni rilevanti nel documento per rispondere alla tua domanda. Prova a formulare la domanda in modo diverso o carica un documento più pertinente.\",\r\n      confidence: 0,\r\n      sources: [],\r\n    };\r\n  }\r\n\r\n  // Combina i chunk più rilevanti - SOLO TESTO (no oggetti, no IDs)\r\n  const combinedContext = relevantChunks\r\n    .map((chunk, idx) => `[Sezione ${idx + 1}]\\n${chunk.text}`)\r\n    .join('\\n\\n---\\n\\n');\r\n\r\n  // Usa OpenAI GPT-4 per generare una risposta intelligente\r\n  const confidence = Math.min(relevantChunks[0].score * 10, 1.0);\r\n  \r\n  try {\r\n    // Costruisci il prompt con contesto della conversazione se disponibile\r\n    let contextSection = '';\r\n    if (conversationContext && conversationContext.trim()) {\r\n      contextSection = `\\n\\n**CONTESTO DELLA CONVERSAZIONE PRECEDENTE:**\r\n${conversationContext}\r\n\r\nUsa questo contesto per capire meglio la domanda e fornire una risposta coerente con la conversazione.`;\r\n    }\r\n\r\n    const messages = [\r\n      {\r\n        role: 'system',\r\n        content: `Sei un assistente AI esperto nell'analisi di documenti. Segui un ragionamento interno SILENTE (non mostrarlo) con i passi: 1) Identifica concetti chiave 2) Seleziona parti rilevanti 3) Sintetizza relazioni 4) Verifica contraddizioni o assenze 5) Struttura risposta finale. Poi produci SOLO l'output formattato.\r\n\r\nOBIETTIVI:\r\n1. Analisi accurata delle sezioni fornite\r\n2. Risposta logica e coerente basata esclusivamente sul contenuto\r\n3. Struttura chiara e professionale in italiano\r\n4. Citazione delle fonti/Sezioni rilevanti\r\n5. Nessuna invenzione: se manca l'informazione, dichiaralo e suggerisci cosa servirebbe\r\n\r\nFORMATTA LA RISPOSTA CON LE SEZIONI (usa markdown semplice):\r\n**Risposta**: sintesi principale diretta alla domanda.\r\n**Dettagli**: approfondisci punti chiave organizzati.\r\n**Fonti**: elenco puntato con sezione e breve estratto.\r\n**Limiti**: cosa non è presente o ambiguo.\r\n**Suggerimenti**: eventuali passi successivi o chiarimenti da richiedere.\r\n\r\nRegole:\r\n- Non includere il ragionamento interno.\r\n- Non scusarti a meno che il contenuto sia realmente assente.\r\n- Mantieni tono professionale, conciso ma completo.`\r\n      },\r\n      {\r\n        role: 'user',\r\n        content: `Analizza il seguente contenuto estratto dal documento e rispondi alla domanda dell'utente in modo completo e accurato.\r\n\r\n**CONTENUTO DEL DOCUMENTO:**\r\n${combinedContext}${contextSection}\r\n\r\n**DOMANDA DELL'UTENTE:**\r\n${query}\r\n\r\n**ISTRUZIONI:**\r\n- Rispondi basandoti SOLO sul contenuto fornito sopra\r\n- Se la risposta richiede informazioni non presenti, dillo chiaramente\r\n- Cita o fai riferimento alle sezioni rilevanti quando possibile\r\n- Fornisci una risposta completa e ben strutturata\r\n- Considera il contesto della conversazione se fornito per una risposta più pertinente`\r\n      }\r\n    ];\r\n    \r\n    let answer = await chatCompletion(messages, {\r\n      model: 'gpt-4o-mini', // Modello veloce e economico\r\n      temperature: 0.2, // Bassa temperatura per risposte più accurate e consistenti\r\n      max_tokens: 1200, // Aumentato per risposte più complete\r\n      top_p: 0.9,\r\n      frequency_penalty: 0.1, // Riduce ripetizioni\r\n      presence_penalty: 0.1 // Incentiva varietà\r\n    });\r\n    answer = answer.trim();\r\n    // Post-processing: se il modello ha prodotto solo una frase debole/apologetica, arricchisci con estratti\r\n    const isWeak = /mi dispiace|non posso/i.test(answer) && answer.length < 120;\r\n    if (isWeak) {\r\n      const enriched = `**Risposta**: Informazioni limitate nel testo fornito.\r\n**Dettagli**:\\n${relevantChunks.slice(0,3).map(c=>'- '+c.text.substring(0,200).replace(/\\n+/g,' ')+ (c.text.length>200?'...':'' )).join('\\n')}\\n**Fonti**:\\n${relevantChunks.map((c,i)=>`- Sezione ${i+1} (score ${c.score.toFixed(3)})`).join('\\n')}\\n**Limiti**: Il documento sembra contenere testo estremamente breve o generico.\\n**Suggerimenti**: Carica un documento più esteso oppure specifica meglio la domanda.`;\r\n      answer = enriched;\r\n    }\r\n    return {\r\n      answer,\r\n      confidence,\r\n      sources: relevantChunks.map(c => ({\r\n        filename: documentMetadata?.originalFilename || documentMetadata?.filename || 'Documento',\r\n        text: c.text.substring(0, 150) + '...',\r\n        score: c.score.toFixed(3),\r\n      })),\r\n    };\r\n  } catch (error) {\r\n    console.error('Errore nella generazione della risposta con OpenAI:', error);\r\n    // Fallback a risposta semplice se OpenAI fallisce\r\n    const contextText = relevantChunks[0].text;\r\n    return {\r\n      answer: `Basandomi sul documento:\\n\\n${contextText}\\n\\n${relevantChunks.length > 1 ? '\\nInformazioni aggiuntive:\\n' + relevantChunks.slice(1, 3).map((c, i) => `• ${c.text.substring(0, 200)}...`).join('\\n') : ''}`,\r\n      confidence,\r\n      sources: relevantChunks.map(c => ({\r\n        filename: documentMetadata?.originalFilename || documentMetadata?.filename || 'Documento',\r\n        text: c.text.substring(0, 150) + '...',\r\n        score: c.score.toFixed(3),\r\n      })),\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Salva documento nello storage (con embeddings per ricerca semantica)\r\n */\r\nexport async function storeDocument(fileId, text, metadata = {}) {\r\n  console.log(`storeDocument called for ${fileId}, text length: ${text.length}`);\r\n  \r\n  const chunks = await createTextChunks(text);\r\n  \r\n  console.log(`Created ${chunks.length} chunks for document ${fileId}`);\r\n  \r\n  const documentData = {\r\n    text,\r\n    chunks,\r\n    metadata: {\r\n      ...metadata,\r\n      filename: metadata.filename || metadata.originalFilename || 'Unknown',\r\n      storedAt: new Date().toISOString(),\r\n      chunkCount: chunks.length,\r\n    },\r\n  };\r\n  \r\n  documentStore.set(fileId, documentData);\r\n  \r\n  console.log(`Document ${fileId} stored. Store size now: ${documentStore.size}`);\r\n  console.log(`Store keys:`, Array.from(documentStore.keys()));\r\n\r\n  return {\r\n    fileId,\r\n    chunkCount: chunks.length,\r\n    wordCount: text.split(/\\s+/).length,\r\n  };\r\n}\r\n\r\n/**\r\n * Recupera documento dallo storage\r\n */\r\nexport function getDocument(fileId) {\r\n  return documentStore.get(fileId);\r\n}\r\n\r\n/**\r\n * Rimuovi documento dallo storage\r\n */\r\nexport function removeDocument(fileId) {\r\n  return documentStore.delete(fileId);\r\n}\r\n\r\n/**\r\n * Cerca in tutti i documenti (async per embeddings)\r\n */\r\nexport async function searchAllDocuments(query, fileIds = null) {\r\n  console.log('searchAllDocuments called with query:', query, 'fileIds:', fileIds);\r\n  console.log('documentStore size:', documentStore.size);\r\n  console.log('documentStore keys:', Array.from(documentStore.keys()));\r\n  \r\n  const documents = fileIds && fileIds.length > 0\r\n    ? fileIds.map(id => {\r\n        const data = documentStore.get(id);\r\n        console.log(`Looking for fileId ${id}:`, data ? 'found' : 'NOT FOUND');\r\n        return { id, data };\r\n      }).filter(d => d.data)\r\n    : Array.from(documentStore.entries()).map(([id, data]) => {\r\n        console.log(`Document ${id}:`, data ? 'found' : 'NOT FOUND');\r\n        return { id, data };\r\n      });\r\n\r\n  console.log(`Found ${documents.length} documents to search`);\r\n\r\n  if (documents.length === 0) {\r\n    console.log('No documents found to search in');\r\n    return [];\r\n  }\r\n\r\n  const allResults = [];\r\n\r\n  for (const { id, data } of documents) {\r\n    if (!data || !data.chunks || !data.chunks.length) {\r\n      console.log(`Document ${id} has no chunks, skipping`);\r\n      continue;\r\n    }\r\n\r\n    console.log(`Searching in document ${id} (${data.chunks.length} chunks)`);\r\n    const results = await semanticSearch(data.text, data.chunks, query, 5);\r\n    \r\n    if (results.length > 0) {\r\n      console.log(`Found ${results.length} relevant chunks in document ${id}`);\r\n      allResults.push({\r\n        fileId: id,\r\n        filename: data.metadata?.originalFilename || data.metadata?.filename || 'Unknown',\r\n        results,\r\n        topScore: results[0].score,\r\n      });\r\n    } else {\r\n      console.log(`No relevant chunks found in document ${id}`);\r\n    }\r\n  }\r\n\r\n  console.log(`Total search results: ${allResults.length}`);\r\n\r\n  // Ordina per score migliore\r\n  return allResults.sort((a, b) => b.topScore - a.topScore);\r\n}\r\n\r\n/**\r\n * Genera risposta combinando risultati da più documenti usando OpenAI\r\n * @param {string} query - Domanda dell'utente\r\n * @param {Array} searchResults - Risultati della ricerca nei documenti\r\n * @param {string} conversationContext - Contesto della conversazione (opzionale)\r\n */\r\nexport async function generateMultiDocumentAnswer(query, searchResults, conversationContext = '') {\r\n  if (!searchResults || searchResults.length === 0) {\r\n    return {\r\n      answer: \"Non ho trovato informazioni rilevanti nei documenti caricati. Prova a formulare la domanda in modo diverso o carica documenti più pertinenti.\",\r\n      confidence: 0,\r\n      sources: [],\r\n    };\r\n  }\r\n\r\n  // Prendi i chunk migliori da tutti i documenti\r\n  const topChunks = searchResults\r\n    .flatMap(fileResult => \r\n      fileResult.results.map(r => ({\r\n        ...r,\r\n        filename: fileResult.filename,\r\n        fileId: fileResult.fileId,\r\n      }))\r\n    )\r\n    .sort((a, b) => b.score - a.score)\r\n    .slice(0, 5);\r\n\r\n  if (topChunks.length === 0) {\r\n    return {\r\n      answer: \"Non ho trovato informazioni sufficienti per rispondere.\",\r\n      confidence: 0,\r\n      sources: [],\r\n    };\r\n  }\r\n\r\n  // Genera risposta combinata usando OpenAI\r\n  const primaryChunk = topChunks[0];\r\n  const document = getDocument(primaryChunk.fileId);\r\n  \r\n  if (searchResults.length === 1) {\r\n    // Un solo documento - usa generateAnswer con metadata per filename\r\n    return await generateAnswer(query, topChunks, document.text, conversationContext, document.metadata || {});\r\n  } else {\r\n    // Multiple documenti - combina informazioni da più fonti\r\n    const confidence = Math.min(primaryChunk.score * 10, 1.0);\r\n    \r\n    try {\r\n      // Combina SOLO testo dai documenti (no file IDs, no oggetti)\r\n      const combinedContext = topChunks\r\n        .map((chunk, idx) => `[Documento: \"${chunk.filename}\" - Sezione ${idx + 1}]\\n${chunk.text}`)\r\n        .join('\\n\\n---\\n\\n');\r\n      \r\n      // Costruisci il prompt con contesto della conversazione se disponibile\r\n      let contextSection = '';\r\n      if (conversationContext && conversationContext.trim()) {\r\n        contextSection = `\\n\\n**CONTESTO DELLA CONVERSAZIONE PRECEDENTE:**\r\n${conversationContext}\r\n\r\nUsa questo contesto per capire meglio la domanda e fornire una risposta coerente con la conversazione.`;\r\n      }\r\n\r\n      const messages = [\r\n        {\r\n          role: 'system',\r\n          content: `Sei un assistente AI esperto nell'analisi di documenti multipli. Usa ragionamento interno SILENTE (non mostrarlo) seguendo: 1) Mappa concetti per documento 2) Trova sovrapposizioni/contrasti 3) Sintetizza 4) Valuta completezza 5) Struttura output. Non mostrare i passi.\r\n\r\nFORMATTA OUTPUT:\r\n**Risposta** (sintesi diretta alla domanda)\r\n**Analisi** (integrazione logica tra documenti, relazioni, eventuali differenze)\r\n**Fonti** (elenco: Documento – breve estratto pertinente)\r\n**Limiti** (informazioni mancanti, contraddizioni non risolte)\r\n**Suggerimenti** (cosa potrebbe aiutare o prossimi passi)\r\n\r\nRegole:\r\n- Non inventare contenuto\r\n- Non scusarti salvo assenza totale di informazioni\r\n- Cita il nome del documento per ogni informazione specifica\r\n- Indica contraddizioni se presenti.`\r\n        },\r\n        {\r\n          role: 'user',\r\n          content: `Analizza il contenuto estratto da ${searchResults.length} documenti diversi e rispondi alla domanda dell'utente sintetizzando le informazioni rilevanti.\r\n\r\n**CONTENUTO DAI DOCUMENTI:**\r\n${combinedContext}${contextSection}\r\n\r\n**DOMANDA DELL'UTENTE:**\r\n${query}\r\n\r\n**ISTRUZIONI:**\r\n- Combina informazioni da tutti i documenti rilevanti\r\n- Cita sempre il nome del documento quando fai riferimento a informazioni specifiche\r\n- Se ci sono informazioni correlate in più documenti, integrale in modo coerente\r\n- Fornisci una risposta completa che risponda alla domanda utilizzando tutte le fonti pertinenti\r\n- Considera il contesto della conversazione se fornito per una risposta più pertinente`\r\n        }\r\n      ];\r\n      \r\n      let answer = await chatCompletion(messages, {\r\n        model: 'gpt-4o-mini',\r\n        temperature: 0.2,\r\n        max_tokens: 1500, // Aumentato per risposte multi-documento più complete\r\n        top_p: 0.9,\r\n        frequency_penalty: 0.1,\r\n        presence_penalty: 0.1\r\n      });\r\n      answer = answer.trim();\r\n      const isWeak = /mi dispiace|non posso/i.test(answer) && answer.length < 140;\r\n      if (isWeak) {\r\n        const enrichment = topChunks.slice(0,5).map((c,i)=>`- ${c.filename} [score ${c.score.toFixed(3)}]: ${c.text.substring(0,160).replace(/\\n+/g,' ')}${c.text.length>160?'...':''}`).join('\\n');\r\n        answer = `**Risposta**: Informazioni limitate ma estratte dai documenti.\r\n**Analisi**: I contenuti disponibili sono molto brevi; non emergono argomentazioni complesse.\r\n**Fonti**:\\n${enrichment}\r\n**Limiti**: Poca profondità; serve testo aggiuntivo.\r\n**Suggerimenti**: Carica versioni più complete dei documenti o specifica una domanda più dettagliata.`;\r\n      }\r\n      return {\r\n        answer,\r\n        confidence,\r\n        sources: topChunks.slice(0, 3).map(c => ({\r\n          filename: c.filename,\r\n          text: c.text.substring(0, 100) + '...',\r\n          score: c.score.toFixed(3),\r\n        })),\r\n      };\r\n    } catch (error) {\r\n      console.error('Errore nella generazione della risposta multi-documento con OpenAI:', error);\r\n      // Fallback\r\n      let answer = `Basandomi sui ${searchResults.length} documenti caricati:\\n\\n`;\r\n      answer += `**Dal documento \"${primaryChunk.filename}\":**\\n${primaryChunk.text}\\n\\n`;\r\n      \r\n      if (topChunks.length > 1) {\r\n        const otherDocs = topChunks.slice(1, 3).filter(c => c.fileId !== primaryChunk.fileId);\r\n        if (otherDocs.length > 0) {\r\n          answer += `**Informazioni correlate da altri documenti:**\\n`;\r\n          otherDocs.forEach((chunk, idx) => {\r\n            answer += `\\n[${idx + 1}] Da \"${chunk.filename}\":\\n${chunk.text.substring(0, 200)}...\\n`;\r\n          });\r\n        }\r\n      }\r\n      \r\n      const confidence = Math.min(primaryChunk.score * 10, 1.0);\r\n      \r\n      return {\r\n        answer: answer.trim(),\r\n        confidence,\r\n        sources: topChunks.slice(0, 3).map(c => ({\r\n          filename: c.filename,\r\n          text: c.text.substring(0, 100) + '...',\r\n          score: c.score.toFixed(3),\r\n        })),\r\n      };\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * Ottieni tutti i documenti con i loro ID\r\n */\r\nexport function getAllDocuments() {\r\n  return Array.from(documentStore.entries()).map(([fileId, doc]) => ({\r\n    fileId,\r\n    ...doc\r\n  }));\r\n}\r\n\r\n/**\r\n * Ottieni statistiche sui documenti caricati\r\n */\r\nexport function getDocumentStats() {\r\n  const documents = Array.from(documentStore.values());\r\n  \r\n  return {\r\n    totalDocuments: documentStore.size,\r\n    totalWords: documents.reduce((sum, doc) => sum + (doc.text.split(/\\s+/).length || 0), 0),\r\n    totalChunks: documents.reduce((sum, doc) => sum + (doc.chunks?.length || 0), 0),\r\n    documents: Array.from(documentStore.entries()).map(([fileId, doc]) => ({\r\n      fileId,\r\n      index: Array.from(documentStore.keys()).indexOf(fileId),\r\n      filename: doc.metadata?.filename || doc.metadata?.originalFilename || 'Unknown',\r\n      wordCount: doc.text.split(/\\s+/).length,\r\n      chunkCount: doc.chunks?.length || 0,\r\n      storedAt: doc.metadata?.storedAt,\r\n    })),\r\n  };\r\n}\r\n\r\n","// API chat intelligente che usa OpenAI e ricerca semantica con embeddings\r\nimport { searchAllDocuments, generateMultiDocumentAnswer, getDocumentStats } from '../../../lib/documentAI.js';\r\n\r\nexport default async function handler(req, res) {\r\n  // Handle CORS preflight\r\n  if (req.method === 'OPTIONS') {\r\n    res.setHeader('Access-Control-Allow-Origin', '*');\r\n    res.setHeader('Access-Control-Allow-Methods', 'POST, OPTIONS');\r\n    res.setHeader('Access-Control-Allow-Headers', 'Content-Type');\r\n    res.status(200).end();\r\n    return;\r\n  }\r\n\r\n  if (req.method !== 'POST') {\r\n    return res.status(405).json({ error: 'Method not allowed' });\r\n  }\r\n\r\n  try {\r\n    const { message, fileIds = [], conversationHistory = [] } = req.body;\r\n    \r\n    if (!message || !message.trim()) {\r\n      return res.status(400).json({ \r\n        error: 'Message is required',\r\n        details: 'Please provide a non-empty message'\r\n      });\r\n    }\r\n\r\n    console.log('Chat request:', { message, fileIds: fileIds?.length || 0, conversationHistory: conversationHistory.length });\r\n\r\n    // Ottieni statistiche documenti dallo store in-memory\r\n    const stats = getDocumentStats();\r\n    \r\n    console.log('=== CHAT API CALL ===');\r\n    console.log('Message:', message);\r\n    console.log('FileIds received:', fileIds);\r\n    console.log('Document stats:', JSON.stringify(stats, null, 2));\r\n    console.log('Total documents in store:', stats.totalDocuments);\r\n    \r\n    // Verifica se ci sono fileIds validi\r\n    const validFileIds = (fileIds && Array.isArray(fileIds) && fileIds.length > 0) \r\n      ? fileIds.filter(id => id && typeof id === 'string')\r\n      : null; // null = cerca in tutti i documenti\r\n    \r\n    console.log('Valid fileIds:', validFileIds);\r\n\r\n    // Se non ci sono documenti nel database\r\n    if (stats.totalDocuments === 0) {\r\n      console.log('NO DOCUMENTS FOUND - returning helpful message');\r\n      const lowerMessage = message.toLowerCase();\r\n      \r\n      // Risposte utili per quando non ci sono documenti\r\n      let helpfulResponse = '';\r\n      \r\n      if (lowerMessage.includes('come funziona') || lowerMessage.includes('how does')) {\r\n        helpfulResponse = 'Benvenuto in **Documenti AI**! 🚀\\n\\n**Come funziona:**\\n1. Carica uno o più documenti (PDF, DOCX, XLSX, TXT)\\n2. Fai domande sul contenuto\\n3. Ricevi risposte intelligenti basate sui tuoi file\\n\\n**Cosa posso fare:**\\n- Analizzare documenti e trovare informazioni specifiche\\n- Rispondere a domande sul contenuto\\n- Eseguire ricerche semantiche nei tuoi file\\n- Sintetizzare informazioni da più documenti\\n\\n**Carica un documento per iniziare!**';\r\n      } else if (lowerMessage.includes('formato') || lowerMessage.includes('format')) {\r\n        helpfulResponse = '**Formati supportati:**\\n\\n✅ PDF - Documenti PDF\\n✅ DOCX - Documenti Word\\n✅ XLSX/XLS/CSV - Fogli di calcolo Excel\\n✅ TXT - File di testo\\n\\nTutti i formati vengono analizzati completamente per permetterti di fare domande intelligenti sul contenuto.';\r\n      } else if (lowerMessage.includes('cosa puoi fare') || lowerMessage.includes('what can')) {\r\n        helpfulResponse = '**Cosa posso fare con i tuoi documenti:**\\n\\n📊 **Analisi intelligente** - Estraggo e organizzo tutto il contenuto\\n🔍 **Ricerca semantica** - Trovo informazioni anche con parole chiave diverse\\n💬 **Chat intelligente** - Rispondo a domande specifiche sul contenuto\\n📝 **Sintesi** - Riassumo informazioni da più documenti\\n🔗 **Citazioni** - Mostro esattamente da dove provengono le risposte\\n\\n**Carica un documento e prova!**';\r\n      } else if (lowerMessage.includes('ciao') || lowerMessage.includes('hello') || lowerMessage.includes('hi')) {\r\n        helpfulResponse = 'Ciao! 👋\\n\\nSono il tuo assistente AI per l\\'analisi documenti. Posso aiutarti a:\\n- Analizzare documenti PDF, DOCX, Excel e file di testo\\n- Trovare informazioni specifiche nel contenuto\\n- Rispondere a domande sui tuoi file\\n- Eseguire ricerche semantiche intelligenti\\n\\n**Carica un documento per iniziare!** Usa il pulsante + per caricare i tuoi file.';\r\n      } else {\r\n        helpfulResponse = `Ho ricevuto il tuo messaggio: \"${message}\"\\n\\n**Per rispondere alle tue domande sui documenti:**\\n1. Carica uno o più documenti usando il pulsante + in basso\\n2. Fai domande sul contenuto\\n3. Ricevi risposte precise basate sui tuoi file\\n\\n**Formati supportati:** PDF, DOCX, XLSX, TXT\\n**Tutto completamente gratuito e illimitato!**`;\r\n      }\r\n\r\n      return res.status(200).json({\r\n        success: true,\r\n        message: helpfulResponse,\r\n        timestamp: new Date().toISOString(),\r\n        noDocuments: true,\r\n        stats,\r\n      });\r\n    }\r\n\r\n    // Ricerca semantica con embeddings nello store in-memory\r\n    console.log('Eseguendo ricerca semantica con embeddings...');\r\n    const searchResults = await searchAllDocuments(message, validFileIds);\r\n    \r\n    console.log('Search results:', searchResults.length, 'documents found');\r\n    if (searchResults.length > 0) {\r\n      console.log('Top result:', {\r\n        filename: searchResults[0].filename,\r\n        topScore: searchResults[0].topScore?.toFixed(4),\r\n        resultsCount: searchResults[0].results?.length\r\n      });\r\n    }\r\n\r\n    // Se non ci sono risultati rilevanti\r\n    if (searchResults.length === 0) {\r\n      console.log('No semantic search results found');\r\n      \r\n      return res.status(200).json({\r\n        success: true,\r\n        message: `Non ho trovato informazioni rilevanti nei documenti caricati per rispondere a: \"${message}\"\\n\\n**Suggerimenti:**\\n- Prova a formulare la domanda in modo diverso\\n- Usa parole chiave più specifiche\\n- Verifica che i documenti caricati contengano le informazioni richieste\\n\\n**Documenti caricati:** ${stats.totalDocuments}\\n**Sezioni totali:** ${stats.totalChunks}`,\r\n        timestamp: new Date().toISOString(),\r\n        noResults: true,\r\n        stats,\r\n      });\r\n    }\r\n\r\n    // Costruisci contesto della conversazione (ultimi 3 messaggi)\r\n    const conversationContext = conversationHistory\r\n      .filter(m => m.role && m.content)\r\n      .slice(-3)\r\n      .map(m => `${m.role === 'user' ? 'Utente' : 'Assistente'}: ${m.content}`)\r\n      .join('\\n\\n');\r\n\r\n    // Genera risposta usando OpenAI con i risultati della ricerca semantica\r\n    // IMPORTANTE: passa SOLO testo, non oggetti o ID\r\n    console.log('Generating answer with OpenAI...');\r\n    const answer = await generateMultiDocumentAnswer(message, searchResults, conversationContext);\r\n    \r\n    console.log('Generated answer:', {\r\n      answerLength: answer.answer.length,\r\n      confidence: answer.confidence,\r\n      sourcesCount: answer.sources?.length || 0,\r\n    });\r\n\r\n    // Costruisci risposta completa con formattazione\r\n    let responseMessage = answer.answer;\r\n\r\n    // Aggiungi informazioni sui documenti usati\r\n    if (answer.sources && answer.sources.length > 0) {\r\n      responseMessage += `\\n\\n📚 **Documenti consultati:**\\n\\n`;\r\n      answer.sources.forEach((source, idx) => {\r\n        const score = parseFloat(source.score);\r\n        const percentage = (score * 100).toFixed(0);\r\n        responseMessage += `\"${source.filename}\" (rilevanza: ${percentage}%)\\n`;\r\n      });\r\n    }\r\n\r\n    // Aggiungi statistiche\r\n    responseMessage += `\\n\\n💡 Ho cercato in ${stats.totalDocuments} document${stats.totalDocuments > 1 ? 'i' : 'o'} con ${stats.totalChunks} sezioni totali.`;\r\n\r\n    return res.status(200).json({\r\n      success: true,\r\n      message: responseMessage,\r\n      timestamp: new Date().toISOString(),\r\n      confidence: answer.confidence,\r\n      sources: answer.sources || [],\r\n      documentsUsed: searchResults.map(r => ({\r\n        fileId: r.fileId,\r\n        filename: r.filename,\r\n        topScore: r.topScore,\r\n      })),\r\n      stats,\r\n    });\r\n  } catch (error) {\r\n    console.error('Chat API Error:', error);\r\n    \r\n    return res.status(500).json({ \r\n      error: 'Errore durante l\\'elaborazione',\r\n      details: error.message,\r\n      timestamp: new Date().toISOString(),\r\n    });\r\n  }\r\n}\r\n","import type { NextApiResponse } from '../../types'\nimport type { IncomingMessage, ServerResponse } from 'node:http'\n\nimport { sendError } from '../../server/api-utils'\nimport { RouteKind } from '../../server/route-kind'\nimport type { Span } from '../../server/lib/trace/tracer'\nimport { PagesAPIRouteModule } from '../../server/route-modules/pages-api/module.compiled'\n\nimport { hoist } from './helpers'\n\n// Import the userland code.\nimport * as userland from 'VAR_USERLAND'\nimport { getTracer, SpanKind } from '../../server/lib/trace/tracer'\nimport { BaseServerSpan } from '../../server/lib/trace/constants'\nimport type { InstrumentationOnRequestError } from '../../server/instrumentation/types'\nimport { addRequestMeta } from '../../server/request-meta'\n\n// Re-export the handler (should be the default export).\nexport default hoist(userland, 'default')\n\n// Re-export config.\nexport const config = hoist(userland, 'config')\n\n// Create and export the route module that will be consumed.\nconst routeModule = new PagesAPIRouteModule({\n  definition: {\n    kind: RouteKind.PAGES_API,\n    page: 'VAR_DEFINITION_PAGE',\n    pathname: 'VAR_DEFINITION_PATHNAME',\n    // The following aren't used in production.\n    bundlePath: '',\n    filename: '',\n  },\n  userland,\n  distDir: process.env.__NEXT_RELATIVE_DIST_DIR || '',\n  relativeProjectDir: process.env.__NEXT_RELATIVE_PROJECT_DIR || '',\n})\n\nexport async function handler(\n  req: IncomingMessage,\n  res: ServerResponse,\n  ctx: {\n    waitUntil?: (prom: Promise<void>) => void\n  }\n): Promise<void> {\n  if (routeModule.isDev) {\n    addRequestMeta(req, 'devRequestTimingInternalsEnd', process.hrtime.bigint())\n  }\n  let srcPage = 'VAR_DEFINITION_PAGE'\n\n  // turbopack doesn't normalize `/index` in the page name\n  // so we need to to process dynamic routes properly\n  // TODO: fix turbopack providing differing value from webpack\n  if (process.env.TURBOPACK) {\n    srcPage = srcPage.replace(/\\/index$/, '') || '/'\n  }\n\n  const prepareResult = await routeModule.prepare(req, res, { srcPage })\n\n  if (!prepareResult) {\n    res.statusCode = 400\n    res.end('Bad Request')\n    ctx.waitUntil?.(Promise.resolve())\n    return\n  }\n\n  const { query, params, prerenderManifest, routerServerContext } =\n    prepareResult\n\n  try {\n    const method = req.method || 'GET'\n    const tracer = getTracer()\n\n    const activeSpan = tracer.getActiveScopeSpan()\n    const onRequestError =\n      routeModule.instrumentationOnRequestError.bind(routeModule)\n\n    const invokeRouteModule = async (span?: Span) =>\n      routeModule\n        .render(req, res, {\n          query: {\n            ...query,\n            ...params,\n          },\n          params,\n          allowedRevalidateHeaderKeys: process.env\n            .__NEXT_ALLOWED_REVALIDATE_HEADERS as any as string[],\n          multiZoneDraftMode: Boolean(process.env.__NEXT_MULTI_ZONE_DRAFT_MODE),\n          trustHostHeader: process.env\n            .__NEXT_TRUST_HOST_HEADER as any as boolean,\n          // TODO: get this from from runtime env so manifest\n          // doesn't need to load\n          previewProps: prerenderManifest.preview,\n          propagateError: false,\n          dev: routeModule.isDev,\n          page: 'VAR_DEFINITION_PAGE',\n\n          internalRevalidate: routerServerContext?.revalidate,\n\n          onError: (...args: Parameters<InstrumentationOnRequestError>) =>\n            onRequestError(req, ...args),\n        })\n        .finally(() => {\n          if (!span) return\n\n          span.setAttributes({\n            'http.status_code': res.statusCode,\n            'next.rsc': false,\n          })\n\n          const rootSpanAttributes = tracer.getRootSpanAttributes()\n          // We were unable to get attributes, probably OTEL is not enabled\n          if (!rootSpanAttributes) {\n            return\n          }\n\n          if (\n            rootSpanAttributes.get('next.span_type') !==\n            BaseServerSpan.handleRequest\n          ) {\n            console.warn(\n              `Unexpected root span type '${rootSpanAttributes.get(\n                'next.span_type'\n              )}'. Please report this Next.js issue https://github.com/vercel/next.js`\n            )\n            return\n          }\n\n          const route = rootSpanAttributes.get('next.route')\n          if (route) {\n            const name = `${method} ${route}`\n\n            span.setAttributes({\n              'next.route': route,\n              'http.route': route,\n              'next.span_name': name,\n            })\n            span.updateName(name)\n          } else {\n            span.updateName(`${method} ${srcPage}`)\n          }\n        })\n\n    // TODO: activeSpan code path is for when wrapped by\n    // next-server can be removed when this is no longer used\n    if (activeSpan) {\n      await invokeRouteModule(activeSpan)\n    } else {\n      await tracer.withPropagatedContext(req.headers, () =>\n        tracer.trace(\n          BaseServerSpan.handleRequest,\n          {\n            spanName: `${method} ${srcPage}`,\n            kind: SpanKind.SERVER,\n            attributes: {\n              'http.method': method,\n              'http.target': req.url,\n            },\n          },\n          invokeRouteModule\n        )\n      )\n    }\n  } catch (err) {\n    // we re-throw in dev to show the error overlay\n    if (routeModule.isDev) {\n      throw err\n    }\n    // this is technically an invariant as error handling\n    // should be done inside of api-resolver onError\n    sendError(res as NextApiResponse, 500, 'Internal Server Error')\n  } finally {\n    // We don't allow any waitUntil work in pages API routes currently\n    // so if callback is present return with resolved promise since no\n    // pending work\n    ctx.waitUntil?.(Promise.resolve())\n  }\n}\n"],"names":["sendError","RouteKind","PagesAPIRouteModule","hoist","userland","getTracer","SpanKind","BaseServerSpan","addRequestMeta","config","routeModule","definition","kind","PAGES_API","page","pathname","bundlePath","filename","distDir","process","env","__NEXT_RELATIVE_DIST_DIR","relativeProjectDir","__NEXT_RELATIVE_PROJECT_DIR","handler","req","res","ctx","isDev","hrtime","bigint","srcPage","TURBOPACK","replace","prepareResult","prepare","statusCode","end","waitUntil","Promise","resolve","query","params","prerenderManifest","routerServerContext","method","tracer","activeSpan","getActiveScopeSpan","onRequestError","instrumentationOnRequestError","bind","invokeRouteModule","span","render","allowedRevalidateHeaderKeys","__NEXT_ALLOWED_REVALIDATE_HEADERS","multiZoneDraftMode","Boolean","__NEXT_MULTI_ZONE_DRAFT_MODE","trustHostHeader","__NEXT_TRUST_HOST_HEADER","previewProps","preview","propagateError","dev","internalRevalidate","revalidate","onError","args","finally","setAttributes","rootSpanAttributes","getRootSpanAttributes","get","handleRequest","console","warn","route","name","updateName","withPropagatedContext","headers","trace","spanName","SERVER","attributes","url","err"],"mappings":"sUACA,IAAA,EAAA,EAAA,CAAA,CAAA,yCAEA,IAAM,EAAS,IAAI,EAAA,OAAM,CAAC,CACxB,OAAQ,QAAQ,GAAG,CAAC,cAAc,AACpC,GAGO,eAAe,EAAkB,CAAI,EAC1C,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAMF,MAAO,CALU,MAAM,EAAO,UAAU,CAAC,MAAM,CAAC,CAC9C,MAAO,yBACP,MAAO,EAAK,SAAS,CAAC,EAAG,IAC3B,EAAA,EAEgB,IAAI,CAAC,EAAE,CAAC,SAAS,AACnC,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,8BAA+B,GACvC,AAAI,MAAM,CAAC,8BAA8B,EAAE,EAAM,OAAO,CAAA,CAAE,CAClE,CACF,CAGO,eAAe,EAAwB,CAAK,EACjD,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAAC,MAAM,OAAO,CAAC,IAAU,AAAiB,MAAX,MAAM,CAAQ,MAAO,EAAE,CAE1D,GAAI,CAMF,MAAO,CALU,MAAM,EAAO,UAAU,CAAC,MAAM,CAAC,CAC9C,MAAO,yBACP,MAAO,EAAM,GAAG,CAAC,GAAK,CAAC,GAAK,EAAA,CAAE,CAAE,QAAQ,GAAG,SAAS,CAAC,EAAG,KAC1D,EAAA,EAEgB,IAAI,CAAC,GAAG,CAAC,GAAK,EAAE,SAAS,CAC3C,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,qCAAsC,GAC9C,AAAI,MAAM,CAAC,qCAAqC,EAAE,EAAM,OAAO,CAAA,CAAE,CACzE,CACF,CAGO,eAAe,EAAe,CAAQ,CAAE,EAAU,CAAC,CAAC,EACzD,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAWF,MAAO,CAVU,MAAM,EAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,CACpD,MAAO,EAAQ,KAAK,EAAI,cACxB,SAAU,EACV,YAAa,EAAQ,WAAW,EAAI,GACpC,WAAY,EAAQ,UAAU,EAAI,IAClC,MAAO,EAAQ,KAAK,EAAI,EACxB,kBAAmB,EAAQ,iBAAiB,EAAI,EAChD,iBAAkB,EAAQ,gBAAgB,EAAI,CAChD,EAAA,EAEgB,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO,AAC5C,CAAE,MAAO,EAAO,CAId,GAHA,QAAQ,KAAK,CAAC,4BAA6B,GAGtB,KAAK,CAAtB,EAAM,MAAM,CACd,MAAM,AAAI,MAAM,6DACX,GAAI,AAAiB,KAAK,GAAhB,MAAM,CACrB,MAAM,AAAI,MAAM,0DACX,GAAqB,KAAK,CAAtB,EAAM,MAAM,CACrB,MAAM,AAAI,MAAM,+CAGlB,OAAU,AAAJ,MAAU,CAAC,uCAAuC,EAAE,EAAM,OAAO,CAAA,CAAE,CAC3E,CACF,CAGO,eAAe,EAAgB,CAAI,CAAE,EAAY,GAAG,EACzD,IAAM,EAAW,CACf,CACE,KAAM,SACN,QAAS,6DACX,EACA,CACE,KAAM,OACN,QAAS,CAAC,gCAAgC,EAAE,EAAU;AAAA;AAAmB,EAAE,EAAA,CAAM,AACnF,EACD,CAED,OAAO,MAAM,EAAe,EAAU,CAAE,YAAa,GAAK,WAAY,GAAI,EAC5E,CAGO,eAAe,EAAa,CAAI,CAAE,EAAQ,CAAC,EAChD,IAAM,EAAW,CACf,CACE,KAAM,SACN,QAAS,4HACX,EACA,CACE,KAAM,OACN,QAAS,CAAC,SAAS,EAAE,EAAM;AAAA;AAAqC,EAAE,EAAK,SAAS,CAAC,EAAG,KAAA,CAAO,AAC7F,EACD,CAID,MAAO,CAFU,MAAM,EAAe,EAAU,CAAE,YAAa,GAAK,WAAY,GAAI,EAAA,EAGjF,KAAK,CAAC,KACN,GAAG,CAAC,GAAO,EAAI,IAAI,GAAG,WAAW,IACjC,MAAM,CAAC,GAAO,EAAI,MAAM,CAAG,GAC3B,KAAK,CAAC,EAAG,EACd,CAGO,eAAe,EAAiB,CAAI,EACzC,IAAM,EAAa,CACjB,WAAY,UAAW,SAAU,eACjC,cAAe,QAAS,OAAQ,QAAS,UAAW,QACrD,CAEK,EAAW,CACf,CACE,KAAM,SACN,QAAS,CAAC,2FAA2F,EAAE,EAAW,IAAI,CAAC,MAAM,8CAA8C,CAAC,AAC9K,EACA,CACE,KAAM,OACN,QAAS,CAAC;AAAA;AAA2B,EAAE,EAAK,SAAS,CAAC,EAAG,KAAA,CAAO,AAClE,EACD,CAID,MAAO,CAFU,MAAM,EAAe,EAAU,CAAE,YAAa,GAAK,WAAY,EAAG,EAAA,EAGhF,KAAK,CAAC,KACN,GAAG,CAAC,GAAO,EAAI,IAAI,GAAG,WAAW,IACjC,MAAM,CAAC,GAAO,EAAW,QAAQ,CAAC,GACvC,CAGO,eAAe,EAAuB,CAAW,CAAE,CAAa,CAAE,EAAQ,6DAA6D,EAC5I,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAEF,IAAM,EAAc,EAAY,QAAQ,CAAC,UA8BzC,MAAO,CA5BU,MAAM,EAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,CACpD,MAAO,SACP,SAAU,CACR,CACE,KAAM,SACN,QAAS,mOACX,EACA,CACE,KAAM,OACN,QAAS,CACP,CACE,KAAM,OACN,KAAM,CACR,EACA,CACE,KAAM,YACN,UAAW,CACT,IAAK,CAAC,KAAK,EAAE,EAAc,QAAQ,EAAE,EAAA,CAAa,CAClD,OAAQ,MACV,CACF,EACD,AACH,EACD,CACD,WAAY,IACZ,YAAa,EACf,EAAA,EAEgB,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO,AAC5C,CAAE,MAAO,EAAO,CAGd,GAFA,QAAQ,KAAK,CAAC,uBAAwB,GAEjB,KAAK,CAAtB,EAAM,MAAM,CACd,MAAM,AAAI,MAAM,6DACX,GAAI,AAAiB,KAAK,GAAhB,MAAM,CACrB,MAAM,AAAI,MAAM,0DACX,GAAqB,MAAjB,EAAM,MAAM,EAAY,EAAM,OAAO,EAAE,SAAS,SACzD,CADmE,KACzD,AAAJ,MAAU,4DAGlB,OAAM,AAAI,MAAM,CAAC,mCAAmC,EAAE,EAAM,OAAO,CAAA,CAAE,CACvE,CACF,CAIO,eAAe,EAA6B,CAAQ,EACzD,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,IAAM,EAAK,MAAA,EAAA,CAAA,CAAA,QAEP,EAAe,KACnB,GAAI,CAIF,EAAe,MAAM,EAAO,KAAK,CAAC,MAAM,CAAC,CACvC,KAAM,EAAG,gBAAgB,CAAC,GAC1B,QAAS,WACX,GAqBA,IAAM,EAAgB,AAAC,CAhBN,OAAM,EAAO,SAAS,CAAC,MAAM,CAAC,CAC7C,MAAO,SACP,MAAO,CACL,CACE,KAAM,OACN,QAAS,CACP,CAAE,KAAM,aAAc,KAAM,6HAA8H,EAC1J,CAAE,KAAM,aAAc,QAAS,EAAa,EAAG,AAAD,EAC/C,AACH,EACD,CACD,kBAAmB,IACnB,YAAa,EACf,EAAA,EAGgC,WAAW,EAAI,EAAA,CAAE,CAAE,QAAQ,GAAG,IAAI,GAGlE,GAAI,CAAC,EACH,MAAM,AAAI,MAAM,CADE,gCAIpB,OAAO,CAET,CAAE,MAAO,EAAO,CAGd,GAFA,QAAQ,KAAK,CAAC,gDAAiD,GAE1C,KAAK,CAAtB,EAAM,MAAM,CACd,MAAM,AAAI,MAAM,6DACX,GAAqB,KAAK,CAAtB,EAAM,MAAM,CACrB,MAAM,AAAI,MAAM,0DACX,GAAqB,KAAK,CAAtB,EAAM,MAAM,CACrB,MAAM,AAAI,MAAM,sGAGlB,OAAM,AAAI,MAAM,CAAC,sCAAsC,EAAE,EAAM,OAAO,CAAA,CAAE,CAC1E,QAAU,CAER,GAAI,CACE,GAAgB,EAAa,EAAE,EAAE,CAC/B,EAAO,KAAK,EAAE,OAChB,CADwB,KAClB,EAAO,KAAK,CAAC,MAAM,CAAC,EAAa,EAAE,EAChC,EAAO,KAAK,EAAE,KAAK,AAC5B,MAAM,EAAO,KAAK,CAAC,GAAG,CAAC,EAAa,EAAE,EAI5C,CAAE,MAAO,EAAU,CACjB,QAAQ,IAAI,CAAC,8CAA+C,GAAU,SAAW,EACnF,CACF,CACF,CAGO,eAAe,EAAqB,CAAM,CAAE,EAAU,CAAC,CAAC,EAC7D,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CACF,IAAM,EAAO,EAAQ,IAAI,EAAI,YACvB,EAAU,EAAQ,OAAO,EAAI,WAC7B,EAAQ,EAAQ,KAAK,EAAI,QAEzB,EAAW,MAAM,EAAO,MAAM,CAAC,QAAQ,CAAC,CAC5C,MAAO,WACP,OAAQ,EACR,KAAM,EACN,QAAS,EACT,MAAO,EACP,EAAG,CACL,GAEM,EAAW,EAAS,IAAI,CAAC,EAAE,EAAE,IACnC,GAAI,CAAC,EACH,MAAM,AAAI,EADG,IACG,uCAGlB,OAAO,CACT,CAAE,MAAO,EAAO,CAUd,GATA,QAAQ,KAAK,CAAC,uCAAwC,GACtD,QAAQ,KAAK,CAAC,iBAAkB,CAC9B,OAAQ,EAAM,MAAM,CACpB,WAAY,EAAM,UAAU,CAC5B,QAAS,EAAM,OAAO,CACtB,KAAM,EAAM,IAAI,CAChB,SAAU,EAAM,QAAQ,EAAE,MAAQ,EAAM,QAAQ,AAClD,GAEqB,KAAK,CAAtB,EAAM,MAAM,CACd,MAAM,AAAI,MAAM,6DACX,GAAqB,KAAK,CAAtB,EAAM,MAAM,CACrB,MAAM,AAAI,MAAM,0DACX,GAAI,AAAiB,QAAX,MAAM,CAAU,CAC/B,IAAM,EAAe,EAAM,OAAO,EAAI,EAAM,QAAQ,EAAE,MAAM,OAAO,SAAW,8CAC9E,OAAM,AAAI,MAAM,CAAC,0BAA0B,EAAE,EAAA,CAAc,CAC7D,MAAO,GAAmB,cAAf,EAAM,IAAI,EAAoB,AAAe,gBAAgB,GAAzB,IAAI,CACjD,MAAM,AAAI,MAAM,0EAGlB,OAAM,AAAI,MAAM,CAAC,wCAAwC,EAAE,EAAM,OAAO,EAAI,qBAAA,CAAsB,CACpG,CACF,CAGO,eAAe,EAAuB,CAAM,CAAE,EAAU,CAAC,CAAC,EAC/D,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CACF,IAAM,EAAW,MAAM,EAAqB,EAAQ,GAG9C,EAAgB,MAAM,MAAM,GAClC,GAAI,CAAC,EAAc,EAAE,CAAE,CACrB,IAAM,EAAY,MAAM,EAAc,IAAI,GAAG,KAAK,CAAC,IAAM,gBACzD,OAAU,AAAJ,MAAU,CAAC,4CAA4C,EAAE,EAAc,MAAM,CAAC,CAAC,EAAE,EAAc,UAAU,CAAC,EAAE,EAAE,EAAA,CAAW,CACjI,CAEA,IAAM,EAAc,MAAM,EAAc,WAAW,GACnD,OAAO,OAAO,IAAI,CAAC,EACrB,CAAE,MAAO,EAAO,CAEd,MAAM,CACR,CACF,CAGO,eAAe,EAAsB,CAAW,CAAE,CAAa,CAAE,EAAoB,IAAI,EAC9F,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAIF,IAAM,EAAmB,MAAM,EAC7B,EACA,EAJqB,GAAqB,UAK1C,6LAII,EAAwB,CAAC,uEAAuE,EAAE,EAAiB,qGAA+F,CAAC,CASzN,OAN4B,AAMrB,MAN2B,EAAuB,EAAuB,CAC9E,KAAM,YACN,QAAS,KACT,MAAO,SACT,EAGF,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,qCAAsC,GAC9C,AAAI,MAAM,CAAC,wCAAwC,EAAE,EAAM,OAAO,CAAA,CAAE,CAC5E,CACF,CAGO,eAAe,EAA0B,CAAW,CAAE,CAAa,EACxE,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAEF,IAAM,EAAiB,CAAC;;;;;;;yMAO6K,CAAC,CAEhM,EAAiB,MAAM,EAC3B,EACA,EACA,GAIE,EAAW,CACb,MAAO,SACP,UAAW,WACX,MAAO,SACP,UAAW,MACb,EAEA,GAAI,CAEF,IAAM,EAAY,EAAe,KAAK,CAAC,eACvC,GAAI,EAAW,CACb,IAAM,EAAS,KAAK,KAAK,CAAC,CAAS,CAAC,EAAE,EACtC,EAAW,CAAE,GAAG,CAAQ,CAAE,GAAG,CAAO,AAAD,CACrC,CACF,CAAE,MAAO,EAAY,CACnB,QAAQ,IAAI,CAAC,8CACf,CAIA,IAAI,EAAW,GADD,CAAC,MAAA,EAAA,CAAA,CAAA,OAAA,CAAqB,CAAE,OAAO,AAAP,EACjB,EAAa,CAAE,gBAAgB,CAAK,GA0DzD,OAvDuB,AAuDhB,SAvDH,EAAS,KAAK,EAAkC,WAAnB,EAAS,KAAK,AAAK,GAAU,CAC5D,EAAW,EAAS,MAAM,CAAoB,SAAnB,EAAS,KAAK,CAAc,EAAI,EAAA,EAIlC,UAAU,CAAjC,EAAS,SAAS,CACpB,EAAW,EAAS,OAAO,CAAC,CAC1B,MAAO,EACP,GAAI,EACJ,GAAI,GACJ,GAAI,EACJ,GAAI,EACJ,GAAI,CACN,GACgC,YAAY,CAAnC,EAAS,SAAS,GAC3B,EAAW,EAAS,OAAO,CAAC,CAC1B,MAAO,EACP,GAAI,GACJ,GAAI,EACN,EAAA,EAIqB,UAAU,CAA7B,EAAS,KAAK,GAChB,EAAW,EAAS,QAAQ,CAAC,CAC3B,WAAY,KACZ,WAAY,IACd,GAAG,MAAM,CAAC,KAAM,CAAE,IAAM,EAAA,AAKxB,CALgC,CAIP,UAAvB,EAAS,SAAS,EAJoC,AAIpB,AAAuB,SAAS,GAAvB,SAAS,CAC3C,EAAS,GAAG,CAAC,CACtB,QAAS,IACT,iBAAkB,EAClB,mBAAmB,CACrB,GAGsB,eAAlB,GAAoD,aAAa,CAA/B,EACzB,EAAS,IAAI,CAAC,CACvB,QAAS,GACT,SAAS,EACT,qBAAqB,EACrB,oBAAoB,CACtB,GAEW,EAAS,GAAG,CAAC,CACtB,QAAS,IACT,iBAAkB,CACpB,GAImB,MAAM,EAAS,QAAQ,EAEhD,CAAE,MAAO,EAAO,CAGd,OAFA,QAAQ,KAAK,CAAC,yCAA0C,GAEjD,CACT,CACF,kdC1eA,IAAA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,0CAKA,IAAM,EAAgB,IAAI,IASnB,GAT0B,YASX,EAAwB,CAAM,CAAE,CAAQ,CAAE,CAAQ,CAAE,EAAW,IAAI,EACvF,GAAI,CACF,IAAI,EAAO,GACP,AAZkE,EAYvD,UACb,WACA,EACA,MAAO,EACP,UAAW,CACb,EAEA,GAAiB,oBAAb,GAAkC,EAAS,WAAW,GAAG,QAAQ,CAAC,QAAS,CAE7E,GAAM,8BAAE,CAA4B,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAInC,EAAK,MAAA,EAAA,CAAA,CAAA,QACL,EAAO,MAAA,EAAA,CAAA,CAAA,QAGP,EAAU,CAFL,MAAA,EAAA,CAAA,CAAA,OAAA,EAEQ,MAAM,GACnB,EAAe,EAAK,IAAI,CAAC,EAAS,CAAC,KAAK,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,EAAA,CAAU,EAExE,GAAI,CAWF,GATA,EAAG,aAAa,CAAC,EAAc,GAM/B,EAAO,CAAC,CAHR,EAAO,MAAM,EAA6B,EAAA,GAG1B,EAAA,CAAE,CAAE,QAAQ,GAAG,IAAI,GACnC,EAAS,cAAc,CAAG,qBAEtB,CAAC,GAAwB,GAAG,CAAnB,EAAK,MAAM,CACtB,MAAM,AAAI,MAAM,+CAIpB,QAAU,CAER,GAAI,CACE,EAAG,UAAU,CAAC,IAChB,EAAG,SAD4B,CAClB,CAAC,EAElB,CAAE,MAAO,EAAc,CACrB,QAAQ,IAAI,CAAC,kCAAmC,EAClD,CACF,CACF,MACK,GAAI,EAAS,QAAQ,CAAC,qBAAuB,EAAS,WAAW,GAAG,QAAQ,CAAC,SAKhF,CAL0F,CAKnF,CAHP,EAAO,CADQ,MAAM,EAAA,OAAO,CAAC,cAAc,CAAC,QAAE,CAAO,EAAA,EACvC,KAAA,AAAK,EAGP,OAAO,CAAC,OAAQ,KAAK,IAAI,QAElC,GAAI,EAAS,QAAQ,CAAC,gBAAkB,EAAS,WAAW,GAAG,KAAK,CAAC,sBAAuB,CAC/F,IAAM,EAAW,EAAA,IAAS,CAAC,EAAQ,CAAE,KAAM,QAAS,GAC9C,EAAS,EAAS,UAAU,CAG5B,EAAU,EAAE,CAClB,IAAK,IAAM,KAAa,EAAQ,CAC9B,IAAM,EAAQ,EAAS,MAAM,CAAC,EAAU,CAGxC,IAAK,IAAM,KAFO,EAAA,AAEA,KAFU,CAAC,IAEA,SAFa,CAAC,EAAO,CAAE,OAAQ,EAAG,OAAQ,EAAG,GAGxE,GAAI,MAAM,OAAO,CAAC,GAAM,CACtB,IAAM,EAAU,EAAI,MAAM,CAAC,GAAQ,GAAQ,EAAK,QAAQ,GAAG,IAAI,IAAI,IAAI,CAAC,KACpE,EAAQ,IAAI,IAAI,AAClB,EAAQ,IAAI,CAAC,CAAC,CAAC,EAAE,EAAU,EAAE,EAAE,EAAA,CAAS,CAE5C,CAEJ,CAEA,EAAO,EAAQ,IAAI,CAAC,KACtB,MACK,GAAI,EAAS,UAAU,CAAC,UAAY,EAAS,WAAW,GAAG,QAAQ,CAAC,QACvE,CADgF,CACzE,EAAO,QAAQ,CAAC,cAEpB,GAAI,EAAS,UAAU,CAAC,WAAa,EAAS,WAAW,GAAG,KAAK,CAAC,sDAErE,CAF4H,EAExH,CACF,GAAM,wBAAE,CAAsB,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAGnC,GAAI,CAQF,EANmB,KAMZ,CANkB,EACvB,EACA,EACA,4MAOF,EAAS,cAAc,CAAG,eAC5B,CAAE,MAAO,EAAa,CAIpB,IAAM,EAAY,CAAC,MAAA,EAAA,CAAA,CAAA,OAAA,CAA4B,CAAE,OAAO,CAClD,EAAc,GAAY,EAEhC,GAAI,CASF,EAAO,CARQ,MAAM,EAAU,SAAS,CAAC,EAAa,UAAW,CAC/D,OAAQ,AAAC,IACH,EAAE,MAAM,AAGd,CACF,EAAA,EAJqB,AAMP,IAAI,CAAC,IAAI,CAAC,IAAI,GAC5B,EAAS,CAPgC,aAOlB,CAAG,eAC5B,CAAE,MAAO,EAAU,CAIjB,IAAM,EAAS,MAAM,EAAU,YAAY,CAAC,UAAW,EAAG,CACxD,OAAQ,AAAC,IACH,EAAE,MAAM,AAGd,CACF,GAEA,CANqB,EAMjB,CAEF,EAAO,CADQ,MAAM,EAAO,MAPW,GAOF,CAAC,EAAA,EACxB,IAAI,CAAC,IAAI,CAAC,IAAI,GAC5B,EAAS,cAAc,CAAG,sBAC5B,QAAU,CACR,MAAM,EAAO,SAAS,EACxB,CACF,CACF,CAEA,GAAI,CAAC,GAAwB,GAAG,CAAnB,EAAK,MAAM,CACtB,MAAM,AAAI,MAAM,6GAIpB,CAAE,MAAO,EAAY,CAEnB,MADA,QAAQ,KAAK,CAAC,oCAAqC,GAC7C,AAAI,MAAM,CAAC,mCAAmC,EAAE,EAAW,OAAO,CAAA,CAAE,CAC5E,MAGA,MAAU,AAAJ,MAAU,CAAC,6BAA6B,EAAE,EAAA,CAAU,EAG5D,GAAI,CAAC,GAA+B,GAAG,CAA1B,EAAK,IAAI,GAAG,MAAM,CAC7B,MAAM,AAAI,MAAM,uCAKlB,OAFA,EAAS,SAAS,CAAG,EAAK,KAAK,CAAC,OAAO,MAAM,CAEtC,MAAE,WAAM,CAAS,CAC1B,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,2BAA4B,GACpC,AAAI,MAAM,CAAC,kCAAkC,EAAE,EAAM,OAAO,CAAA,CAAE,CACtE,CACF,CAMO,eAAe,EAAiB,CAAI,CAAE,EAAY,GAAI,CAAE,EAAU,GAAG,EAC1E,IAAM,EAAY,EAAK,KAAK,CAAC,aAAa,MAAM,CAAC,GAAK,EAAE,IAAI,GAAG,MAAM,CAAG,IAClE,EAAS,EAAE,CAEb,EAAe,GACf,EAAgB,EAEpB,IAAK,IAAM,KAAY,EAAW,CAChC,IAAM,EAAiB,EAAS,MAAM,CAElC,EAAgB,EAAiB,GAAa,EAAa,IAAI,IAEjE,AAFqE,EAE9D,IAAI,CAAC,CACV,KAAM,EAAa,IAAI,GACvB,WAAY,EAAK,OAAO,CAAC,EAAa,IAAI,IAC1C,SAAU,EAAK,OAAO,CAAC,EAAa,IAAI,IAAM,EAAa,MAAM,AACnE,GAMA,EAAgB,CADhB,EAFc,AACO,AACN,EAFY,KAAK,CAAC,OACN,KAAK,CAAC,CAAC,KAAK,KAAK,CAAC,EAAU,KAC3B,IAAI,CAAC,KAAO,IAAM,EAAW,GAAA,EAC5B,MAAM,GAEnC,GAAgB,EAAW,KAC3B,GAAiB,EAAiB,EAEtC,CAGI,EAAa,IAAI,IAAI,AACvB,EAAO,IAAI,CAAC,CACV,KAAM,EAAa,IAAI,GACvB,WAAY,EAAK,OAAO,CAAC,EAAa,IAAI,IAC1C,SAAU,EAAK,MAAM,AACvB,GAGF,IAAM,EAAc,EAAO,MAAM,CAAG,EAAI,EAAS,CAAC,CAAE,KAAM,EAAK,IAAI,GAAI,WAAY,EAAG,SAAU,EAAK,MAAM,AAAC,EAAE,CAGxG,yBAAE,CAAuB,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAEpC,GAAI,CAGF,IAAK,IAAI,EAAI,EAAG,EAAI,EAAY,MAAM,CAAE,KAAK,CAAY,CACvD,IAAM,EAAQ,EAAY,KAAK,CAAC,EAAG,EAFlB,EAEsB,EACpB,AACnB,OADyB,EAAwB,EAAM,GAAG,CAAC,GAAK,EAAE,IAAI,EAAA,EAC3D,OAAO,CAAC,CAAC,EAAK,KACvB,CAAK,CAAC,EAAI,CAAC,SAAS,CAAG,CACzB,EACF,CACF,CAAE,MAAO,EAAU,CACjB,QAAQ,IAAI,CAAC,sDAAuD,EAAS,OAAO,EACpF,GAAM,mBAAE,CAAiB,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAC9B,IAAK,IAAM,KAAS,EAClB,GAAI,CACF,EAAM,IAFuB,KAEd,CAAG,MAAM,EAAkB,EAAM,IAAI,CACtD,CAAE,MAAO,EAAK,CACZ,QAAQ,IAAI,CAAC,0CAA2C,EAAI,OAAO,EACnE,EAAM,SAAS,CAAG,IACpB,CAEJ,CAEA,OAAO,CACT,CAgDO,eAAe,EAAe,CAAY,CAAE,CAAM,CAAE,CAAK,CAAE,EAAO,CAAC,EACxE,GAAI,CAAC,GAA4B,GAAG,CAArB,EAAO,MAAM,CAC1B,MAAO,EAAE,CAIX,GAAM,mBAAE,CAAiB,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAC1B,EAAiB,KAErB,GAAI,CACF,EAAiB,MAAM,EAAkB,EAC3C,CAAE,MAAO,EAAU,CACjB,QAAQ,IAAI,CAAC,kDAAmD,EAClE,CA4CA,OAzCqB,AAkCA,AAOd,EAzCqB,GAAG,CAAC,CAAC,EAAO,KACtC,IAAI,EAAgB,EAIlB,EADE,GAAkB,EAAM,SAAS,CA/DzC,AAgEsB,CADqB,QA/DlC,AAAiB,CAAI,CAAE,CAAI,EAClC,GAAI,CAAC,GAAQ,CAAC,GAAQ,EAAK,MAAM,GAAK,EAAK,MAAM,CAAE,OAAO,EAE1D,IAAM,EAAM,EAAK,MAAM,CAAC,CAAC,EAAK,EAAK,IAAM,EAAM,EAAM,CAAI,CAAC,EAAE,CAAE,GACxD,EAAO,KAAK,IAAI,CAAC,EAAK,MAAM,CAAC,CAAC,EAAK,IAAQ,EAAM,EAAM,EAAK,IAC5D,EAAO,KAAK,IAAI,CAAC,EAAK,MAAM,CAAC,CAAC,EAAK,IAAQ,EAAM,EAAM,EAAK,IAElE,OAAO,GAAO,EAAO,CAAA,AAAR,CAAY,AAC3B,EAwDuC,EAAgB,EAAM,SAAS,EAnDtE,AAsDsB,SAtDb,AAAe,CAAI,CAAE,CAAK,EACjC,IAAM,EAAY,EAAK,WAAW,GAAG,KAAK,CAAC,OAAO,MAAM,CAAC,GAAK,EAAE,MAAM,CAAG,GACnE,EAAa,EAAM,WAAW,GAAG,KAAK,CAAC,OAAO,MAAM,CAAC,GAAK,EAAE,MAAM,CAAG,GAE3E,GAA0B,IAAtB,EAAW,MAAM,CAAQ,OAAO,EAEpC,IAAI,EAAQ,EACN,EAAgB,CAAC,EAgBvB,OAfA,EAAU,OAAO,CAAC,IAChB,CAAa,CAAC,EAAK,CAAG,CAAC,CAAa,CAAC,EAAK,GAAI,CAAC,CAAI,CACrD,GAEA,EAAW,OAAO,CAAC,IACjB,IAAM,EAAY,CAAa,CAAC,EAAU,EAAI,EAC9C,GAAI,EAAY,EAAG,CAEjB,IAAM,EAAK,EAAY,EAAU,MAAM,CAEjC,EAAM,KAAK,GAAG,CAAC,EAAU,MAAM,CAAI,EAAD,CAAa,CAAC,GAAK,EAC3D,GAAS,EAAK,CAChB,CACF,GAEO,EAAQ,EAAW,MAAM,AAClC,EA8BqC,EAAM,IAAI,CAAE,GAAS,GAItD,CAJ0D,GAIpD,EAAa,EAAM,IAAI,CAAC,WAAW,GACnC,EAAa,EAAM,UALyE,CAK9D,GAChC,EAAkB,EAClB,EAAW,QAAQ,CAAC,KACtB,EAAkB,EAAA,EAIpB,EALqC,EAK/B,EAAa,EAAM,WAAW,GAAG,KAAK,CAAC,OAAO,MAAM,CAAC,GAAK,EAAE,MAAM,CAAG,GAErE,EAAgB,AADA,EAAW,MAAM,CAAC,GAAQ,EAAW,QAAQ,CAAC,IAAO,MAAM,CAC3C,EAAW,MAAM,CAAI,IAErD,EAAa,EAAgB,EAAkB,EAErD,MAAO,CACL,GAAG,CAAK,CACR,MAAO,EACP,OACF,CACF,GAIG,IAAI,CAAC,CAAC,EAAG,IAAM,EAAE,KAAK,CAAG,EAAE,KAAK,EAChC,KAAK,CAAC,EAAG,GAKQ,MAAM,CAAC,GAAS,EAAM,KAAK,EAAI,EACrD,CASO,eAAe,EAAe,CAAK,CAAE,CAAc,CAAE,CAAY,CAAE,EAAsB,EAAE,CAAE,EAAmB,CAAC,CAAC,EACvH,GAAI,CAAC,GAA4C,GAAG,CAA7B,EAAe,MAAM,CAC1C,MAAO,CACL,OAAQ,0KACR,WAAY,EACZ,QAAS,EAAE,AACb,EAIF,IAAM,EAAkB,EACrB,GAAG,CAAC,CAAC,EAAO,IAAQ,CAAC,SAAS,EAAE,EAAM,EAAE;AAAG,EAAE,EAAM,IAAI,CAAA,CAAE,EACzD,IAAI,CAAC,eAGF,EAAa,KAAK,GAAG,CAA2B,GAA1B,CAAc,CAAC,EAAE,CAAC,KAAK,CAAO,GAE1D,GAAI,CAEF,IAAI,EAAiB,GACjB,GAAuB,EAAoB,IAAI,IAAI,CACrD,EAAiB,CAAC;AAAA;AAAA;AACxB,EAAE,oBAAoB;;uGAEgF,AAAC,EAGnG,IAAM,EAAW,CACf,CACE,KAAM,SACN,QAAS,CAAC;;;;;;;;;;;;;;;;;;;mDAmBiC,CAAC,AAC9C,EACA,CACE,KAAM,OACN,QAAS,CAAC;;;AAGlB,EAAE,EAAA,EAAkB,eAAe;;;AAGnC,EAAE,MAAM;;;;;;;yFAO8E,CAAC,AACjF,EACD,CAEG,EAAS,MAAM,CAAA,EAAA,EAAA,cAAc,AAAd,EAAe,EAAU,CAC1C,MAAO,cACP,YAAa,GACb,WAAY,KACZ,MAAO,GACP,kBAAmB,GACnB,iBAAkB,EACpB,EADwB,CAUxB,OARA,EAAS,EAAO,IAAI,GAEL,CAJ6B,wBAIJ,IAAI,CAAC,IAAW,EAAO,MAAM,CAAG,KAItE,GAFiB,CAAC,KAET;;AADA,EAAE,EAAe,KAAK,CAAC,EAAE,GAAG,GAAG,CAAC,GAAG,KAAK,EAAE,IAAI,CAAC,SAAS,CAAC,EAAE,KAAK,OAAO,CAAC,OAAO,KAAO,EAAD,CAAG,IAAI,CAAC,MAAM,CAAC,IAAI,MAAM,EAAA,CAAG,EAAG,IAAI,CAAC,MAAM;AAAA;AAAc,EAAE,EAAe,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,UAAU,EAAE,EAAE,EAAE,QAAQ,EAAE,EAAE,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,MAAM;AAAA;AAAA,uFAAsK,CAC5Y,AAD6Y,EAGjZ,QACL,aACA,EACA,QAAS,EAAe,GAAG,CAAC,IAAK,AAAC,CAChC,SAAU,GAAkB,kBAAoB,GAAkB,UAAY,YAC9E,KAAM,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAO,MACjC,MAAO,EAAE,KAAK,CAAC,OAAO,CAAC,GACzB,CAAC,CACH,CACF,CAAE,MAAO,EAAO,CACd,QAAQ,KAAK,CAAC,sDAAuD,GAErE,IAAM,EAAc,CAAc,CAAC,EAAE,CAAC,IAAI,CAC1C,MAAO,CACL,OAAQ,CAAC;AAAA;AAA4B,EAAE,YAAY;AAAA;AAAI,EAAE,EAAe,MAAM,CAAG,EAAI,+BAAiC,EAAe,KAAK,CAAC,EAAG,GAAG,GAAG,CAAC,CAAC,EAAG,IAAM,CAAC,EAAE,EAAE,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAK,GAAG,CAAC,EAAE,IAAI,CAAC,MAAQ,GAAA,CAAI,YACpN,EACA,QAAS,EAAe,GAAG,CAAC,IAAK,AAAC,CAChC,SAAU,GAAkB,kBAAoB,GAAkB,UAAY,YAC9E,KAAM,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAO,MACjC,MAAO,EAAE,KAAK,CAAC,OAAO,CAAC,GACzB,CAAC,CACH,CACF,CACF,CAKO,eAAe,EAAc,CAAM,CAAE,CAAI,CAAE,EAAW,CAAC,CAAC,EAG7D,IAAM,EAAS,MAAM,EAAiB,GAIhC,EAAe,MACnB,SACA,EACA,SAAU,CACR,GAAG,CAAQ,CACX,SAAU,EAAS,QAAQ,EAAI,EAAS,gBAAgB,EAAI,UAC5D,SAAU,IAAI,OAAO,WAAW,GAChC,WAAY,EAAO,MAAM,AAC3B,CACF,EAOA,OALA,EAAc,GAAG,CAAC,EAAQ,GAKnB,QACL,EACA,WAAY,EAAO,MAAM,CACzB,UAAW,EAAK,KAAK,CAAC,OAAO,MAAM,AACrC,CACF,CAmBO,eAAe,EAAmB,CAAK,CAAE,EAAU,IAAI,EAK5D,IAAM,EAAY,GAAW,EAAQ,MAAM,CAAG,EAC1C,EAAQ,GAAG,CAAC,IACV,IAAM,EAAO,EAAc,GAAG,CAAC,GAE/B,MAAO,IAAE,OAAI,CAAK,CACpB,GAAG,MAAM,CAAC,GAAK,EAAE,IAAI,EACrB,MAAM,IAAI,CAAC,EAAc,OAAO,IAAI,GAAG,CAAC,CAAC,CAAC,EAAI,EAAK,IAE1C,IAAE,EAAI,OAAK,GAKxB,GAAyB,GAAG,CAAxB,EAAU,MAAM,CAElB,MAAO,EAAE,CAGX,IAAM,EAAa,EAAE,CAErB,IAAK,GAAM,IAAE,CAAE,MAAE,CAAI,CAAE,GAAI,EAAW,CACpC,GAAI,CAAC,GAAQ,CAAC,EAAK,MAAM,EAAI,CAAC,EAAK,MAAM,CAAC,MAAM,CAE9C,CAFgD,QAMlD,IAAM,EAAU,MAAM,EAAe,EAAK,IAAI,CAAE,EAAK,MAAM,CAAE,EAAO,GAEhE,EAAQ,MAAM,CAAG,GAAG,AAEtB,EAAW,IAAI,CAAC,CACd,OAAQ,EACR,SAAU,EAAK,QAAQ,EAAE,kBAAoB,EAAK,QAAQ,EAAE,UAAY,kBACxE,EACA,SAAU,CAAO,CAAC,EAAE,CAAC,KAAK,AAC5B,EAIJ,CAKA,OAAO,EAAW,IAAI,CAAC,CAAC,EAAG,IAAM,EAAE,QAAQ,CAAG,EAAE,QAAQ,CAC1D,CAQO,eAAe,EAA4B,CAAK,CAAE,CAAa,CAAE,EAAsB,EAAE,QAC9F,GAAI,CAAC,GAA0C,GAAG,CAA5B,EAAc,MAAM,CACxC,MAAO,CACL,OAAQ,gJACR,WAAY,EACZ,QAAS,EAAE,AACb,EAIF,IAAM,EAAY,EACf,OAAO,CAAC,GACP,EAAW,OAAO,CAAC,GAAG,CAAC,IAAK,AAAC,CAC3B,GAAG,CAAC,CACJ,SAAU,EAAW,QAAQ,CAC7B,OAAQ,EAAW,MAAM,CAC3B,CAAC,GAEF,IAAI,CAAC,CAAC,EAAG,IAAM,EAAE,KAAK,CAAG,EAAE,KAAK,EAChC,KAAK,CAAC,EAAG,GAEZ,GAAyB,GAAG,CAAxB,EAAU,MAAM,CAClB,MAAO,CACL,OAAQ,0DACR,WAAY,EACZ,QAAS,EAAE,AACb,EAIF,IAAM,EAAe,CAAS,CAAC,EAAE,CAC3B,GAxGoB,EAwGG,EAAa,EAxGV,EAwGf,EAA+B,CAvGzC,EAAc,GAAG,CAAC,IAyGzB,GAA6B,GAAG,CAA5B,EAAc,MAAM,CAEtB,OAAO,MAAM,EAAe,EAAO,EAAW,EAAS,IAAI,CAAE,EAAqB,EAAS,QAAQ,EAAI,CAAC,EACnG,EAEL,IAAM,EAAa,KAAK,GAAG,CAAsB,GAArB,EAAa,KAAK,CAAO,GAErD,GAAI,CAEF,IAAM,EAAkB,EACrB,GAAG,CAAC,CAAC,EAAO,IAAQ,CAAC,aAAa,EAAE,EAAM,QAAQ,CAAC,YAAY,EAAE,EAAM,EAAE;AAAG,EAAE,EAAM,IAAI,CAAA,CAAE,EAC1F,IAAI,CAAC,eAGJ,EAAiB,EACjB,IAAuB,EAAoB,IAAI,IAAI,CACrD,EAAiB,CAAC;AAAA;AAAA;AAC1B,EAAE,oBAAoB;;uGAEgF,AAAC,EAGjG,IAAM,EAAW,CACf,CACE,KAAM,SACN,QAAS,CAAC;;;;;;;;;;;;;oCAagB,CAAC,AAC7B,EACA,CACE,KAAM,OACN,QAAS,CAAC,kCAAkC,EAAE,EAAc,MAAM,CAAC;;;AAG7E,EAAE,EAAA,EAAkB,eAAe;;;AAGnC,EAAE,MAAM;;;;;;;yFAO8E,CAAC,AAC/E,EACD,CAEG,EAAS,MAAM,CAAA,EAAA,EAAA,cAAc,AAAd,EAAe,EAAU,CAC1C,MAAO,cACP,YAAa,GACb,WAAY,KACZ,MAAO,GACP,kBAAmB,GACnB,iBAAkB,EACpB,GAGA,GAFA,CAEI,CAFK,EAAO,IAAI,GACL,yBAAyB,IAAI,CAAC,IAAW,EAAO,MAAM,CAAG,IAC5D,CACV,IAAM,EAAa,EAAU,KAAK,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,EAAE,EAAE,EAAE,QAAQ,CAAC,QAAQ,EAAE,EAAE,KAAK,CAAC,OAAO,CAAC,GAAG,GAAG,EAAE,EAAE,IAAI,CAAC,SAAS,CAAC,EAAE,KAAK,OAAO,CAAC,OAAO,KAAA,EAAO,EAAE,IAAI,CAAC,MAAM,CAAC,IAAI,MAAM,GAAA,CAAI,EAAE,IAAI,CAAC,MACtL,EAAS,CAAC;;;AAEN,EAAE,WAAW;;2GAE4E,CAAC,AAChG,CACA,MAAO,CACL,SACA,aACA,QAAS,EAAU,KAAK,CAAC,EAAG,GAAG,GAAG,CAAC,IAAM,AAAD,CACtC,SAAU,EAAE,QAAQ,CACpB,KAAM,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAO,MACjC,MAAO,EAAE,KAAK,CAAC,OAAO,CAAC,EACzB,CAAC,EACH,CACF,CAAE,MAAO,EAAO,CACd,QAAQ,KAAK,CAAC,sEAAuE,GAErF,IAAI,EAAS,CAAC,cAAc,EAAE,EAAc,MAAM,CAAC;AAAA;AAAwB,CAAC,CAG5E,GAFA,GAAU,CAAC,iBAAiB,EAAE,EAAa,QAAQ,CAAC;AAAM,EAAE,EAAa,IAAI,CAAC;AAAA;AAAI,CAAC,CAE/E,EAAU,MAAM,CAAG,EAAG,CACxB,IAAM,EAAY,EAAU,KAAK,CAAC,EAAG,GAAG,MAAM,CAAC,GAAK,EAAE,MAAM,GAAK,EAAa,MAAM,EAChF,EAAU,MAAM,CAAG,GAAG,CACxB,GAAU,CAAC;AAAgD,CAAC,CAC5D,EAAU,OAAO,CAAC,CAAC,EAAO,KACxB,GAAU,CAAC;AAAA,CAAG,EAAE,EAAM,EAAE,MAAM,EAAE,EAAM,QAAQ,CAAC;AAAI,EAAE,EAAM,IAAI,CAAC,SAAS,CAAC,EAAG,KAAK;AAAK,CACzF,AAD0F,GAG9F,CAEA,IAAM,EAAa,KAAK,GAAG,CAAsB,GAArB,EAAa,KAAK,CAAO,GAErD,MAAO,CACL,OAAQ,EAAO,IAAI,cACnB,EACA,QAAS,EAAU,KAAK,CAAC,EAAG,GAAG,GAAG,CAAC,IAAM,AAAD,CACtC,SAAU,EAAE,QAAQ,CACpB,KAAM,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAO,MACjC,MAAO,EAAE,KAAK,CAAC,OAAO,CAAC,GACzB,CAAC,CACH,CACF,CACF,CACF,CAeO,SAAS,IACd,IAAM,EAAY,MAAM,IAAI,CAAC,EAAc,MAAM,IAEjD,MAAO,CACL,eAAgB,EAAc,IAAI,CAClC,WAAY,EAAU,MAAM,CAAC,CAAC,EAAK,IAAQ,GAAO,EAAI,CAAL,GAAS,CAAC,KAAK,CAAC,OAAO,MAAM,GAAI,CAAC,CAAG,GACtF,YAAa,EAAU,MAAM,CAAC,CAAC,EAAK,IAAQ,GAAO,EAAI,CAAL,KAAW,EAAE,SAAU,CAAC,CAAG,GAC7E,UAAW,MAAM,IAAI,CAAC,EAAc,OAAO,IAAI,GAAG,CAAC,CAAC,CAAC,EAAQ,EAAI,GAAK,AAAC,SACrE,EACA,MAAO,MAAM,IAAI,CAAC,EAAc,IAAI,IAAI,OAAO,CAAC,GAChD,SAAU,EAAI,QAAQ,EAAE,UAAY,EAAI,QAAQ,EAAE,kBAAoB,UACtE,UAAW,EAAI,IAAI,CAAC,KAAK,CAAC,OAAO,MAAM,CACvC,WAAY,EAAI,MAAM,EAAE,QAAU,EAClC,SAAU,EAAI,QAAQ,EAAE,SAC1B,CAAC,CACH,CACF,6MCjwBA,IAAA,EAAA,EAAA,CAAA,CAAA,iBAEe,eAAe,EAAQ,CAAG,CAAE,CAAG,EAE5C,GAAmB,YAAf,EAAI,MAAM,CAAgB,CAC5B,EAAI,SAAS,CAAC,8BAA+B,KAC7C,EAAI,SAAS,CAAC,+BAAgC,iBAC9C,EAAI,SAAS,CAAC,+BAAgC,gBAC9C,EAAI,MAAM,CAAC,KAAK,GAAG,GACnB,MACF,CAEA,GAAI,AAAe,QAAQ,GAAnB,MAAM,CACZ,OAAO,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAAE,MAAO,oBAAqB,GAG5D,GAAI,CACF,GAAM,SAAE,CAAO,SAAE,EAAU,EAAE,qBAAE,EAAsB,EAAE,CAAE,CAAG,EAAI,IAAI,CAEpE,GAAI,CAAC,GAAW,CAAC,EAAQ,IAAI,GAC3B,CAD+B,MACxB,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAC1B,MAAO,sBACP,QAAS,oCACX,GAMF,IAAM,EAAQ,CAAA,EAAA,EAAA,gBAAA,AAAgB,IASxB,EAAgB,GAAW,MAAM,OAAO,CAAC,IAAY,EAAQ,MAAM,CAAG,EACxE,EAAQ,MAAM,CAAC,GAAM,GAAoB,UAAd,OAAO,GAClC,KAKJ,CALU,EAKmB,IAAzB,EAAM,cAAc,CAAQ,CAE9B,IAAM,EAAe,EAAQ,IAPe,OAOJ,GAGpC,EAAkB,GActB,OAXE,EADE,EAAa,QAAQ,CAAC,kBAAoB,EAAa,QAAQ,CAAC,YAChD,CAD6D,gcAEtE,EAAa,QAAQ,CAAC,YAAc,EAAa,QAAQ,CAAC,UACjD,CAD4D,2PAErE,EAAa,QAAQ,CAAC,mBAAqB,EAAa,QAAQ,CAAC,YACxD,CADqE,8aAE9E,EAAa,QAAQ,CAAC,SAAW,EAAa,QAAQ,CAAC,UAAY,EAAa,QAAQ,CAAC,MAChF,CADuF,oWAGvF,CAAC,+BAA+B,EAAE,EAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,8CAAmS,CAAC,CAG3V,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAC1B,SAAS,EACT,QAAS,EACT,UAAW,IAAI,OAAO,WAAW,GACjC,YAAa,GACb,OACF,EACF,CAIA,IAAM,EAAgB,MAAM,CAAA,EAAA,EAAA,kBAAA,AAAkB,EAAC,EAAS,GAYxD,GATI,EAAc,MAAM,CASpB,AAAyB,EATF,CASK,EATF,CASZ,MAAM,CAGtB,OAAO,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAC1B,SAAS,EACT,QAAS,CAAC,gFAAgF,EAAE,EAAQ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,wBAAgN,EAAE,EAAM,cAAc,CAAC;AAAA,oBAAsB,EAAE,EAAM,WAAW,CAAA,CAAE,CACtX,UAAW,IAAI,OAAO,WAAW,GACjC,WAAW,QACX,CACF,GAIF,IAAM,EAAsB,EACzB,MAAM,CAAC,GAAK,EAAE,IAAI,EAAI,EAAE,OAAO,EAC/B,KAAK,CAAC,CAAC,GACP,GAAG,CAAC,GAAK,CAAA,EAAc,SAAX,EAAE,IAAI,CAAc,SAAW,aAAa,EAAE,EAAE,EAAE,OAAO,CAAA,CAAE,EACvE,IAAI,CAAC,QAKF,EAAS,MAAM,CAAA,EAAA,EAAA,2BAAA,AAA2B,EAAC,EAAS,EAAe,GASrE,EAAkB,EAAO,MAAM,CAenC,OAZI,EAAO,OAAO,EAAI,EAAO,OAAO,CAAC,MAAM,CAAG,GAAG,CAC/C,GAAmB,CAAC;AAAA;AAAA;AAAA;AAAoC,CAAC,CACzD,EAAO,OAAO,CAAC,OAAO,CAAC,CAAC,EAAQ,KAC9B,IAAM,EAAQ,WAAW,EAAO,KAAK,EAC/B,EAAa,CAAS,IAAR,CAAQ,CAAG,CAAE,OAAO,CAAC,GACzC,GAAmB,CAAC,CAAC,EAAE,EAAO,QAAQ,CAAC,cAAc,EAAE,EAAW;AAAI,CAAC,AACzE,IAIF,GAAmB,CAAC;AAAA;AAAA,iBAAqB,EAAE,EAAM,cAAc,CAAC,SAAS,EAAE,EAAM,cAAc,CAAG,EAAI,IAAM,IAAI,KAAK,EAAE,EAAM,WAAW,CAAC,gBAAgB,CAAC,CAEnJ,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAC1B,SAAS,EACT,QAAS,EACT,UAAW,IAAI,OAAO,WAAW,GACjC,WAAY,EAAO,UAAU,CAC7B,QAAS,EAAO,OAAO,EAAI,EAAE,CAC7B,cAAe,EAAc,GAAG,CAAC,GAAM,CAAD,CACpC,OAAQ,EAAE,MAAM,CAChB,SAAU,EAAE,QAAQ,CACpB,SAAU,EAAE,QAAQ,CACtB,CAAC,QACD,CACF,EACF,CAAE,MAAO,EAAO,CAGd,OAFA,QAAQ,KAAK,CAAC,kBAAmB,GAE1B,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAC1B,MAAO,gCACP,QAAS,EAAM,OAAO,CACtB,UAAW,IAAI,OAAO,WAAW,EACnC,EACF,CACF,uGCzJA,IAAA,EAA0B,EAAwB,CAAzCA,AAAyC,CAAA,CAAA,OAAhC,AAClB,EAA0B,EAAyB,CAA1CC,AAA0C,CAAA,EAAA,AADzB,MACR,AAElB,EAAoC,EAAA,CAA3BC,AAA2B,CAAA,EAFV,MAI1B,EAAiC,EAAA,CAAxBC,AAAwB,CAAA,IAFL,AAEd,GAF4E,CAK1F,EAAwC,EALJ,AAEd,AAGkB,CAAA,CAAA,EAA5BC,MACZ,EAAoC,AAJH,EAIG,CAA3BC,AAA2B,CAA+B,EADzC,IAE1B,EADkB,AACa,EADXC,AAC6C,CAAxDC,AAAwD,CAAA,KAFzB,CACZ,EAG5B,EAA+B,EAA2B,CAFnC,AAEdC,AAAiD,CAHtB,AAGsB,EAFO,KAAlC,EAE2B,IAAnC,QAAQ,8BAGhBL,EAAAA,KAAAA,EAAMC,EAAU,WAAU,AAG5BK,EAAAA,CAAAA,EAASN,EAAAA,KAAAA,EAAMC,EAAU,UAAS,AAGzCM,EAAc,IAAIR,EAAAA,mBAAAA,CAAoB,CAC1CS,WAAY,CACVC,KAAMX,EAAAA,SAAAA,CAAUY,SAAS,CACzBC,KAAM,oBACNC,SAAU,oBAEVC,WAAY,GACZC,SAAU,EACZ,WACAb,EACAc,QAAqBG,CAAZF,EAAoC,MAA5BC,GAAG,CAACC,CACrBC,IADiD,eACc,CAA3CH,CACtB,GAEO,IAHuBC,GAAG,CAACG,OAGZC,EACpBC,CAAoB,CACpBC,CAAmB,CACnBC,CAEC,EAEGjB,EAAYkB,KAAK,EAAE,EAVoC,CAWzDpB,EAAAA,cAAAA,EAAeiB,EAAK,+BAAgCN,QAAQU,MAAM,CAACC,MAAM,IAE3E,IAAIC,EAAU,oBAMZA,EAAUA,EAAQE,OAAO,CAAC,WAAY,KAAO,IAG/C,IAAMC,EAAgB,MAAMxB,EAAYyB,OAAO,CAACV,EAAKC,EAAK,SAAEK,CAAQ,GAEpE,GAAI,CAACG,EAAe,CAClBR,EAAIU,UAAU,CAAG,IACjBV,EAAIW,GAAG,CAAC,eACK,MAAbV,CAAa,CAATW,IAAS,KAAA,EAAbX,EAAIW,SAAS,CAAA,IAAA,CAAbX,EAAgBY,QAAQC,OAAO,IAC/B,MACF,CAEA,GAAM,OAAEC,CAAK,QAAEC,CAAM,mBAAEC,CAAiB,qBAAEC,CAAmB,CAAE,CAC7DV,EAEF,GAAI,CACF,IAAMW,EAASpB,EAAIoB,MAAM,EAAI,MACvBC,EAAAA,CAAAA,EAASzC,EAAAA,SAAAA,IAET0C,EAAaD,EAAOE,kBAAkB,GACtCC,EACJvC,EAAYwC,6BAA6B,CAACC,IAAI,CAACzC,GAE3C0C,EAAoB,MAAOC,GAC/B3C,EACG4C,MAAM,CAAC7B,EAAKC,EAAK,CAChBe,MAAO,CACL,GAAGA,CAAK,CACR,GAAGC,CAAM,AACX,SACAA,EACAa,2BAAAA,CACGC,CAD0BrC,CAC1BqC,CACHC,MAFqCrC,GAAG,AACJ,CAAjCoC,SACqCG,CAApBD,AAAoBC,EACxCC,KADoE,CAAxCzC,QAAQC,CACpCwC,CACGC,CAAAA,AADc1C,AADsB,CAACwC,CAKxCG,CAH2B,KADF1C,GAAG,CACzByC,GAGWlB,EAAkBoB,OAAO,CACvCC,gBAAgB,EAChBC,IAAKvD,EAAYkB,KAAK,CACtBd,KAAM,oBAENoD,kBAAkB,CAAEtB,QAAAA,KAAAA,EAAAA,EAAqBuB,UAAU,CAEnDC,QAAS,CAAC,GAAGC,IACXpB,EAAexB,KAAQ4C,EAC3B,GACCC,OAAO,CAAC,KACP,GAAI,CAACjB,EAAM,OAEXA,EAAKkB,aAAa,CAAC,CACjB,mBAAoB7C,EAAIU,UAAU,CAClC,YAAY,CACd,GAEA,IAAMoC,EAAqB1B,EAAO2B,qBAAqB,GAEvD,GAAI,CAACD,EACH,OAGF,GACEA,EAAmBE,GAAG,CAAC,EALA,kBAMvBnE,EAAAA,cAAAA,CAAeoE,aAAa,CAC5B,YACAC,QAAQC,IAAI,CACV,CAAC,2BAA2B,EAAEL,EAAmBE,GAAG,CAClD,kBACA,qEAAqE,CAAC,EAK5E,IAAMI,EAAQN,EAAmBE,GAAG,CAAC,cACrC,GAAII,EAAO,CACT,IAAMC,EAAO,CAAA,EAAGlC,EAAO,CAAC,EAAEiC,EAAAA,CAAO,CAEjCzB,EAAKkB,aAAa,CAAC,CACjB,aAAcO,EACd,aAAcA,EACd,iBAAkBC,CACpB,GACA1B,EAAK2B,UAAU,CAACD,EAClB,MACE1B,CADK,CACA2B,UAAU,CAAC,CAAA,EAAGnC,EAAO,CAAC,EAAEd,EAAAA,CAAS,CAE1C,GAIAgB,EACF,MAAMK,EAAkBL,EADV,CAGd,MAAMD,EAAOmC,qBAAqB,CAACxD,EAAIyD,OAAO,CAAE,IAC9CpC,EAAOqC,KAAK,CACV5E,EAAAA,cAAAA,CAAeoE,aAAa,CAC5B,CACES,SAAU,CAAA,EAAGvC,EAAO,CAAC,EAAEd,EAAAA,CAAS,CAChCnB,KAAMN,EAAAA,QAAAA,CAAS+E,MAAM,CACrBC,WAAY,CACV,cAAezC,EACf,cAAepB,EAAI8D,GAAG,AACxB,CACF,EACAnC,GAIR,CAAE,MAAOoC,EAAK,CAEZ,GAAI9E,EAAYkB,KAAK,CACnB,CADqB,KACf4D,KAIRxF,EAAAA,SAAAA,EAAU0B,EAAwB,IAAK,wBACzC,QAAU,CAIK,MAAbC,CAAa,CAATW,IAAS,KAAA,EAAbX,EAAIW,SAAS,CAAA,IAAA,CAAbX,EAAgBY,QAAQC,OAAO,GACjC,CACF","ignoreList":[3]}