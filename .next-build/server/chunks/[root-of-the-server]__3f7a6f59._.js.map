{"version":3,"sources":["../../../lib/openai.js","../../../lib/documentAI.js","../../../pages/api/chat/upload-document.js","../../../node_modules/next/src/build/templates/pages-api.ts"],"sourcesContent":["// OpenAI API integration with official SDK\r\nimport OpenAI from 'openai';\r\n\r\nconst openai = new OpenAI({\r\n  apiKey: process.env.OPENAI_API_KEY,\r\n});\r\n\r\n// Generate embeddings for text\r\nexport async function generateEmbedding(text) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const response = await openai.embeddings.create({\r\n      model: 'text-embedding-3-small',\r\n      input: text.substring(0, 8000), // Limit input size\r\n    });\r\n\r\n    return response.data[0].embedding;\r\n  } catch (error) {\r\n    console.error('Error generating embedding:', error);\r\n    throw new Error(`Failed to generate embedding: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Generate embeddings in batch for an array of texts\r\nexport async function generateEmbeddingsBatch(texts) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  if (!Array.isArray(texts) || texts.length === 0) return [];\r\n\r\n  try {\r\n    const response = await openai.embeddings.create({\r\n      model: 'text-embedding-3-small',\r\n      input: texts.map(t => (t || '').toString().substring(0, 8000)),\r\n    });\r\n\r\n    return response.data.map(d => d.embedding);\r\n  } catch (error) {\r\n    console.error('Error generating batch embeddings:', error);\r\n    throw new Error(`Failed to generate batch embeddings: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Chat completion using OpenAI GPT models\r\nexport async function chatCompletion(messages, options = {}) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const response = await openai.chat.completions.create({\r\n      model: options.model || 'gpt-4o-mini', // Fast and affordable\r\n      messages: messages,\r\n      temperature: options.temperature || 0.7,\r\n      max_tokens: options.max_tokens || 1000,\r\n      top_p: options.top_p || 1,\r\n      frequency_penalty: options.frequency_penalty || 0,\r\n      presence_penalty: options.presence_penalty || 0,\r\n    });\r\n\r\n    return response.choices[0].message.content;\r\n  } catch (error) {\r\n    console.error('Error in chat completion:', error);\r\n    \r\n    // Handle specific OpenAI errors\r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 500) {\r\n      throw new Error('Errore del server OpenAI. Riprova più tardi.');\r\n    }\r\n    \r\n    throw new Error(`Errore nella comunicazione con OpenAI: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Generate summary\r\nexport async function generateSummary(text, maxLength = 200) {\r\n  const messages = [\r\n    {\r\n      role: 'system',\r\n      content: 'You are a helpful assistant that creates concise summaries.',\r\n    },\r\n    {\r\n      role: 'user',\r\n      content: `Summarize the following text in ${maxLength} words or less:\\n\\n${text}`,\r\n    },\r\n  ];\r\n\r\n  return await chatCompletion(messages, { temperature: 0.5, max_tokens: 300 });\r\n}\r\n\r\n// Generate tags\r\nexport async function generateTags(text, count = 5) {\r\n  const messages = [\r\n    {\r\n      role: 'system',\r\n      content: 'You are a helpful assistant that generates relevant tags for documents. Return only comma-separated tags, no explanations.',\r\n    },\r\n    {\r\n      role: 'user',\r\n      content: `Generate ${count} relevant tags for this document:\\n\\n${text.substring(0, 2000)}`,\r\n    },\r\n  ];\r\n\r\n  const response = await chatCompletion(messages, { temperature: 0.3, max_tokens: 100 });\r\n  \r\n  return response\r\n    .split(',')\r\n    .map(tag => tag.trim().toLowerCase())\r\n    .filter(tag => tag.length > 0)\r\n    .slice(0, count);\r\n}\r\n\r\n// Classify document\r\nexport async function classifyDocument(text) {\r\n  const categories = [\r\n    'contract', 'invoice', 'report', 'presentation', \r\n    'spreadsheet', 'image', 'code', 'email', 'article', 'other'\r\n  ];\r\n\r\n  const messages = [\r\n    {\r\n      role: 'system',\r\n      content: `You are a document classifier. Classify the document into one or more of these categories: ${categories.join(', ')}. Return only category names, comma-separated.`,\r\n    },\r\n    {\r\n      role: 'user',\r\n      content: `Classify this document:\\n\\n${text.substring(0, 1000)}`,\r\n    },\r\n  ];\r\n\r\n  const response = await chatCompletion(messages, { temperature: 0.2, max_tokens: 50 });\r\n  \r\n  return response\r\n    .split(',')\r\n    .map(cat => cat.trim().toLowerCase())\r\n    .filter(cat => categories.includes(cat));\r\n}\r\n\r\n// Vision API - Analizza immagini come ChatGPT\r\nexport async function analyzeImageWithVision(imageBuffer, imageMimeType, query = 'Cosa contiene questa immagine? Descrivi tutto ciò che vedi.') {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    // Converti il buffer in base64\r\n    const base64Image = imageBuffer.toString('base64');\r\n    \r\n    const response = await openai.chat.completions.create({\r\n      model: 'gpt-4o', // GPT-4o supporta vision\r\n      messages: [\r\n        {\r\n          role: 'system',\r\n          content: 'Sei un assistente AI esperto nell\\'analisi di immagini. Descrivi in dettaglio tutto ciò che vedi nell\\'immagine, inclusi testo, oggetti, persone, scene, colori e qualsiasi altro dettaglio rilevante. Rispondi sempre in italiano.'\r\n        },\r\n        {\r\n          role: 'user',\r\n          content: [\r\n            {\r\n              type: 'text',\r\n              text: query\r\n            },\r\n            {\r\n              type: 'image_url',\r\n              image_url: {\r\n                url: `data:${imageMimeType};base64,${base64Image}`,\r\n                detail: 'high'\r\n              }\r\n            }\r\n          ]\r\n        }\r\n      ],\r\n      max_tokens: 2000,\r\n      temperature: 0.2\r\n    });\r\n\r\n    return response.choices[0].message.content;\r\n  } catch (error) {\r\n    console.error('Error in vision API:', error);\r\n    \r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 400 && error.message?.includes('image')) {\r\n      throw new Error('Formato immagine non supportato o immagine troppo grande.');\r\n    }\r\n    \r\n    throw new Error(`Errore nell'analisi dell'immagine: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Estrazione testo da PDF con OpenAI Responses API (gpt-4o) usando input_file\r\n// Ritorna SOLO la stringa di testo estratto (no IDs, no oggetti)\r\nexport async function extractTextFromPdfWithOpenAI(filePath) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  const fs = await import('fs');\r\n  \r\n  let uploadedFile = null;\r\n  try {\r\n    console.log('Caricamento PDF su OpenAI (Responses API):', filePath);\r\n    \r\n    // 1) Carica il file su OpenAI come user_data\r\n    uploadedFile = await openai.files.create({\r\n      file: fs.createReadStream(filePath),\r\n      purpose: 'user_data'\r\n    });\r\n\r\n    console.log('File caricato su OpenAI:', uploadedFile.id);\r\n\r\n    // 2) Richiesta al modello GPT-4o per estrazione testo dal file caricato\r\n    const response = await openai.responses.create({\r\n      model: 'gpt-4o',\r\n      input: [\r\n        {\r\n          role: 'user',\r\n          content: [\r\n            { type: 'input_text', text: 'Estrai tutto il testo e le informazioni rilevanti da questo documento. Rispondi SOLO con il testo estratto, senza commenti.' },\r\n            { type: 'input_file', file_id: uploadedFile.id }\r\n          ]\r\n        }\r\n      ],\r\n      max_output_tokens: 8000,\r\n      temperature: 0.1\r\n    });\r\n\r\n    // 3) Prendi solo testo\r\n    const extractedText = (response.output_text || '').toString().trim();\r\n    console.log(`Testo estratto da PDF: ${extractedText.length} caratteri`);\r\n    \r\n    if (!extractedText) {\r\n      throw new Error('Nessun testo estratto dal PDF');\r\n    }\r\n\r\n    return extractedText;\r\n\r\n  } catch (error) {\r\n    console.error('Error in PDF text extraction (Responses API):', error);\r\n    \r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 400) {\r\n      throw new Error('Errore nell\\'analisi del PDF con Responses API. Il file potrebbe essere troppo grande o danneggiato.');\r\n    }\r\n    \r\n    throw new Error(`Errore nell'estrazione del testo PDF: ${error.message}`);\r\n  } finally {\r\n    // 4) Prova a rimuovere il file caricato (se l'SDK lo supporta)\r\n    try {\r\n      if (uploadedFile && uploadedFile.id) {\r\n        if (openai.files?.delete) {\r\n          await openai.files.delete(uploadedFile.id);\r\n        } else if (openai.files?.del) {\r\n          await openai.files.del(uploadedFile.id);\r\n        }\r\n        console.log('File rimosso da OpenAI:', uploadedFile.id);\r\n      }\r\n    } catch (delError) {\r\n      console.warn('Errore rimozione file da OpenAI (ignorato):', delError?.message || delError);\r\n    }\r\n  }\r\n}\r\n\r\n// DALL-E 3 - Get image URL only (faster, for streaming)\r\nexport async function getImageUrlFromDALLE(prompt, options = {}) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const size = options.size || '1024x1024';\r\n    const quality = options.quality || 'standard';\r\n    const style = options.style || 'vivid';\r\n\r\n    const response = await openai.images.generate({\r\n      model: 'dall-e-3',\r\n      prompt: prompt,\r\n      size: size,\r\n      quality: quality,\r\n      style: style,\r\n      n: 1,\r\n    });\r\n\r\n    const imageUrl = response.data[0]?.url;\r\n    if (!imageUrl) {\r\n      throw new Error('Nessuna immagine generata da DALL-E');\r\n    }\r\n\r\n    return imageUrl;\r\n  } catch (error) {\r\n    console.error('Error getting image URL from DALL-E:', error);\r\n    console.error('Error details:', {\r\n      status: error.status,\r\n      statusText: error.statusText,\r\n      message: error.message,\r\n      code: error.code,\r\n      response: error.response?.data || error.response\r\n    });\r\n    \r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 400) {\r\n      const errorMessage = error.message || error.response?.data?.error?.message || 'Prompt non valido o contenuto non consentito';\r\n      throw new Error(`Errore nella generazione: ${errorMessage}`);\r\n    } else if (error.code === 'ENOTFOUND' || error.code === 'ECONNREFUSED') {\r\n      throw new Error('Errore di connessione con OpenAI. Verifica la tua connessione internet.');\r\n    }\r\n    \r\n    throw new Error(`Errore nella generazione dell'immagine: ${error.message || 'Errore sconosciuto'}`);\r\n  }\r\n}\r\n\r\n// DALL-E 3 - Generazione immagini (download completo, per backward compatibility)\r\nexport async function generateImageWithDALLE(prompt, options = {}) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const imageUrl = await getImageUrlFromDALLE(prompt, options);\r\n\r\n    // Download the image and return as buffer\r\n    const imageResponse = await fetch(imageUrl);\r\n    if (!imageResponse.ok) {\r\n      const errorText = await imageResponse.text().catch(() => 'Unknown error');\r\n      throw new Error(`Errore nel download dell'immagine generata: ${imageResponse.status} ${imageResponse.statusText}. ${errorText}`);\r\n    }\r\n\r\n    const arrayBuffer = await imageResponse.arrayBuffer();\r\n    return Buffer.from(arrayBuffer);\r\n  } catch (error) {\r\n    // Re-throw errors from getImageUrlFromDALLE\r\n    throw error;\r\n  }\r\n}\r\n\r\n// DALL-E 3 - Upscale/Miglioramento immagine usando variante\r\nexport async function upscaleImageWithDALLE(imageBuffer, imageMimeType, enhancementPrompt = null) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    // 1. Analizza l'immagine con Vision API per creare un prompt descrittivo\r\n    const analysisPrompt = enhancementPrompt || 'Descrivi in dettaglio questa immagine, includendo tutti i dettagli visivi, colori, composizione, stile e qualità. La descrizione sarà usata per creare una versione migliorata ad alta risoluzione.';\r\n    \r\n    const imageDescription = await analyzeImageWithVision(\r\n      imageBuffer, \r\n      imageMimeType, \r\n      analysisPrompt\r\n    );\r\n\r\n    // 2. Crea un prompt per DALL-E che migliora l'immagine\r\n    const enhancementPromptText = `Crea una versione migliorata e ad alta risoluzione di questa immagine: ${imageDescription}. Mantieni fedeltà ai dettagli originali ma migliora la qualità, la nitidezza e la risoluzione.`;\r\n\r\n    // 3. Genera immagine migliorata con DALL-E 3 in alta risoluzione\r\n    const enhancedImageBuffer = await generateImageWithDALLE(enhancementPromptText, {\r\n      size: '1792x1024', // Formato landscape per alta risoluzione\r\n      quality: 'hd',\r\n      style: 'natural'\r\n    });\r\n\r\n    return enhancedImageBuffer;\r\n  } catch (error) {\r\n    console.error('Error upscaling image with DALL-E:', error);\r\n    throw new Error(`Errore nel miglioramento dell'immagine: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Enhance existing image quality using AI analysis + sharp processing\r\nexport async function enhanceImageQualityWithAI(imageBuffer, imageMimeType) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    // Use Vision API to analyze image quality issues\r\n    const analysisPrompt = `Analyze this image and identify specific quality issues that need improvement. Focus on:\r\n1. Noise level (low/medium/high)\r\n2. Sharpness (blurry/sharp)\r\n3. Color accuracy (washed out/vibrant)\r\n4. Artifacts (compression artifacts, pixelation)\r\n5. Overall quality issues\r\n\r\nRespond with a JSON object: {\"noise\": \"low|medium|high\", \"sharpness\": \"blurry|moderate|sharp\", \"color\": \"washed|normal|vibrant\", \"artifacts\": \"none|minor|major\", \"recommendations\": \"brief description\"}`;\r\n    \r\n    const analysisResult = await analyzeImageWithVision(\r\n      imageBuffer, \r\n      imageMimeType, \r\n      analysisPrompt\r\n    );\r\n\r\n    // Parse analysis result\r\n    let analysis = {\r\n      noise: 'medium',\r\n      sharpness: 'moderate',\r\n      color: 'normal',\r\n      artifacts: 'none'\r\n    };\r\n\r\n    try {\r\n      // Try to parse JSON from analysis\r\n      const jsonMatch = analysisResult.match(/\\{[\\s\\S]*\\}/);\r\n      if (jsonMatch) {\r\n        const parsed = JSON.parse(jsonMatch[0]);\r\n        analysis = { ...analysis, ...parsed };\r\n      }\r\n    } catch (parseError) {\r\n      console.warn('Could not parse AI analysis, using defaults');\r\n    }\r\n\r\n    // Apply targeted enhancements using sharp based on AI analysis\r\n    const sharp = (await import('sharp')).default;\r\n    let enhanced = sharp(imageBuffer, { sequentialRead: true });\r\n\r\n    // Apply denoising if needed\r\n    if (analysis.noise === 'high' || analysis.noise === 'medium') {\r\n      enhanced = enhanced.median(analysis.noise === 'high' ? 3 : 2);\r\n    }\r\n\r\n    // Apply sharpening based on analysis\r\n    if (analysis.sharpness === 'blurry') {\r\n      enhanced = enhanced.sharpen({\r\n        sigma: 2.0,\r\n        m1: 1.0,\r\n        m2: 0.5,\r\n        x1: 3,\r\n        y2: 3,\r\n        y3: 3\r\n      });\r\n    } else if (analysis.sharpness === 'moderate') {\r\n      enhanced = enhanced.sharpen({\r\n        sigma: 1.0,\r\n        m1: 0.7,\r\n        m2: 0.4\r\n      });\r\n    }\r\n\r\n    // Enhance color if needed\r\n    if (analysis.color === 'washed') {\r\n      enhanced = enhanced.modulate({\r\n        saturation: 1.15,\r\n        brightness: 1.05\r\n      }).linear(1.05, -(128 * 0.05)); // Slight contrast boost\r\n    }\r\n\r\n    // Remove compression artifacts\r\n    if (analysis.artifacts === 'major' || analysis.artifacts === 'minor') {\r\n      enhanced = enhanced.png({\r\n        quality: 100,\r\n        compressionLevel: 6,\r\n        adaptiveFiltering: true\r\n      });\r\n    } else {\r\n      // Keep original format but with high quality\r\n      if (imageMimeType === 'image/jpeg' || imageMimeType === 'image/jpg') {\r\n        enhanced = enhanced.jpeg({\r\n          quality: 98,\r\n          mozjpeg: true,\r\n          trellisQuantisation: true,\r\n          overshootDeringing: true\r\n        });\r\n      } else {\r\n        enhanced = enhanced.png({\r\n          quality: 100,\r\n          compressionLevel: 6\r\n        });\r\n      }\r\n    }\r\n\r\n    const enhancedBuffer = await enhanced.toBuffer();\r\n    return enhancedBuffer;\r\n  } catch (error) {\r\n    console.error('Error enhancing image quality with AI:', error);\r\n    // Return original buffer if enhancement fails\r\n    return imageBuffer;\r\n  }\r\n}\r\n","// Sistema AI completo per analisi documenti con OpenAI GPT-4\r\nimport mammoth from 'mammoth';\r\nimport * as XLSX from 'xlsx';\r\nimport { chatCompletion } from './openai.js';\r\n\r\n// pdf-parse ha problemi ESM/CJS con Turbopack, usiamo solo pdfjs-dist\r\n\r\n// Storage in-memory per i documenti caricati (in produzione si può usare database)\r\nconst documentStore = new Map(); // { fileId: { text, chunks, metadata } }\r\n\r\n/**\r\n * Estrae testo da un documento\r\n * @param {Buffer} buffer - Buffer del file\r\n * @param {string} mimeType - Tipo MIME del file\r\n * @param {string} filename - Nome del file\r\n * @param {string} [filepath] - Percorso opzionale del file (utile per OCR)\r\n */\r\nexport async function extractTextFromDocument(buffer, mimeType, filename, filepath = null) {\r\n  try {\r\n    let text = '';\r\n    let metadata = {\r\n      filename,\r\n      mimeType,\r\n      pages: 0,\r\n      wordCount: 0,\r\n    };\r\n\r\n    if (mimeType === 'application/pdf' || filename.toLowerCase().endsWith('.pdf')) {\r\n      // PDF: usa OpenAI file upload + GPT extraction (tutto lato server OpenAI)\r\n      const { extractTextFromPdfWithOpenAI } = await import('./openai.js');\r\n      console.log(`Analizzando PDF con OpenAI file upload: ${filename}`);\r\n      \r\n      // Salva temporaneamente il file per l'upload\r\n      const fs = await import('fs');\r\n      const path = await import('path');\r\n      const os = await import('os');\r\n      \r\n      const tempDir = os.tmpdir();\r\n      const tempFilePath = path.join(tempDir, `temp_${Date.now()}_${filename}`);\r\n      \r\n      try {\r\n        // Scrivi il buffer su file temporaneo\r\n        fs.writeFileSync(tempFilePath, buffer);\r\n        \r\n        // Estrai testo con OpenAI (file upload -> GPT risponde con SOLO testo)\r\n        text = await extractTextFromPdfWithOpenAI(tempFilePath);\r\n        \r\n        // Assicurati che sia una stringa pulita\r\n        text = (text || \"\").toString().trim();\r\n        metadata.analysisMethod = 'openai-file-upload';\r\n        \r\n        if (!text || text.length === 0) {\r\n          throw new Error('Nessun testo estratto dal PDF tramite OpenAI');\r\n        }\r\n        \r\n        console.log(`PDF analizzato con OpenAI: ${text.length} caratteri estratti`);\r\n      } finally {\r\n        // Pulisci file temporaneo\r\n        try {\r\n          if (fs.existsSync(tempFilePath)) {\r\n            fs.unlinkSync(tempFilePath);\r\n          }\r\n        } catch (cleanupError) {\r\n          console.warn('Errore pulizia file temporaneo:', cleanupError);\r\n        }\r\n      }\r\n    }\r\n    else if (mimeType.includes('wordprocessingml') || filename.toLowerCase().endsWith('.docx')) {\r\n      const result = await mammoth.extractRawText({ buffer });\r\n      text = result.value;\r\n      \r\n      // Pulisci il testo\r\n      text = text.replace(/\\s+/g, ' ').trim();\r\n    }\r\n    else if (mimeType.includes('spreadsheet') || filename.toLowerCase().match(/\\.(xlsx|xls|csv)$/i)) {\r\n      const workbook = XLSX.read(buffer, { type: 'buffer' });\r\n      const sheets = workbook.SheetNames;\r\n      \r\n      // Estrai testo da tutte le celle\r\n      const allText = [];\r\n      for (const sheetName of sheets) {\r\n        const sheet = workbook.Sheets[sheetName];\r\n        const sheetData = XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' });\r\n        \r\n        for (const row of sheetData) {\r\n          if (Array.isArray(row)) {\r\n            const rowText = row.filter(cell => cell && cell.toString().trim()).join(' ');\r\n            if (rowText.trim()) {\r\n              allText.push(`[${sheetName}] ${rowText}`);\r\n            }\r\n          }\r\n        }\r\n      }\r\n      \r\n      text = allText.join('\\n');\r\n    }\r\n    else if (mimeType.startsWith('text/') || filename.toLowerCase().endsWith('.txt')) {\r\n      text = buffer.toString('utf-8');\r\n    }\r\n    else if (mimeType.startsWith('image/') || filename.toLowerCase().match(/\\.(png|jpg|jpeg|gif|webp|bmp|tif|tiff|heic|heif)$/i)) {\r\n      // Usa OpenAI Vision API come ChatGPT (più intelligente) + OCR come fallback\r\n      try {\r\n        const { analyzeImageWithVision } = await import('./openai.js');\r\n        console.log(`Analizzando immagine con OpenAI Vision API: ${filename}`);\r\n        \r\n        try {\r\n          // Prova prima con OpenAI Vision API (come ChatGPT)\r\n          const visionText = await analyzeImageWithVision(\r\n            buffer, \r\n            mimeType,\r\n            'Analizza questa immagine in dettaglio. Descrivi tutto ciò che vedi, incluso qualsiasi testo presente, oggetti, persone, scene, colori e dettagli rilevanti. Se c\\'è del testo, trascrivilo accuratamente.'\r\n          );\r\n          \r\n          text = visionText;\r\n          console.log(`Vision API completato: ${text.length} caratteri estratti`);\r\n          \r\n          // Aggiungi metadata per indicare che è stato usato Vision API\r\n          metadata.analysisMethod = 'openai-vision';\r\n        } catch (visionError) {\r\n          console.log('Vision API fallito, provo con OCR:', visionError.message);\r\n          \r\n          // Fallback a OCR tradizionale\r\n          const Tesseract = (await import('tesseract.js')).default;\r\n          const imageSource = filepath || buffer;\r\n          \r\n          try {\r\n            const result = await Tesseract.recognize(imageSource, 'ita+eng', {\r\n              logger: (m) => {\r\n                if (m.status === 'recognizing text') {\r\n                  console.log(`OCR Progress: ${Math.round(m.progress * 100)}%`);\r\n                }\r\n              }\r\n            });\r\n            \r\n            text = result.data.text.trim();\r\n            metadata.analysisMethod = 'ocr-tesseract';\r\n          } catch (ocrError) {\r\n            // Se anche OCR fallisce, prova con createWorker\r\n            console.log('OCR semplice fallito, provo con createWorker:', ocrError.message);\r\n            \r\n            const worker = await Tesseract.createWorker('ita+eng', 1, {\r\n              logger: (m) => {\r\n                if (m.status === 'recognizing text') {\r\n                  console.log(`OCR Progress: ${Math.round(m.progress * 100)}%`);\r\n                }\r\n              }\r\n            });\r\n            \r\n            try {\r\n              const result = await worker.recognize(imageSource);\r\n              text = result.data.text.trim();\r\n              metadata.analysisMethod = 'ocr-tesseract-worker';\r\n            } finally {\r\n              await worker.terminate();\r\n            }\r\n          }\r\n        }\r\n        \r\n        if (!text || text.length === 0) {\r\n          throw new Error('Nessun contenuto estratto dall\\'immagine. L\\'immagine potrebbe essere vuota o non contenere testo leggibile.');\r\n        }\r\n        \r\n        console.log(`Analisi immagine completata: ${text.length} caratteri estratti (metodo: ${metadata.analysisMethod || 'unknown'})`);\r\n      } catch (imageError) {\r\n        console.error('Errore analisi immagine completo:', imageError);\r\n        throw new Error(`Errore nell'analisi dell'immagine: ${imageError.message}`);\r\n      }\r\n    }\r\n    else {\r\n      throw new Error(`Tipo di file non supportato: ${mimeType}`);\r\n    }\r\n\r\n    if (!text || text.trim().length === 0) {\r\n      throw new Error('Nessun testo estratto dal documento');\r\n    }\r\n\r\n    metadata.wordCount = text.split(/\\s+/).length;\r\n\r\n    return { text, metadata };\r\n  } catch (error) {\r\n    console.error('Errore estrazione testo:', error);\r\n    throw new Error(`Errore nell'estrazione del testo: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Divide il testo in chunk intelligenti per la ricerca semantica\r\n * Genera anche embeddings per ogni chunk (ricerca semantica vera)\r\n */\r\nexport async function createTextChunks(text, chunkSize = 1000, overlap = 200) {\r\n  const sentences = text.split(/[.!?]+\\s+/).filter(s => s.trim().length > 10);\r\n  const chunks = [];\r\n  \r\n  let currentChunk = '';\r\n  let currentLength = 0;\r\n\r\n  for (const sentence of sentences) {\r\n    const sentenceLength = sentence.length;\r\n    \r\n    if (currentLength + sentenceLength > chunkSize && currentChunk.trim()) {\r\n      // Salva il chunk corrente\r\n      chunks.push({\r\n        text: currentChunk.trim(),\r\n        startIndex: text.indexOf(currentChunk.trim()),\r\n        endIndex: text.indexOf(currentChunk.trim()) + currentChunk.length,\r\n      });\r\n\r\n      // Crea nuovo chunk con overlap (ultime parole del chunk precedente)\r\n      const words = currentChunk.split(/\\s+/);\r\n      const overlapWords = words.slice(-Math.floor(overlap / 10));\r\n      currentChunk = overlapWords.join(' ') + ' ' + sentence + ' ';\r\n      currentLength = currentChunk.length;\r\n    } else {\r\n      currentChunk += sentence + '. ';\r\n      currentLength += sentenceLength + 2;\r\n    }\r\n  }\r\n\r\n  // Aggiungi l'ultimo chunk\r\n  if (currentChunk.trim()) {\r\n    chunks.push({\r\n      text: currentChunk.trim(),\r\n      startIndex: text.indexOf(currentChunk.trim()),\r\n      endIndex: text.length,\r\n    });\r\n  }\r\n\r\n  const finalChunks = chunks.length > 0 ? chunks : [{ text: text.trim(), startIndex: 0, endIndex: text.length }];\r\n  \r\n  // Genera embeddings per i chunk in batch per ridurre latenza\r\n  const { generateEmbeddingsBatch } = await import('./openai.js');\r\n\r\n  try {\r\n    // Processa in lotti per evitare payload troppo grandi\r\n    const BATCH_SIZE = 16;\r\n    for (let i = 0; i < finalChunks.length; i += BATCH_SIZE) {\r\n      const batch = finalChunks.slice(i, i + BATCH_SIZE);\r\n      const embeddings = await generateEmbeddingsBatch(batch.map(c => c.text));\r\n      embeddings.forEach((emb, idx) => {\r\n        batch[idx].embedding = emb;\r\n      });\r\n    }\r\n  } catch (embError) {\r\n    console.warn('Batch embeddings failed, falling back to per-chunk:', embError.message);\r\n    const { generateEmbedding } = await import('./openai.js');\r\n    for (const chunk of finalChunks) {\r\n      try {\r\n        chunk.embedding = await generateEmbedding(chunk.text);\r\n      } catch (err) {\r\n        console.warn('Errore generazione embedding per chunk:', err.message);\r\n        chunk.embedding = null;\r\n      }\r\n    }\r\n  }\r\n  \r\n  return finalChunks;\r\n}\r\n\r\n/**\r\n * Calcola cosine similarity tra due vettori di embedding\r\n */\r\nfunction cosineSimilarity(vecA, vecB) {\r\n  if (!vecA || !vecB || vecA.length !== vecB.length) return 0;\r\n  \r\n  const dot = vecA.reduce((sum, val, i) => sum + val * vecB[i], 0);\r\n  const magA = Math.sqrt(vecA.reduce((sum, val) => sum + val * val, 0));\r\n  const magB = Math.sqrt(vecB.reduce((sum, val) => sum + val * val, 0));\r\n  \r\n  return dot / (magA * magB);\r\n}\r\n\r\n/**\r\n * Calcola TF-IDF per ricerca semantica semplice (fallback se embedding non disponibile)\r\n */\r\nfunction calculateTFIDF(text, query) {\r\n  const textWords = text.toLowerCase().split(/\\W+/).filter(w => w.length > 2);\r\n  const queryWords = query.toLowerCase().split(/\\W+/).filter(w => w.length > 2);\r\n  \r\n  if (queryWords.length === 0) return 0;\r\n\r\n  let score = 0;\r\n  const textWordCount = {};\r\n  textWords.forEach(word => {\r\n    textWordCount[word] = (textWordCount[word] || 0) + 1;\r\n  });\r\n\r\n  queryWords.forEach(queryWord => {\r\n    const wordCount = textWordCount[queryWord] || 0;\r\n    if (wordCount > 0) {\r\n      // TF: frequenza del termine nel documento\r\n      const tf = wordCount / textWords.length;\r\n      // IDF: inversa della frequenza (più raro = più importante)\r\n      const idf = Math.log(textWords.length / (wordCount + 1)) + 1;\r\n      score += tf * idf;\r\n    }\r\n  });\r\n\r\n  return score / queryWords.length;\r\n}\r\n\r\n/**\r\n * Ricerca semantica nel documento usando embeddings (cosine similarity)\r\n * Fallback a TF-IDF se embeddings non disponibili\r\n */\r\nexport async function semanticSearch(documentText, chunks, query, topK = 5) {\r\n  if (!chunks || chunks.length === 0) {\r\n    return [];\r\n  }\r\n\r\n  // Genera embedding per la query\r\n  const { generateEmbedding } = await import('./openai.js');\r\n  let queryEmbedding = null;\r\n  \r\n  try {\r\n    queryEmbedding = await generateEmbedding(query);\r\n  } catch (embError) {\r\n    console.warn('Errore generazione embedding query, uso TF-IDF:', embError);\r\n  }\r\n\r\n  // Calcola score per ogni chunk\r\n  const scoredChunks = chunks.map((chunk, index) => {\r\n    let semanticScore = 0;\r\n    \r\n    // Usa cosine similarity se embeddings disponibili\r\n    if (queryEmbedding && chunk.embedding) {\r\n      semanticScore = cosineSimilarity(queryEmbedding, chunk.embedding);\r\n    } else {\r\n      // Fallback a TF-IDF\r\n      semanticScore = calculateTFIDF(chunk.text, query) / 10; // Normalizza per essere simile a cosine\r\n    }\r\n    \r\n    // Bonus per match esatti\r\n    const lowerChunk = chunk.text.toLowerCase();\r\n    const lowerQuery = query.toLowerCase();\r\n    let exactMatchBonus = 0;\r\n    if (lowerChunk.includes(lowerQuery)) {\r\n      exactMatchBonus = 0.1;\r\n    }\r\n    \r\n    // Bonus per parole chiave comuni\r\n    const queryWords = query.toLowerCase().split(/\\W+/).filter(w => w.length > 2);\r\n    const matchingWords = queryWords.filter(word => lowerChunk.includes(word)).length;\r\n    const keywordBonus = (matchingWords / queryWords.length) * 0.05;\r\n\r\n    const totalScore = semanticScore + exactMatchBonus + keywordBonus;\r\n\r\n    return {\r\n      ...chunk,\r\n      score: totalScore,\r\n      index,\r\n    };\r\n  });\r\n\r\n  // Ordina per score e ritorna i top K (anche con score bassi)\r\n  const sortedChunks = scoredChunks\r\n    .sort((a, b) => b.score - a.score)\r\n    .slice(0, topK);\r\n  \r\n  console.log('Top chunk scores:', sortedChunks.map(c => c.score.toFixed(4)));\r\n  \r\n  // Ritorna anche risultati con score bassi (meglio di niente)\r\n  return sortedChunks.filter(chunk => chunk.score >= 0);\r\n}\r\n\r\n/**\r\n * Genera risposta intelligente basata sul contenuto del documento usando OpenAI GPT-4\r\n * @param {string} query - Domanda dell'utente\r\n * @param {Array} relevantChunks - Chunk rilevanti dal documento\r\n * @param {string} documentText - Testo completo del documento\r\n * @param {string} conversationContext - Contesto della conversazione (opzionale)\r\n */\r\nexport async function generateAnswer(query, relevantChunks, documentText, conversationContext = '', documentMetadata = {}) {\r\n  if (!relevantChunks || relevantChunks.length === 0) {\r\n    return {\r\n      answer: \"Non ho trovato informazioni rilevanti nel documento per rispondere alla tua domanda. Prova a formulare la domanda in modo diverso o carica un documento più pertinente.\",\r\n      confidence: 0,\r\n      sources: [],\r\n    };\r\n  }\r\n\r\n  // Combina i chunk più rilevanti - SOLO TESTO (no oggetti, no IDs)\r\n  const combinedContext = relevantChunks\r\n    .map((chunk, idx) => `[Sezione ${idx + 1}]\\n${chunk.text}`)\r\n    .join('\\n\\n---\\n\\n');\r\n\r\n  // Usa OpenAI GPT-4 per generare una risposta intelligente\r\n  const confidence = Math.min(relevantChunks[0].score * 10, 1.0);\r\n  \r\n  try {\r\n    // Costruisci il prompt con contesto della conversazione se disponibile\r\n    let contextSection = '';\r\n    if (conversationContext && conversationContext.trim()) {\r\n      contextSection = `\\n\\n**CONTESTO DELLA CONVERSAZIONE PRECEDENTE:**\r\n${conversationContext}\r\n\r\nUsa questo contesto per capire meglio la domanda e fornire una risposta coerente con la conversazione.`;\r\n    }\r\n\r\n    const messages = [\r\n      {\r\n        role: 'system',\r\n        content: `Sei un assistente AI esperto nell'analisi di documenti. Segui un ragionamento interno SILENTE (non mostrarlo) con i passi: 1) Identifica concetti chiave 2) Seleziona parti rilevanti 3) Sintetizza relazioni 4) Verifica contraddizioni o assenze 5) Struttura risposta finale. Poi produci SOLO l'output formattato.\r\n\r\nOBIETTIVI:\r\n1. Analisi accurata delle sezioni fornite\r\n2. Risposta logica e coerente basata esclusivamente sul contenuto\r\n3. Struttura chiara e professionale in italiano\r\n4. Citazione delle fonti/Sezioni rilevanti\r\n5. Nessuna invenzione: se manca l'informazione, dichiaralo e suggerisci cosa servirebbe\r\n\r\nFORMATTA LA RISPOSTA CON LE SEZIONI (usa markdown semplice):\r\n**Risposta**: sintesi principale diretta alla domanda.\r\n**Dettagli**: approfondisci punti chiave organizzati.\r\n**Fonti**: elenco puntato con sezione e breve estratto.\r\n**Limiti**: cosa non è presente o ambiguo.\r\n**Suggerimenti**: eventuali passi successivi o chiarimenti da richiedere.\r\n\r\nRegole:\r\n- Non includere il ragionamento interno.\r\n- Non scusarti a meno che il contenuto sia realmente assente.\r\n- Mantieni tono professionale, conciso ma completo.`\r\n      },\r\n      {\r\n        role: 'user',\r\n        content: `Analizza il seguente contenuto estratto dal documento e rispondi alla domanda dell'utente in modo completo e accurato.\r\n\r\n**CONTENUTO DEL DOCUMENTO:**\r\n${combinedContext}${contextSection}\r\n\r\n**DOMANDA DELL'UTENTE:**\r\n${query}\r\n\r\n**ISTRUZIONI:**\r\n- Rispondi basandoti SOLO sul contenuto fornito sopra\r\n- Se la risposta richiede informazioni non presenti, dillo chiaramente\r\n- Cita o fai riferimento alle sezioni rilevanti quando possibile\r\n- Fornisci una risposta completa e ben strutturata\r\n- Considera il contesto della conversazione se fornito per una risposta più pertinente`\r\n      }\r\n    ];\r\n    \r\n    let answer = await chatCompletion(messages, {\r\n      model: 'gpt-4o-mini', // Modello veloce e economico\r\n      temperature: 0.2, // Bassa temperatura per risposte più accurate e consistenti\r\n      max_tokens: 1200, // Aumentato per risposte più complete\r\n      top_p: 0.9,\r\n      frequency_penalty: 0.1, // Riduce ripetizioni\r\n      presence_penalty: 0.1 // Incentiva varietà\r\n    });\r\n    answer = answer.trim();\r\n    // Post-processing: se il modello ha prodotto solo una frase debole/apologetica, arricchisci con estratti\r\n    const isWeak = /mi dispiace|non posso/i.test(answer) && answer.length < 120;\r\n    if (isWeak) {\r\n      const enriched = `**Risposta**: Informazioni limitate nel testo fornito.\r\n**Dettagli**:\\n${relevantChunks.slice(0,3).map(c=>'- '+c.text.substring(0,200).replace(/\\n+/g,' ')+ (c.text.length>200?'...':'' )).join('\\n')}\\n**Fonti**:\\n${relevantChunks.map((c,i)=>`- Sezione ${i+1} (score ${c.score.toFixed(3)})`).join('\\n')}\\n**Limiti**: Il documento sembra contenere testo estremamente breve o generico.\\n**Suggerimenti**: Carica un documento più esteso oppure specifica meglio la domanda.`;\r\n      answer = enriched;\r\n    }\r\n    return {\r\n      answer,\r\n      confidence,\r\n      sources: relevantChunks.map(c => ({\r\n        filename: documentMetadata?.originalFilename || documentMetadata?.filename || 'Documento',\r\n        text: c.text.substring(0, 150) + '...',\r\n        score: c.score.toFixed(3),\r\n      })),\r\n    };\r\n  } catch (error) {\r\n    console.error('Errore nella generazione della risposta con OpenAI:', error);\r\n    // Fallback a risposta semplice se OpenAI fallisce\r\n    const contextText = relevantChunks[0].text;\r\n    return {\r\n      answer: `Basandomi sul documento:\\n\\n${contextText}\\n\\n${relevantChunks.length > 1 ? '\\nInformazioni aggiuntive:\\n' + relevantChunks.slice(1, 3).map((c, i) => `• ${c.text.substring(0, 200)}...`).join('\\n') : ''}`,\r\n      confidence,\r\n      sources: relevantChunks.map(c => ({\r\n        filename: documentMetadata?.originalFilename || documentMetadata?.filename || 'Documento',\r\n        text: c.text.substring(0, 150) + '...',\r\n        score: c.score.toFixed(3),\r\n      })),\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Salva documento nello storage (con embeddings per ricerca semantica)\r\n */\r\nexport async function storeDocument(fileId, text, metadata = {}) {\r\n  console.log(`storeDocument called for ${fileId}, text length: ${text.length}`);\r\n  \r\n  const chunks = await createTextChunks(text);\r\n  \r\n  console.log(`Created ${chunks.length} chunks for document ${fileId}`);\r\n  \r\n  const documentData = {\r\n    text,\r\n    chunks,\r\n    metadata: {\r\n      ...metadata,\r\n      filename: metadata.filename || metadata.originalFilename || 'Unknown',\r\n      storedAt: new Date().toISOString(),\r\n      chunkCount: chunks.length,\r\n    },\r\n  };\r\n  \r\n  documentStore.set(fileId, documentData);\r\n  \r\n  console.log(`Document ${fileId} stored. Store size now: ${documentStore.size}`);\r\n  console.log(`Store keys:`, Array.from(documentStore.keys()));\r\n\r\n  return {\r\n    fileId,\r\n    chunkCount: chunks.length,\r\n    wordCount: text.split(/\\s+/).length,\r\n  };\r\n}\r\n\r\n/**\r\n * Recupera documento dallo storage\r\n */\r\nexport function getDocument(fileId) {\r\n  return documentStore.get(fileId);\r\n}\r\n\r\n/**\r\n * Rimuovi documento dallo storage\r\n */\r\nexport function removeDocument(fileId) {\r\n  return documentStore.delete(fileId);\r\n}\r\n\r\n/**\r\n * Cerca in tutti i documenti (async per embeddings)\r\n */\r\nexport async function searchAllDocuments(query, fileIds = null) {\r\n  console.log('searchAllDocuments called with query:', query, 'fileIds:', fileIds);\r\n  console.log('documentStore size:', documentStore.size);\r\n  console.log('documentStore keys:', Array.from(documentStore.keys()));\r\n  \r\n  const documents = fileIds && fileIds.length > 0\r\n    ? fileIds.map(id => {\r\n        const data = documentStore.get(id);\r\n        console.log(`Looking for fileId ${id}:`, data ? 'found' : 'NOT FOUND');\r\n        return { id, data };\r\n      }).filter(d => d.data)\r\n    : Array.from(documentStore.entries()).map(([id, data]) => {\r\n        console.log(`Document ${id}:`, data ? 'found' : 'NOT FOUND');\r\n        return { id, data };\r\n      });\r\n\r\n  console.log(`Found ${documents.length} documents to search`);\r\n\r\n  if (documents.length === 0) {\r\n    console.log('No documents found to search in');\r\n    return [];\r\n  }\r\n\r\n  const allResults = [];\r\n\r\n  for (const { id, data } of documents) {\r\n    if (!data || !data.chunks || !data.chunks.length) {\r\n      console.log(`Document ${id} has no chunks, skipping`);\r\n      continue;\r\n    }\r\n\r\n    console.log(`Searching in document ${id} (${data.chunks.length} chunks)`);\r\n    const results = await semanticSearch(data.text, data.chunks, query, 5);\r\n    \r\n    if (results.length > 0) {\r\n      console.log(`Found ${results.length} relevant chunks in document ${id}`);\r\n      allResults.push({\r\n        fileId: id,\r\n        filename: data.metadata?.originalFilename || data.metadata?.filename || 'Unknown',\r\n        results,\r\n        topScore: results[0].score,\r\n      });\r\n    } else {\r\n      console.log(`No relevant chunks found in document ${id}`);\r\n    }\r\n  }\r\n\r\n  console.log(`Total search results: ${allResults.length}`);\r\n\r\n  // Ordina per score migliore\r\n  return allResults.sort((a, b) => b.topScore - a.topScore);\r\n}\r\n\r\n/**\r\n * Genera risposta combinando risultati da più documenti usando OpenAI\r\n * @param {string} query - Domanda dell'utente\r\n * @param {Array} searchResults - Risultati della ricerca nei documenti\r\n * @param {string} conversationContext - Contesto della conversazione (opzionale)\r\n */\r\nexport async function generateMultiDocumentAnswer(query, searchResults, conversationContext = '') {\r\n  if (!searchResults || searchResults.length === 0) {\r\n    return {\r\n      answer: \"Non ho trovato informazioni rilevanti nei documenti caricati. Prova a formulare la domanda in modo diverso o carica documenti più pertinenti.\",\r\n      confidence: 0,\r\n      sources: [],\r\n    };\r\n  }\r\n\r\n  // Prendi i chunk migliori da tutti i documenti\r\n  const topChunks = searchResults\r\n    .flatMap(fileResult => \r\n      fileResult.results.map(r => ({\r\n        ...r,\r\n        filename: fileResult.filename,\r\n        fileId: fileResult.fileId,\r\n      }))\r\n    )\r\n    .sort((a, b) => b.score - a.score)\r\n    .slice(0, 5);\r\n\r\n  if (topChunks.length === 0) {\r\n    return {\r\n      answer: \"Non ho trovato informazioni sufficienti per rispondere.\",\r\n      confidence: 0,\r\n      sources: [],\r\n    };\r\n  }\r\n\r\n  // Genera risposta combinata usando OpenAI\r\n  const primaryChunk = topChunks[0];\r\n  const document = getDocument(primaryChunk.fileId);\r\n  \r\n  if (searchResults.length === 1) {\r\n    // Un solo documento - usa generateAnswer con metadata per filename\r\n    return await generateAnswer(query, topChunks, document.text, conversationContext, document.metadata || {});\r\n  } else {\r\n    // Multiple documenti - combina informazioni da più fonti\r\n    const confidence = Math.min(primaryChunk.score * 10, 1.0);\r\n    \r\n    try {\r\n      // Combina SOLO testo dai documenti (no file IDs, no oggetti)\r\n      const combinedContext = topChunks\r\n        .map((chunk, idx) => `[Documento: \"${chunk.filename}\" - Sezione ${idx + 1}]\\n${chunk.text}`)\r\n        .join('\\n\\n---\\n\\n');\r\n      \r\n      // Costruisci il prompt con contesto della conversazione se disponibile\r\n      let contextSection = '';\r\n      if (conversationContext && conversationContext.trim()) {\r\n        contextSection = `\\n\\n**CONTESTO DELLA CONVERSAZIONE PRECEDENTE:**\r\n${conversationContext}\r\n\r\nUsa questo contesto per capire meglio la domanda e fornire una risposta coerente con la conversazione.`;\r\n      }\r\n\r\n      const messages = [\r\n        {\r\n          role: 'system',\r\n          content: `Sei un assistente AI esperto nell'analisi di documenti multipli. Usa ragionamento interno SILENTE (non mostrarlo) seguendo: 1) Mappa concetti per documento 2) Trova sovrapposizioni/contrasti 3) Sintetizza 4) Valuta completezza 5) Struttura output. Non mostrare i passi.\r\n\r\nFORMATTA OUTPUT:\r\n**Risposta** (sintesi diretta alla domanda)\r\n**Analisi** (integrazione logica tra documenti, relazioni, eventuali differenze)\r\n**Fonti** (elenco: Documento – breve estratto pertinente)\r\n**Limiti** (informazioni mancanti, contraddizioni non risolte)\r\n**Suggerimenti** (cosa potrebbe aiutare o prossimi passi)\r\n\r\nRegole:\r\n- Non inventare contenuto\r\n- Non scusarti salvo assenza totale di informazioni\r\n- Cita il nome del documento per ogni informazione specifica\r\n- Indica contraddizioni se presenti.`\r\n        },\r\n        {\r\n          role: 'user',\r\n          content: `Analizza il contenuto estratto da ${searchResults.length} documenti diversi e rispondi alla domanda dell'utente sintetizzando le informazioni rilevanti.\r\n\r\n**CONTENUTO DAI DOCUMENTI:**\r\n${combinedContext}${contextSection}\r\n\r\n**DOMANDA DELL'UTENTE:**\r\n${query}\r\n\r\n**ISTRUZIONI:**\r\n- Combina informazioni da tutti i documenti rilevanti\r\n- Cita sempre il nome del documento quando fai riferimento a informazioni specifiche\r\n- Se ci sono informazioni correlate in più documenti, integrale in modo coerente\r\n- Fornisci una risposta completa che risponda alla domanda utilizzando tutte le fonti pertinenti\r\n- Considera il contesto della conversazione se fornito per una risposta più pertinente`\r\n        }\r\n      ];\r\n      \r\n      let answer = await chatCompletion(messages, {\r\n        model: 'gpt-4o-mini',\r\n        temperature: 0.2,\r\n        max_tokens: 1500, // Aumentato per risposte multi-documento più complete\r\n        top_p: 0.9,\r\n        frequency_penalty: 0.1,\r\n        presence_penalty: 0.1\r\n      });\r\n      answer = answer.trim();\r\n      const isWeak = /mi dispiace|non posso/i.test(answer) && answer.length < 140;\r\n      if (isWeak) {\r\n        const enrichment = topChunks.slice(0,5).map((c,i)=>`- ${c.filename} [score ${c.score.toFixed(3)}]: ${c.text.substring(0,160).replace(/\\n+/g,' ')}${c.text.length>160?'...':''}`).join('\\n');\r\n        answer = `**Risposta**: Informazioni limitate ma estratte dai documenti.\r\n**Analisi**: I contenuti disponibili sono molto brevi; non emergono argomentazioni complesse.\r\n**Fonti**:\\n${enrichment}\r\n**Limiti**: Poca profondità; serve testo aggiuntivo.\r\n**Suggerimenti**: Carica versioni più complete dei documenti o specifica una domanda più dettagliata.`;\r\n      }\r\n      return {\r\n        answer,\r\n        confidence,\r\n        sources: topChunks.slice(0, 3).map(c => ({\r\n          filename: c.filename,\r\n          text: c.text.substring(0, 100) + '...',\r\n          score: c.score.toFixed(3),\r\n        })),\r\n      };\r\n    } catch (error) {\r\n      console.error('Errore nella generazione della risposta multi-documento con OpenAI:', error);\r\n      // Fallback\r\n      let answer = `Basandomi sui ${searchResults.length} documenti caricati:\\n\\n`;\r\n      answer += `**Dal documento \"${primaryChunk.filename}\":**\\n${primaryChunk.text}\\n\\n`;\r\n      \r\n      if (topChunks.length > 1) {\r\n        const otherDocs = topChunks.slice(1, 3).filter(c => c.fileId !== primaryChunk.fileId);\r\n        if (otherDocs.length > 0) {\r\n          answer += `**Informazioni correlate da altri documenti:**\\n`;\r\n          otherDocs.forEach((chunk, idx) => {\r\n            answer += `\\n[${idx + 1}] Da \"${chunk.filename}\":\\n${chunk.text.substring(0, 200)}...\\n`;\r\n          });\r\n        }\r\n      }\r\n      \r\n      const confidence = Math.min(primaryChunk.score * 10, 1.0);\r\n      \r\n      return {\r\n        answer: answer.trim(),\r\n        confidence,\r\n        sources: topChunks.slice(0, 3).map(c => ({\r\n          filename: c.filename,\r\n          text: c.text.substring(0, 100) + '...',\r\n          score: c.score.toFixed(3),\r\n        })),\r\n      };\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * Ottieni tutti i documenti con i loro ID\r\n */\r\nexport function getAllDocuments() {\r\n  return Array.from(documentStore.entries()).map(([fileId, doc]) => ({\r\n    fileId,\r\n    ...doc\r\n  }));\r\n}\r\n\r\n/**\r\n * Ottieni statistiche sui documenti caricati\r\n */\r\nexport function getDocumentStats() {\r\n  const documents = Array.from(documentStore.values());\r\n  \r\n  return {\r\n    totalDocuments: documentStore.size,\r\n    totalWords: documents.reduce((sum, doc) => sum + (doc.text.split(/\\s+/).length || 0), 0),\r\n    totalChunks: documents.reduce((sum, doc) => sum + (doc.chunks?.length || 0), 0),\r\n    documents: Array.from(documentStore.entries()).map(([fileId, doc]) => ({\r\n      fileId,\r\n      index: Array.from(documentStore.keys()).indexOf(fileId),\r\n      filename: doc.metadata?.filename || doc.metadata?.originalFilename || 'Unknown',\r\n      wordCount: doc.text.split(/\\s+/).length,\r\n      chunkCount: doc.chunks?.length || 0,\r\n      storedAt: doc.metadata?.storedAt,\r\n    })),\r\n  };\r\n}\r\n\r\n","// API per caricare e analizzare documenti\r\nimport formidable from 'formidable';\r\nimport fs from 'fs';\r\nimport path from 'path';\r\nimport os from 'os';\r\nimport { extractTextFromDocument, storeDocument } from '../../../lib/documentAI.js';\r\nimport { v4 as uuidv4 } from 'uuid';\r\n\r\nexport const config = {\r\n  api: {\r\n    bodyParser: false,\r\n  },\r\n};\r\n\r\nexport default async function handler(req, res) {\r\n  if (req.method !== 'POST') {\r\n    return res.status(405).json({ error: 'Method not allowed' });\r\n  }\r\n\r\n  try {\r\n    const isVercel = Boolean(process.env.VERCEL);\r\n    const MAX_FILE_MB = isVercel ? Number(process.env.VERCEL_MAX_MB || 25) : 200;\r\n    const MAX_FILES = isVercel ? Number(process.env.VERCEL_MAX_FILES || 5) : 10;\r\n\r\n    // Su Vercel, usa /tmp (unico filesystem scrivibile)\r\n    const tmpDir = process.env.VERCEL ? '/tmp' : os.tmpdir();\r\n    const uploadDir = process.env.VERCEL ? '/tmp' : path.join(process.cwd(), 'uploads', 'chat');\r\n    \r\n    // Su Vercel, /tmp esiste sempre, non serve crearlo\r\n    if (!process.env.VERCEL && !fs.existsSync(uploadDir)) {\r\n      fs.mkdirSync(uploadDir, { recursive: true });\r\n    }\r\n\r\n    const form = formidable({\r\n      uploadDir,\r\n      keepExtensions: true,\r\n      // Imposta limite massimo per file in base all'ambiente\r\n      maxFileSize: MAX_FILE_MB * 1024 * 1024,\r\n      multiples: true,\r\n    });\r\n\r\n    const [fields, files] = await new Promise((resolve, reject) => {\r\n      form.parse(req, (err, fields, files) => {\r\n        if (err) reject(err);\r\n        else resolve([fields, files]);\r\n      });\r\n    });\r\n\r\n    const fileArray = Array.isArray(files.files) ? files.files : [files.files].filter(Boolean);\r\n    \r\n    if (!fileArray || fileArray.length === 0) {\r\n      return res.status(400).json({ error: 'Nessun file caricato' });\r\n    }\r\n\r\n    if (fileArray.length > MAX_FILES) {\r\n      return res.status(400).json({\r\n        error: `Numero massimo di file per analisi superato: ${fileArray.length} > ${MAX_FILES}`,\r\n        details: isVercel\r\n          ? `Limite Vercel: ${MAX_FILES} file per richiesta (riduci o usa caricamento diretto su storage).`\r\n          : `Carica al massimo ${MAX_FILES} file per volta.`,\r\n        limit: MAX_FILES,\r\n      });\r\n    }\r\n\r\n    // Verifica dimensione file (utile per errori di payload su Vercel)\r\n    for (const f of fileArray) {\r\n      const size = f.size || (f.filepath && fs.existsSync(f.filepath) ? fs.statSync(f.filepath).size : 0);\r\n      if (size > MAX_FILE_MB * 1024 * 1024) {\r\n        return res.status(413).json({\r\n          error: `File troppo grande: ${(size / (1024 * 1024)).toFixed(1)}MB > ${MAX_FILE_MB}MB`,\r\n          details: isVercel\r\n            ? `Le funzioni serverless Vercel hanno un limite di payload. Usa file più piccoli, carica direttamente su storage (Vercel Blob/S3) o esegui in ambiente non serverless.`\r\n            : `Riduci la dimensione del file o carica meno contenuti.`,\r\n          limitMB: MAX_FILE_MB,\r\n        });\r\n      }\r\n    }\r\n\r\n    // Processa i file in parallelo per velocità (max 3 alla volta)\r\n    const processFile = async (file) => {\r\n      try {\r\n        // Leggi il file come buffer\r\n        const buffer = fs.readFileSync(file.filepath);\r\n        const filename = file.originalFilename || file.newFilename;\r\n        const mimeType = file.mimetype || 'application/octet-stream';\r\n\r\n        // Estrai testo dal documento usando pdfjs-dist, mammoth, xlsx, ecc.\r\n        console.log(`Processing file: ${filename} (${mimeType})`);\r\n        let text, metadata;\r\n        try {\r\n          const result = await extractTextFromDocument(buffer, mimeType, filename, file.filepath);\r\n          text = result.text;\r\n          metadata = result.metadata || {};\r\n          console.log(`Extracted text length: ${text ? text.length : 0} characters`);\r\n        } catch (extractError) {\r\n          console.error(`Error extracting text from ${filename}:`, extractError);\r\n          return {\r\n            filename,\r\n            success: false,\r\n            error: `Errore estrazione testo: ${extractError.message}`,\r\n          };\r\n        }\r\n\r\n        if (!text || text.trim().length === 0) {\r\n          console.warn(`No text extracted from ${filename}`);\r\n          return {\r\n            filename,\r\n            success: false,\r\n            error: 'Nessun testo estratto dal documento',\r\n          };\r\n        }\r\n\r\n        // Genera ID unico per il file\r\n        const fileId = uuidv4();\r\n\r\n        console.log(`Storing document ${fileId} with filename ${filename}`);\r\n        console.log(`Text length: ${text.length} characters`);\r\n\r\n        // Salva nello store in-memory con embeddings (async)\r\n        const storeResult = await storeDocument(fileId, text, {\r\n          ...metadata,\r\n          originalFilename: filename,\r\n          filename,\r\n          mimeType,\r\n          uploadedAt: new Date().toISOString(),\r\n          size: buffer.length,\r\n        });\r\n\r\n        console.log(`Document ${fileId} stored in memory with ${storeResult.chunkCount} chunks and embeddings`);\r\n\r\n        // Pulisci il file temporaneo\r\n        try {\r\n          fs.unlinkSync(file.filepath);\r\n        } catch (unlinkError) {\r\n          console.warn('Errore eliminazione file temporaneo:', unlinkError);\r\n        }\r\n\r\n        return {\r\n          fileId,\r\n          filename,\r\n          success: true,\r\n          wordCount: storeResult.wordCount,\r\n          chunkCount: storeResult.chunkCount,\r\n          pages: metadata.pages || 0,\r\n          size: buffer.length,\r\n        };\r\n      } catch (fileError) {\r\n        console.error('Errore processamento file:', fileError);\r\n        return {\r\n          filename: file.originalFilename || file.newFilename,\r\n          success: false,\r\n          error: fileError.message || 'Errore durante il processamento',\r\n        };\r\n      }\r\n    };\r\n\r\n    // Processa tutti i file (riduci concorrenza su Vercel per evitare timeout)\r\n    const BATCH_SIZE = isVercel ? 1 : 3;\r\n    const results = [];\r\n    \r\n    for (let i = 0; i < fileArray.length; i += BATCH_SIZE) {\r\n      const batch = fileArray.slice(i, i + BATCH_SIZE);\r\n      const batchResults = await Promise.all(batch.map(processFile));\r\n      results.push(...batchResults);\r\n    }\r\n\r\n    const successCount = results.filter(r => r.success).length;\r\n\r\n    console.log(`Upload completed: ${successCount} successful out of ${results.length} total files`);\r\n    console.log('Results:', JSON.stringify(results, null, 2));\r\n\r\n    return res.status(200).json({\r\n      success: successCount > 0,\r\n      files: results,\r\n      message: `${successCount} file analizzati con successo`,\r\n    });\r\n  } catch (error) {\r\n    console.error('Upload error:', error);\r\n    return res.status(500).json({\r\n      error: 'Errore durante il caricamento',\r\n      details: error.message,\r\n    });\r\n  }\r\n}\r\n\r\n","import type { NextApiResponse } from '../../types'\nimport type { IncomingMessage, ServerResponse } from 'node:http'\n\nimport { sendError } from '../../server/api-utils'\nimport { RouteKind } from '../../server/route-kind'\nimport type { Span } from '../../server/lib/trace/tracer'\nimport { PagesAPIRouteModule } from '../../server/route-modules/pages-api/module.compiled'\n\nimport { hoist } from './helpers'\n\n// Import the userland code.\nimport * as userland from 'VAR_USERLAND'\nimport { getTracer, SpanKind } from '../../server/lib/trace/tracer'\nimport { BaseServerSpan } from '../../server/lib/trace/constants'\nimport type { InstrumentationOnRequestError } from '../../server/instrumentation/types'\nimport { addRequestMeta } from '../../server/request-meta'\n\n// Re-export the handler (should be the default export).\nexport default hoist(userland, 'default')\n\n// Re-export config.\nexport const config = hoist(userland, 'config')\n\n// Create and export the route module that will be consumed.\nconst routeModule = new PagesAPIRouteModule({\n  definition: {\n    kind: RouteKind.PAGES_API,\n    page: 'VAR_DEFINITION_PAGE',\n    pathname: 'VAR_DEFINITION_PATHNAME',\n    // The following aren't used in production.\n    bundlePath: '',\n    filename: '',\n  },\n  userland,\n  distDir: process.env.__NEXT_RELATIVE_DIST_DIR || '',\n  relativeProjectDir: process.env.__NEXT_RELATIVE_PROJECT_DIR || '',\n})\n\nexport async function handler(\n  req: IncomingMessage,\n  res: ServerResponse,\n  ctx: {\n    waitUntil?: (prom: Promise<void>) => void\n  }\n): Promise<void> {\n  if (routeModule.isDev) {\n    addRequestMeta(req, 'devRequestTimingInternalsEnd', process.hrtime.bigint())\n  }\n  let srcPage = 'VAR_DEFINITION_PAGE'\n\n  // turbopack doesn't normalize `/index` in the page name\n  // so we need to to process dynamic routes properly\n  // TODO: fix turbopack providing differing value from webpack\n  if (process.env.TURBOPACK) {\n    srcPage = srcPage.replace(/\\/index$/, '') || '/'\n  }\n\n  const prepareResult = await routeModule.prepare(req, res, { srcPage })\n\n  if (!prepareResult) {\n    res.statusCode = 400\n    res.end('Bad Request')\n    ctx.waitUntil?.(Promise.resolve())\n    return\n  }\n\n  const { query, params, prerenderManifest, routerServerContext } =\n    prepareResult\n\n  try {\n    const method = req.method || 'GET'\n    const tracer = getTracer()\n\n    const activeSpan = tracer.getActiveScopeSpan()\n    const onRequestError =\n      routeModule.instrumentationOnRequestError.bind(routeModule)\n\n    const invokeRouteModule = async (span?: Span) =>\n      routeModule\n        .render(req, res, {\n          query: {\n            ...query,\n            ...params,\n          },\n          params,\n          allowedRevalidateHeaderKeys: process.env\n            .__NEXT_ALLOWED_REVALIDATE_HEADERS as any as string[],\n          multiZoneDraftMode: Boolean(process.env.__NEXT_MULTI_ZONE_DRAFT_MODE),\n          trustHostHeader: process.env\n            .__NEXT_TRUST_HOST_HEADER as any as boolean,\n          // TODO: get this from from runtime env so manifest\n          // doesn't need to load\n          previewProps: prerenderManifest.preview,\n          propagateError: false,\n          dev: routeModule.isDev,\n          page: 'VAR_DEFINITION_PAGE',\n\n          internalRevalidate: routerServerContext?.revalidate,\n\n          onError: (...args: Parameters<InstrumentationOnRequestError>) =>\n            onRequestError(req, ...args),\n        })\n        .finally(() => {\n          if (!span) return\n\n          span.setAttributes({\n            'http.status_code': res.statusCode,\n            'next.rsc': false,\n          })\n\n          const rootSpanAttributes = tracer.getRootSpanAttributes()\n          // We were unable to get attributes, probably OTEL is not enabled\n          if (!rootSpanAttributes) {\n            return\n          }\n\n          if (\n            rootSpanAttributes.get('next.span_type') !==\n            BaseServerSpan.handleRequest\n          ) {\n            console.warn(\n              `Unexpected root span type '${rootSpanAttributes.get(\n                'next.span_type'\n              )}'. Please report this Next.js issue https://github.com/vercel/next.js`\n            )\n            return\n          }\n\n          const route = rootSpanAttributes.get('next.route')\n          if (route) {\n            const name = `${method} ${route}`\n\n            span.setAttributes({\n              'next.route': route,\n              'http.route': route,\n              'next.span_name': name,\n            })\n            span.updateName(name)\n          } else {\n            span.updateName(`${method} ${srcPage}`)\n          }\n        })\n\n    // TODO: activeSpan code path is for when wrapped by\n    // next-server can be removed when this is no longer used\n    if (activeSpan) {\n      await invokeRouteModule(activeSpan)\n    } else {\n      await tracer.withPropagatedContext(req.headers, () =>\n        tracer.trace(\n          BaseServerSpan.handleRequest,\n          {\n            spanName: `${method} ${srcPage}`,\n            kind: SpanKind.SERVER,\n            attributes: {\n              'http.method': method,\n              'http.target': req.url,\n            },\n          },\n          invokeRouteModule\n        )\n      )\n    }\n  } catch (err) {\n    // we re-throw in dev to show the error overlay\n    if (routeModule.isDev) {\n      throw err\n    }\n    // this is technically an invariant as error handling\n    // should be done inside of api-resolver onError\n    sendError(res as NextApiResponse, 500, 'Internal Server Error')\n  } finally {\n    // We don't allow any waitUntil work in pages API routes currently\n    // so if callback is present return with resolved promise since no\n    // pending work\n    ctx.waitUntil?.(Promise.resolve())\n  }\n}\n"],"names":["sendError","RouteKind","PagesAPIRouteModule","hoist","userland","getTracer","SpanKind","BaseServerSpan","addRequestMeta","config","routeModule","definition","kind","PAGES_API","page","pathname","bundlePath","filename","distDir","process","env","__NEXT_RELATIVE_DIST_DIR","relativeProjectDir","__NEXT_RELATIVE_PROJECT_DIR","handler","req","res","ctx","isDev","hrtime","bigint","srcPage","TURBOPACK","replace","prepareResult","prepare","statusCode","end","waitUntil","Promise","resolve","query","params","prerenderManifest","routerServerContext","method","tracer","activeSpan","getActiveScopeSpan","onRequestError","instrumentationOnRequestError","bind","invokeRouteModule","span","render","allowedRevalidateHeaderKeys","__NEXT_ALLOWED_REVALIDATE_HEADERS","multiZoneDraftMode","Boolean","__NEXT_MULTI_ZONE_DRAFT_MODE","trustHostHeader","__NEXT_TRUST_HOST_HEADER","previewProps","preview","propagateError","dev","internalRevalidate","revalidate","onError","args","finally","setAttributes","rootSpanAttributes","getRootSpanAttributes","get","handleRequest","console","warn","route","name","updateName","withPropagatedContext","headers","trace","spanName","SERVER","attributes","url","err"],"mappings":"8kBACA,IAAA,EAAA,EAAA,CAAA,CAAA,yCAEA,IAAM,EAAS,IAAI,EAAA,OAAM,CAAC,CACxB,OAAQ,QAAQ,GAAG,CAAC,cAAc,AACpC,GAGO,eAAe,EAAkB,CAAI,EAC1C,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAMF,MAAO,CALU,MAAM,EAAO,UAAU,CAAC,MAAM,CAAC,CAC9C,MAAO,yBACP,MAAO,EAAK,SAAS,CAAC,EAAG,IAC3B,EAAA,EAEgB,IAAI,CAAC,EAAE,CAAC,SAAS,AACnC,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,8BAA+B,GACvC,AAAI,MAAM,CAAC,8BAA8B,EAAE,EAAM,OAAO,CAAA,CAAE,CAClE,CACF,CAGO,eAAe,EAAwB,CAAK,EACjD,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAAC,MAAM,OAAO,CAAC,IAAU,AAAiB,MAAX,MAAM,CAAQ,MAAO,EAAE,CAE1D,GAAI,CAMF,MAAO,CALU,MAAM,EAAO,UAAU,CAAC,MAAM,CAAC,CAC9C,MAAO,yBACP,MAAO,EAAM,GAAG,CAAC,GAAK,CAAC,GAAK,EAAA,CAAE,CAAE,QAAQ,GAAG,SAAS,CAAC,EAAG,KAC1D,EAAA,EAEgB,IAAI,CAAC,GAAG,CAAC,GAAK,EAAE,SAAS,CAC3C,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,qCAAsC,GAC9C,AAAI,MAAM,CAAC,qCAAqC,EAAE,EAAM,OAAO,CAAA,CAAE,CACzE,CACF,CAGO,eAAe,EAAe,CAAQ,CAAE,EAAU,CAAC,CAAC,EACzD,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAWF,MAAO,CAVU,MAAM,EAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,CACpD,MAAO,EAAQ,KAAK,EAAI,cACxB,SAAU,EACV,YAAa,EAAQ,WAAW,EAAI,GACpC,WAAY,EAAQ,UAAU,EAAI,IAClC,MAAO,EAAQ,KAAK,EAAI,EACxB,kBAAmB,EAAQ,iBAAiB,EAAI,EAChD,iBAAkB,EAAQ,gBAAgB,EAAI,CAChD,EAAA,EAEgB,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO,AAC5C,CAAE,MAAO,EAAO,CAId,GAHA,QAAQ,KAAK,CAAC,4BAA6B,GAGtB,KAAK,CAAtB,EAAM,MAAM,CACd,MAAM,AAAI,MAAM,6DACX,GAAI,AAAiB,KAAK,GAAhB,MAAM,CACrB,MAAM,AAAI,MAAM,0DACX,GAAqB,KAAK,CAAtB,EAAM,MAAM,CACrB,MAAM,AAAI,MAAM,+CAGlB,OAAM,AAAI,MAAM,CAAC,uCAAuC,EAAE,EAAM,OAAO,CAAA,CAAE,CAC3E,CACF,CAGO,eAAe,EAAgB,CAAI,CAAE,EAAY,GAAG,EACzD,IAAM,EAAW,CACf,CACE,KAAM,SACN,QAAS,6DACX,EACA,CACE,KAAM,OACN,QAAS,CAAC,gCAAgC,EAAE,EAAU;AAAA;AAAmB,EAAE,EAAA,CAAM,AACnF,EACD,CAED,OAAO,MAAM,EAAe,EAAU,CAAE,YAAa,GAAK,WAAY,GAAI,EAC5E,CAGO,eAAe,EAAa,CAAI,CAAE,EAAQ,CAAC,EAChD,IAAM,EAAW,CACf,CACE,KAAM,SACN,QAAS,4HACX,EACA,CACE,KAAM,OACN,QAAS,CAAC,SAAS,EAAE,EAAM;AAAA;AAAqC,EAAE,EAAK,SAAS,CAAC,EAAG,KAAA,CAAO,AAC7F,EACD,CAID,MAAO,CAFU,MAAM,EAAe,EAAU,CAAE,YAAa,GAAK,WAAY,GAAI,EAAA,EAGjF,KAAK,CAAC,KACN,GAAG,CAAC,GAAO,EAAI,IAAI,GAAG,WAAW,IACjC,MAAM,CAAC,GAAO,EAAI,MAAM,CAAG,GAC3B,KAAK,CAAC,EAAG,EACd,CAGO,eAAe,EAAiB,CAAI,EACzC,IAAM,EAAa,CACjB,WAAY,UAAW,SAAU,eACjC,cAAe,QAAS,OAAQ,QAAS,UAAW,QACrD,CAEK,EAAW,CACf,CACE,KAAM,SACN,QAAS,CAAC,2FAA2F,EAAE,EAAW,IAAI,CAAC,MAAM,8CAA8C,CAAC,AAC9K,EACA,CACE,KAAM,OACN,QAAS,CAAC;AAAA;AAA2B,EAAE,EAAK,SAAS,CAAC,EAAG,KAAA,CAAO,AAClE,EACD,CAID,MAAO,CAFU,MAAM,EAAe,EAAU,CAAE,YAAa,GAAK,WAAY,EAAG,EAAA,EAGhF,KAAK,CAAC,KACN,GAAG,CAAC,GAAO,EAAI,IAAI,GAAG,WAAW,IACjC,MAAM,CAAC,GAAO,EAAW,QAAQ,CAAC,GACvC,CAGO,eAAe,EAAuB,CAAW,CAAE,CAAa,CAAE,EAAQ,6DAA6D,EAC5I,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAEF,IAAM,EAAc,EAAY,QAAQ,CAAC,UA8BzC,MAAO,CA5BU,MAAM,EAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC,CACpD,MAAO,SACP,SAAU,CACR,CACE,KAAM,SACN,QAAS,mOACX,EACA,CACE,KAAM,OACN,QAAS,CACP,CACE,KAAM,OACN,KAAM,CACR,EACA,CACE,KAAM,YACN,UAAW,CACT,IAAK,CAAC,KAAK,EAAE,EAAc,QAAQ,EAAE,EAAA,CAAa,CAClD,OAAQ,MACV,CACF,EACD,AACH,EACD,CACD,WAAY,IACZ,YAAa,EACf,EAAA,EAEgB,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO,AAC5C,CAAE,MAAO,EAAO,CAGd,GAFA,QAAQ,KAAK,CAAC,uBAAwB,GAElC,AAAiB,KAAK,GAAhB,MAAM,CACd,MAAM,AAAI,MAAM,6DACX,GAAqB,KAAK,CAAtB,EAAM,MAAM,CACrB,MAAM,AAAI,MAAM,0DACX,GAAqB,MAAjB,EAAM,MAAM,EAAY,EAAM,OAAO,EAAE,SAAS,SACzD,CADmE,KAC7D,AAAI,MAAM,4DAGlB,OAAM,AAAI,MAAM,CAAC,mCAAmC,EAAE,EAAM,OAAO,CAAA,CAAE,CACvE,CACF,CAIO,eAAe,EAA6B,CAAQ,EACzD,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,IAAM,EAAK,MAAA,EAAA,CAAA,CAAA,QAEP,EAAe,KACnB,GAAI,CAIF,EAAe,MAAM,EAAO,KAAK,CAAC,MAAM,CAAC,CACvC,KAAM,EAAG,gBAAgB,CAAC,GAC1B,QAAS,WACX,GAqBA,IAAM,EAAgB,CAhBL,AAgBM,OAhBA,EAAO,SAAS,CAAC,MAAM,CAAC,CAC7C,MAAO,SACP,MAAO,CACL,CACE,KAAM,OACN,QAAS,CACP,CAAE,KAAM,aAAc,KAAM,6HAA8H,EAC1J,CAAE,KAAM,aAAc,QAAS,EAAa,EAAE,AAAC,EAChD,AACH,EACD,CACD,kBAAmB,IACnB,YAAa,EACf,EAAA,EAGgC,WAAW,EAAI,EAAA,CAAE,CAAE,QAAQ,GAAG,IAAI,GAGlE,GAAI,CAAC,EACH,MAAU,AAAJ,MAAU,CADE,gCAIpB,OAAO,CAET,CAAE,MAAO,EAAO,CAGd,GAFA,QAAQ,KAAK,CAAC,gDAAiD,GAE1C,KAAK,CAAtB,EAAM,MAAM,CACd,MAAM,AAAI,MAAM,6DACX,GAAqB,KAAK,CAAtB,EAAM,MAAM,CACrB,MAAM,AAAI,MAAM,0DACX,GAAqB,KAAK,CAAtB,EAAM,MAAM,CACrB,MAAM,AAAI,MAAM,sGAGlB,OAAM,AAAI,MAAM,CAAC,sCAAsC,EAAE,EAAM,OAAO,CAAA,CAAE,CAC1E,QAAU,CAER,GAAI,CACE,GAAgB,EAAa,EAAE,EAAE,CAC/B,EAAO,KAAK,EAAE,OAChB,CADwB,KAClB,EAAO,KAAK,CAAC,MAAM,CAAC,EAAa,EAAE,EAChC,EAAO,KAAK,EAAE,KAAK,AAC5B,MAAM,EAAO,KAAK,CAAC,GAAG,CAAC,EAAa,EAAE,EAI5C,CAAE,MAAO,EAAU,CACjB,QAAQ,IAAI,CAAC,8CAA+C,GAAU,SAAW,EACnF,CACF,CACF,CAGO,eAAe,EAAqB,CAAM,CAAE,EAAU,CAAC,CAAC,EAC7D,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CACF,IAAM,EAAO,EAAQ,IAAI,EAAI,YACvB,EAAU,EAAQ,OAAO,EAAI,WAC7B,EAAQ,EAAQ,KAAK,EAAI,QAEzB,EAAW,MAAM,EAAO,MAAM,CAAC,QAAQ,CAAC,CAC5C,MAAO,WACP,OAAQ,EACR,KAAM,EACN,QAAS,EACT,MAAO,EACP,EAAG,CACL,GAEM,EAAW,EAAS,IAAI,CAAC,EAAE,EAAE,IACnC,GAAI,CAAC,EACH,MAAU,AAAJ,EADO,IACG,uCAGlB,OAAO,CACT,CAAE,MAAO,EAAO,CAUd,GATA,QAAQ,KAAK,CAAC,uCAAwC,GACtD,QAAQ,KAAK,CAAC,iBAAkB,CAC9B,OAAQ,EAAM,MAAM,CACpB,WAAY,EAAM,UAAU,CAC5B,QAAS,EAAM,OAAO,CACtB,KAAM,EAAM,IAAI,CAChB,SAAU,EAAM,QAAQ,EAAE,MAAQ,EAAM,QAAQ,AAClD,GAEqB,KAAK,CAAtB,EAAM,MAAM,CACd,MAAM,AAAI,MAAM,6DACX,GAAqB,KAAK,CAAtB,EAAM,MAAM,CACrB,MAAM,AAAI,MAAM,0DACX,GAAqB,MAAjB,EAAM,MAAM,CAAU,CAC/B,IAAM,EAAe,EAAM,OAAO,EAAI,EAAM,QAAQ,EAAE,MAAM,OAAO,SAAW,8CAC9E,OAAM,AAAI,MAAM,CAAC,0BAA0B,EAAE,EAAA,CAAc,CAC7D,MAAO,GAAmB,cAAf,EAAM,IAAI,EAAmC,gBAAgB,CAA/B,EAAM,IAAI,CACjD,MAAM,AAAI,MAAM,0EAGlB,OAAM,AAAI,MAAM,CAAC,wCAAwC,EAAE,EAAM,OAAO,EAAI,qBAAA,CAAsB,CACpG,CACF,CAGO,eAAe,EAAuB,CAAM,CAAE,EAAU,CAAC,CAAC,EAC/D,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CACF,IAAM,EAAW,MAAM,EAAqB,EAAQ,GAG9C,EAAgB,MAAM,MAAM,GAClC,GAAI,CAAC,EAAc,EAAE,CAAE,CACrB,IAAM,EAAY,MAAM,EAAc,IAAI,GAAG,KAAK,CAAC,IAAM,gBACzD,OAAM,AAAI,MAAM,CAAC,4CAA4C,EAAE,EAAc,MAAM,CAAC,CAAC,EAAE,EAAc,UAAU,CAAC,EAAE,EAAE,EAAA,CAAW,CACjI,CAEA,IAAM,EAAc,MAAM,EAAc,WAAW,GACnD,OAAO,OAAO,IAAI,CAAC,EACrB,CAAE,MAAO,EAAO,CAEd,MAAM,CACR,CACF,CAGO,eAAe,EAAsB,CAAW,CAAE,CAAa,CAAE,EAAoB,IAAI,EAC9F,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAIF,IAAM,EAAmB,MAAM,EAC7B,EACA,EAJqB,GAAqB,UAK1C,6LAII,EAAwB,CAAC,uEAAuE,EAAE,EAAiB,qGAA+F,CAAC,CASzN,OAN4B,AAMrB,MAN2B,EAAuB,EAAuB,CAC9E,KAAM,YACN,QAAS,KACT,MAAO,SACT,EAGF,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,qCAAsC,GAC1C,AAAJ,MAAU,CAAC,wCAAwC,EAAE,EAAM,OAAO,CAAA,CAAE,CAC5E,CACF,CAGO,eAAe,EAA0B,CAAW,CAAE,CAAa,EACxE,GAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,CAC7B,CAD+B,KACzB,AAAI,MAAM,kFAGlB,GAAI,CAEF,IAAM,EAAiB,CAAC;;;;;;;yMAO6K,CAAC,CAEhM,EAAiB,MAAM,EAC3B,EACA,EACA,GAIE,EAAW,CACb,MAAO,SACP,UAAW,WACX,MAAO,SACP,UAAW,MACb,EAEA,GAAI,CAEF,IAAM,EAAY,EAAe,KAAK,CAAC,eACvC,GAAI,EAAW,CACb,IAAM,EAAS,KAAK,KAAK,CAAC,CAAS,CAAC,EAAE,EACtC,EAAW,CAAE,GAAG,CAAQ,CAAE,GAAG,CAAM,AAAC,CACtC,CACF,CAAE,MAAO,EAAY,CACnB,QAAQ,IAAI,CAAC,8CACf,CAIA,IAAI,EAAW,GADD,CAAC,MAAA,EAAA,CAAA,CAAA,OAAA,CAAqB,CAAE,OAAA,AAAO,EACxB,EAAa,CAAE,gBAAgB,CAAK,GA0DzD,OAvDuB,AAuDhB,SAvDH,EAAS,KAAK,EAAkC,WAAnB,EAAS,KAAK,AAAK,GAAU,CAC5D,EAAW,EAAS,MAAM,CAAoB,SAAnB,EAAS,KAAK,CAAc,EAAI,EAAA,EAIlC,UAAU,CAAjC,EAAS,SAAS,CACpB,EAAW,EAAS,OAAO,CAAC,CAC1B,MAAO,EACP,GAAI,EACJ,GAAI,GACJ,GAAI,EACJ,GAAI,EACJ,GAAI,CACN,GACgC,YAAY,CAAnC,EAAS,SAAS,GAC3B,EAAW,EAAS,OAAO,CAAC,CAC1B,MAAO,EACP,GAAI,GACJ,GAAI,EACN,EAAA,EAIqB,UAAU,CAA7B,EAAS,KAAK,GAChB,EAAW,EAAS,QAAQ,CAAC,CAC3B,WAAY,KACZ,WAAY,IACd,GAAG,MAAM,CAAC,KAAM,CAAE,IAAM,EAAA,AAKxB,CALgC,CAIP,UAAvB,EAAS,SAAS,EAJoC,AAIG,SAAS,CAAhC,EAAS,SAAS,CAC3C,EAAS,GAAG,CAAC,CACtB,QAAS,IACT,iBAAkB,EAClB,mBAAmB,CACrB,GAGsB,eAAlB,GAAoD,aAAa,CAA/B,EACzB,EAAS,IAAI,CAAC,CACvB,QAAS,GACT,QAAS,GACT,oBAAqB,GACrB,oBAAoB,CACtB,GAEW,EAAS,GAAG,CAAC,CACtB,QAAS,IACT,iBAAkB,CACpB,GAImB,MAAM,EAAS,QAAQ,EAEhD,CAAE,MAAO,EAAO,CAGd,OAFA,QAAQ,KAAK,CAAC,yCAA0C,GAEjD,CACT,CACF,kdC1eA,IAAA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,0CAKA,IAAM,EAAgB,IAAI,IASnB,GAT0B,YASX,EAAwB,CAAM,CAAE,CAAQ,CAAE,CAAQ,CAAE,EAAW,IAAI,EACvF,GAAI,CACF,IAAI,EAAO,GACP,AAZkE,EAYvD,UACb,WACA,EACA,MAAO,EACP,UAAW,CACb,EAEA,GAAI,AAAa,uBAAqB,EAAS,WAAW,GAAG,QAAQ,CAAC,QAAS,CAE7E,GAAM,8BAAE,CAA4B,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAInC,EAAK,MAAA,EAAA,CAAA,CAAA,QACL,EAAO,MAAA,EAAA,CAAA,CAAA,QAGP,EAAU,CAFL,MAAA,EAAA,CAAA,CAAA,OAAA,EAEQ,MAAM,GACnB,EAAe,EAAK,IAAI,CAAC,EAAS,CAAC,KAAK,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,EAAA,CAAU,EAExE,GAAI,CAWF,GATA,EAAG,aAAa,CAAC,EAAc,GAM/B,EAAO,CAAC,CAHR,EAAO,MAAM,EAA6B,EAAA,GAG1B,EAAA,CAAE,CAAE,QAAQ,GAAG,IAAI,GACnC,EAAS,cAAc,CAAG,qBAEtB,CAAC,GAAwB,GAAG,CAAnB,EAAK,MAAM,CACtB,MAAM,AAAI,MAAM,+CAIpB,QAAU,CAER,GAAI,CACE,EAAG,UAAU,CAAC,IAChB,EAAG,SAD4B,CAClB,CAAC,EAElB,CAAE,MAAO,EAAc,CACrB,QAAQ,IAAI,CAAC,kCAAmC,EAClD,CACF,CACF,MACK,GAAI,EAAS,QAAQ,CAAC,qBAAuB,EAAS,WAAW,GAAG,QAAQ,CAAC,SAKhF,CAL0F,CAKnF,CAHP,EAAO,CADQ,MAAM,EAAA,OAAO,CAAC,cAAc,CAAC,QAAE,CAAO,EAAA,EACvC,KAAA,AAAK,EAGP,OAAO,CAAC,OAAQ,KAAK,IAAI,QAElC,GAAI,EAAS,QAAQ,CAAC,gBAAkB,EAAS,WAAW,GAAG,KAAK,CAAC,sBAAuB,CAC/F,IAAM,EAAW,EAAA,IAAS,CAAC,EAAQ,CAAE,KAAM,QAAS,GAC9C,EAAS,EAAS,UAAU,CAG5B,EAAU,EAAE,CAClB,IAAK,IAAM,KAAa,EAAQ,CAC9B,IAAM,EAAQ,EAAS,MAAM,CAAC,EAAU,CAGxC,IAAK,IAAM,KAFO,EAEA,AAFA,KAAU,CAAC,IAEA,SAFa,CAAC,EAAO,CAAE,OAAQ,EAAG,OAAQ,EAAG,GAGxE,GAAI,MAAM,OAAO,CAAC,GAAM,CACtB,IAAM,EAAU,EAAI,MAAM,CAAC,GAAQ,GAAQ,EAAK,QAAQ,GAAG,IAAI,IAAI,IAAI,CAAC,KACpE,EAAQ,IAAI,IAAI,AAClB,EAAQ,IAAI,CAAC,CAAC,CAAC,EAAE,EAAU,EAAE,EAAE,EAAA,CAAS,CAE5C,CAEJ,CAEA,EAAO,EAAQ,IAAI,CAAC,KACtB,MACK,GAAI,EAAS,UAAU,CAAC,UAAY,EAAS,WAAW,GAAG,QAAQ,CAAC,QACvE,CADgF,CACzE,EAAO,QAAQ,CAAC,cAEpB,GAAI,EAAS,UAAU,CAAC,WAAa,EAAS,WAAW,GAAG,KAAK,CAAC,sDAErE,CAF4H,EAExH,CACF,GAAM,wBAAE,CAAsB,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAGnC,GAAI,CAQF,EANmB,KAMZ,CANkB,EACvB,EACA,EACA,4MAOF,EAAS,cAAc,CAAG,eAC5B,CAAE,MAAO,EAAa,CAIpB,IAAM,EAAY,CAAC,MAAA,EAAA,CAAA,CAAA,OAAA,CAA4B,CAAE,OAAO,CAClD,EAAc,GAAY,EAEhC,GAAI,CASF,EAAO,CARQ,MAAM,EAAU,SAAS,CAAC,EAAa,UAAW,CAC/D,OAAQ,AAAC,IACH,EAAE,MAAM,AAGd,CACF,EAAA,EAJqB,AAMP,IAAI,CAAC,IAAI,CAAC,IAAI,GAC5B,EAAS,CAPgC,aAOlB,CAAG,eAC5B,CAAE,MAAO,EAAU,CAIjB,IAAM,EAAS,MAAM,EAAU,YAAY,CAAC,UAAW,EAAG,CACxD,OAAS,AAAD,IACF,EAAE,MAAM,AAGd,CACF,GAEA,CANqB,EAMjB,CAEF,EAAO,CADQ,MAAM,EAAO,MAPW,GAOF,CAAC,EAAA,EACxB,IAAI,CAAC,IAAI,CAAC,IAAI,GAC5B,EAAS,cAAc,CAAG,sBAC5B,QAAU,CACR,MAAM,EAAO,SAAS,EACxB,CACF,CACF,CAEA,GAAI,CAAC,GAAwB,AAAhB,GAAmB,GAAd,MAAM,CACtB,MAAM,AAAI,MAAM,6GAIpB,CAAE,MAAO,EAAY,CAEnB,MADA,QAAQ,KAAK,CAAC,oCAAqC,GAC7C,AAAI,MAAM,CAAC,mCAAmC,EAAE,EAAW,OAAO,CAAA,CAAE,CAC5E,MAGA,MAAU,AAAJ,MAAU,CAAC,6BAA6B,EAAE,EAAA,CAAU,EAG5D,GAAI,CAAC,GAAQ,AAAuB,GAAG,GAArB,IAAI,GAAG,MAAM,CAC7B,MAAM,AAAI,MAAM,uCAKlB,OAFA,EAAS,SAAS,CAAG,EAAK,KAAK,CAAC,OAAO,MAAM,CAEtC,CAAE,gBAAM,CAAS,CAC1B,CAAE,MAAO,EAAO,CAEd,MADA,QAAQ,KAAK,CAAC,2BAA4B,GACpC,AAAI,MAAM,CAAC,kCAAkC,EAAE,EAAM,OAAO,CAAA,CAAE,CACtE,CACF,CAMO,eAAe,EAAiB,CAAI,CAAE,EAAY,GAAI,CAAE,EAAU,GAAG,EAC1E,IAAM,EAAY,EAAK,KAAK,CAAC,aAAa,MAAM,CAAC,GAAK,EAAE,IAAI,GAAG,MAAM,CAAG,IAClE,EAAS,EAAE,CAEb,EAAe,GACf,EAAgB,EAEpB,IAAK,IAAM,KAAY,EAAW,CAChC,IAAM,EAAiB,EAAS,MAAM,CAElC,EAAgB,EAAiB,GAAa,EAAa,IAAI,IAEjE,AAFqE,EAE9D,IAAI,CAAC,CACV,KAAM,EAAa,IAAI,GACvB,WAAY,EAAK,OAAO,CAAC,EAAa,IAAI,IAC1C,SAAU,EAAK,OAAO,CAAC,EAAa,IAAI,IAAM,EAAa,MAAM,AACnE,GAMA,EAAgB,CADhB,EAAe,AAFD,AACO,EADM,KAAK,CAAC,OACN,KAAK,CAAC,CAAC,KAAK,KAAK,CAAC,EAAU,KAC3B,IAAI,CAAC,KAAO,IAAM,EAAW,GAAA,EAC5B,MAAM,GAEnC,GAAgB,EAAW,KAC3B,GAAiB,EAAiB,EAEtC,CAGI,EAAa,IAAI,IAAI,AACvB,EAAO,IAAI,CAAC,CACV,KAAM,EAAa,IAAI,GACvB,WAAY,EAAK,OAAO,CAAC,EAAa,IAAI,IAC1C,SAAU,EAAK,MAAM,AACvB,GAGF,IAAM,EAAc,EAAO,MAAM,CAAG,EAAI,EAAS,CAAC,CAAE,KAAM,EAAK,IAAI,GAAI,WAAY,EAAG,SAAU,EAAK,MAAO,AAAD,EAAG,CAGxG,yBAAE,CAAuB,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAEpC,GAAI,CAGF,IAAK,IAAI,EAAI,EAAG,EAAI,EAAY,MAAM,CAAE,KAAK,CAAY,CACvD,IAAM,EAAQ,EAAY,KAAK,CAAC,EAAG,EAFlB,EAEsB,EAEvC,CADmB,MAAM,EAAwB,EAAM,GAAG,CAAC,GAAK,EAAE,IAAI,EAAA,EAC3D,OAAO,CAAC,CAAC,EAAK,KACvB,CAAK,CAAC,EAAI,CAAC,SAAS,CAAG,CACzB,EACF,CACF,CAAE,MAAO,EAAU,CACjB,QAAQ,IAAI,CAAC,sDAAuD,EAAS,OAAO,EACpF,GAAM,mBAAE,CAAiB,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAC9B,IAAK,IAAM,KAAS,EAClB,GAAI,CACF,EAAM,IAFuB,KAEd,CAAG,MAAM,EAAkB,EAAM,IAAI,CACtD,CAAE,MAAO,EAAK,CACZ,QAAQ,IAAI,CAAC,0CAA2C,EAAI,OAAO,EACnE,EAAM,SAAS,CAAG,IACpB,CAEJ,CAEA,OAAO,CACT,CAgDO,eAAe,EAAe,CAAY,CAAE,CAAM,CAAE,CAAK,CAAE,EAAO,CAAC,EACxE,GAAI,CAAC,GAA4B,GAAG,CAArB,EAAO,MAAM,CAC1B,MAAO,EAAE,CAIX,GAAM,mBAAE,CAAiB,CAAE,CAAG,MAAA,EAAA,CAAA,CAAA,QAC1B,EAAiB,KAErB,GAAI,CACF,EAAiB,MAAM,EAAkB,EAC3C,CAAE,MAAO,EAAU,CACjB,QAAQ,IAAI,CAAC,kDAAmD,EAClE,CA4CA,OAzCqB,AAkCA,AAOd,EAzCqB,GAAG,CAAC,CAAC,EAAO,KACtC,IAAI,EAAgB,EAIlB,EADE,GAAkB,EAAM,SAAS,CACnB,AAhEtB,CA+D2C,QA/DlC,AAAiB,CAAI,CAAE,CAAI,EAClC,GAAI,CAAC,GAAQ,CAAC,GAAQ,EAAK,MAAM,GAAK,EAAK,MAAM,CAAE,OAAO,EAE1D,IAAM,EAAM,EAAK,MAAM,CAAC,CAAC,EAAK,EAAK,IAAM,EAAM,EAAM,CAAI,CAAC,EAAE,CAAE,GACxD,EAAO,KAAK,IAAI,CAAC,EAAK,MAAM,CAAC,CAAC,EAAK,IAAQ,EAAM,EAAM,EAAK,IAC5D,EAAO,KAAK,IAAI,CAAC,EAAK,MAAM,CAAC,CAAC,EAAK,IAAQ,EAAM,EAAM,EAAK,IAElE,OAAO,GAAO,EAAO,CAAR,AAAQ,CAAI,AAC3B,EAwDuC,EAAgB,EAAM,SAAS,EAnDtE,AAsDsB,SAtDb,AAAe,CAAI,CAAE,CAAK,EACjC,IAAM,EAAY,EAAK,WAAW,GAAG,KAAK,CAAC,OAAO,MAAM,CAAC,GAAK,EAAE,MAAM,CAAG,GACnE,EAAa,EAAM,WAAW,GAAG,KAAK,CAAC,OAAO,MAAM,CAAC,GAAK,EAAE,MAAM,CAAG,GAE3E,GAA0B,IAAtB,EAAW,MAAM,CAAQ,OAAO,EAEpC,IAAI,EAAQ,EACN,EAAgB,CAAC,EAgBvB,OAfA,EAAU,OAAO,CAAC,IAChB,CAAa,CAAC,EAAK,CAAG,CAAC,CAAa,CAAC,EAAK,EAAI,CAAC,EAAI,CACrD,GAEA,EAAW,OAAO,CAAC,IACjB,IAAM,EAAY,CAAa,CAAC,EAAU,EAAI,EAC9C,GAAI,EAAY,EAAG,CAEjB,IAAM,EAAK,EAAY,EAAU,MAAM,CAEjC,EAAM,KAAK,GAAG,CAAC,EAAU,MAAM,EAAI,CAAD,EAAa,CAAC,EAAK,EAC3D,GAAS,EAAK,CAChB,CACF,GAEO,EAAQ,EAAW,MAC5B,AADkC,EA+BG,EAAM,IAAI,CAAE,GAAS,GAItD,CAJ0D,GAIpD,EAAa,EAAM,IAAI,CAAC,WAAW,GACnC,EAAa,EAAM,UALyE,CAK9D,GAChC,EAAkB,CAClB,GAAW,QAAQ,CAAC,KACtB,EAAkB,EAAA,EAIpB,EALqC,EAK/B,EAAa,EAAM,WAAW,GAAG,KAAK,CAAC,OAAO,MAAM,CAAC,GAAK,EAAE,MAAM,CAAG,GAErE,EAAgB,AADA,EAAW,MAAM,CAAC,GAAQ,EAAW,QAAQ,CAAC,IAAO,MAAM,CAC3C,EAAW,MAAM,CAAI,IAErD,EAAa,EAAgB,EAAkB,EAErD,MAAO,CACL,GAAG,CAAK,CACR,MAAO,QACP,CACF,CACF,GAIG,IAAI,CAAC,CAAC,EAAG,IAAM,EAAE,KAAK,CAAG,EAAE,KAAK,EAChC,KAAK,CAAC,EAAG,GAKQ,MAAM,CAAC,GAAS,EAAM,KAAK,EAAI,EACrD,CASO,eAAe,EAAe,CAAK,CAAE,CAAc,CAAE,CAAY,CAAE,EAAsB,EAAE,CAAE,EAAmB,CAAC,CAAC,EACvH,GAAI,CAAC,GAA4C,GAAG,CAA7B,EAAe,MAAM,CAC1C,MAAO,CACL,OAAQ,0KACR,WAAY,EACZ,QAAS,EAAE,AACb,EAIF,IAAM,EAAkB,EACrB,GAAG,CAAC,CAAC,EAAO,IAAQ,CAAC,SAAS,EAAE,EAAM,EAAE;AAAG,EAAE,EAAM,IAAI,CAAA,CAAE,EACzD,IAAI,CAAC,eAGF,EAAa,KAAK,GAAG,CAA2B,GAA1B,CAAc,CAAC,EAAE,CAAC,KAAK,CAAO,GAE1D,GAAI,CAEF,IAAI,EAAiB,GACjB,GAAuB,EAAoB,IAAI,IAAI,CACrD,EAAiB,CAAC;AAAA;AAAA;AACxB,EAAE,oBAAoB;;uGAEiF,AAAD,EAGlG,IAAM,EAAW,CACf,CACE,KAAM,SACN,QAAS,CAAC;;;;;;;;;;;;;;;;;;;mDAmBiC,CAAC,AAC9C,EACA,CACE,KAAM,OACN,QAAS,CAAC;;;AAGlB,EAAE,EAAA,EAAkB,eAAe;;;AAGnC,EAAE,MAAM;;;;;;;yFAO8E,CAAC,AACjF,EACD,CAEG,EAAS,MAAM,CAAA,EAAA,EAAA,cAAA,AAAc,EAAC,EAAU,CAC1C,MAAO,cACP,YAAa,GACb,WAAY,KACZ,MAAO,GACP,kBAAmB,GACnB,iBAAkB,EACpB,EADwB,CAUxB,OARA,EAAS,EAAO,IAAI,GAEL,CAJ6B,wBAIJ,IAAI,CAAC,IAAW,EAAO,MAAM,CAAG,MAItE,EAFiB,CAAC,MAET;;AADA,EAAE,EAAe,KAAK,CAAC,EAAE,GAAG,GAAG,CAAC,GAAG,KAAK,EAAE,IAAI,CAAC,SAAS,CAAC,EAAE,KAAK,OAAO,CAAC,OAAO,MAAO,CAAD,CAAG,IAAI,CAAC,MAAM,CAAC,IAAI,MAAM,EAAA,CAAG,EAAG,IAAI,CAAC,MAAM;AAAA;AAAc,EAAE,EAAe,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,UAAU,EAAE,EAAE,EAAE,QAAQ,EAAE,EAAE,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,MAAM;AAAA;AAAA,uFAAsK,CAC5Y,AAD6Y,EAGjZ,QACL,aACA,EACA,QAAS,EAAe,GAAG,CAAC,IAAK,AAAC,CAChC,SAAU,GAAkB,kBAAoB,GAAkB,UAAY,YAC9E,KAAM,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAO,MACjC,MAAO,EAAE,KAAK,CAAC,OAAO,CAAC,EACzB,CAAC,EACH,CACF,CAAE,MAAO,EAAO,CACd,QAAQ,KAAK,CAAC,sDAAuD,GAErE,IAAM,EAAc,CAAc,CAAC,EAAE,CAAC,IAAI,CAC1C,MAAO,CACL,OAAQ,CAAC;AAAA;AAA4B,EAAE,YAAY;AAAA;AAAI,EAAE,EAAe,MAAM,CAAG,EAAI,+BAAiC,EAAe,KAAK,CAAC,EAAG,GAAG,GAAG,CAAC,CAAC,EAAG,IAAM,CAAC,EAAE,EAAE,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAK,GAAG,CAAC,EAAE,IAAI,CAAC,MAAQ,GAAA,CAAI,YACpN,EACA,QAAS,EAAe,GAAG,CAAC,IAAK,AAAC,CAChC,SAAU,GAAkB,kBAAoB,GAAkB,UAAY,YAC9E,KAAM,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAO,MACjC,MAAO,EAAE,KAAK,CAAC,OAAO,CAAC,GACzB,CAAC,CACH,CACF,CACF,CAKO,eAAe,EAAc,CAAM,CAAE,CAAI,CAAE,EAAW,CAAC,CAAC,EAG7D,IAAM,EAAS,MAAM,EAAiB,GAIhC,EAAe,MACnB,SACA,EACA,SAAU,CACR,GAAG,CAAQ,CACX,SAAU,EAAS,QAAQ,EAAI,EAAS,gBAAgB,EAAI,UAC5D,SAAU,IAAI,OAAO,WAAW,GAChC,WAAY,EAAO,MACrB,AAD2B,CAE7B,EAOA,OALA,EAAc,GAAG,CAAC,EAAQ,GAKnB,QACL,EACA,WAAY,EAAO,MAAM,CACzB,UAAW,EAAK,KAAK,CAAC,OAAO,MAAM,AACrC,CACF,CAmBO,eAAe,EAAmB,CAAK,CAAE,EAAU,IAAI,EAK5D,IAAM,EAAY,GAAW,EAAQ,MAAM,CAAG,EAC1C,EAAQ,GAAG,CAAC,IACV,IAAM,EAAO,EAAc,GAAG,CAAC,GAE/B,MAAO,IAAE,OAAI,CAAK,CACpB,GAAG,MAAM,CAAC,GAAK,EAAE,IAAI,EACrB,MAAM,IAAI,CAAC,EAAc,OAAO,IAAI,GAAG,CAAC,CAAC,CAAC,EAAI,EAAK,IAE1C,IAAE,OAAI,EAAK,GAKxB,GAAyB,GAAG,CAAxB,EAAU,MAAM,CAElB,MAAO,EAAE,CAGX,IAAM,EAAa,EAAE,CAErB,IAAK,GAAM,IAAE,CAAE,MAAE,CAAI,CAAE,GAAI,EAAW,CACpC,GAAI,CAAC,GAAQ,CAAC,EAAK,MAAM,EAAI,CAAC,EAAK,MAAM,CAAC,MAAM,CAE9C,CAFgD,QAMlD,IAAM,EAAU,MAAM,EAAe,EAAK,IAAI,CAAE,EAAK,MAAM,CAAE,EAAO,GAEhE,EAAQ,MAAM,CAAG,GAEnB,AAFsB,EAEX,IAAI,CAAC,CACd,OAAQ,EACR,SAAU,EAAK,QAAQ,EAAE,kBAAoB,EAAK,QAAQ,EAAE,UAAY,kBACxE,EACA,SAAU,CAAO,CAAC,EAAE,CAAC,KAAK,AAC5B,EAIJ,CAKA,OAAO,EAAW,IAAI,CAAC,CAAC,EAAG,IAAM,EAAE,QAAQ,CAAG,EAAE,QAAQ,CAC1D,CAQO,eAAe,EAA4B,CAAK,CAAE,CAAa,CAAE,EAAsB,EAAE,QAC9F,GAAI,CAAC,GAA0C,GAAG,CAA5B,EAAc,MAAM,CACxC,MAAO,CACL,OAAQ,gJACR,WAAY,EACZ,QAAS,EAAE,AACb,EAIF,IAAM,EAAY,EACf,OAAO,CAAC,GACP,EAAW,OAAO,CAAC,GAAG,CAAC,GAAM,CAAD,CAC1B,GAAG,CAAC,CACJ,SAAU,EAAW,QAAQ,CAC7B,OAAQ,EAAW,MAAM,CAC3B,CAAC,GAEF,IAAI,CAAC,CAAC,EAAG,IAAM,EAAE,KAAK,CAAG,EAAE,KAAK,EAChC,KAAK,CAAC,EAAG,GAEZ,GAAyB,GAAG,CAAxB,EAAU,MAAM,CAClB,MAAO,CACL,OAAQ,0DACR,WAAY,EACZ,QAAS,EAAE,AACb,EAIF,IAAM,EAAe,CAAS,CAAC,EAAE,CAC3B,GAxGoB,EAwGG,EAAa,EAxGV,EAwGf,EAA+B,CAvGzC,EAAc,GAAG,CAAC,IAyGzB,GAA6B,GAAG,CAA5B,EAAc,MAAM,CAEtB,OAAO,MAAM,EAAe,EAAO,EAAW,EAAS,IAAI,CAAE,EAAqB,EAAS,QAAQ,EAAI,CAAC,EACnG,EAEL,IAAM,EAAa,KAAK,GAAG,CAAsB,GAArB,EAAa,KAAK,CAAO,GAErD,GAAI,CAEF,IAAM,EAAkB,EACrB,GAAG,CAAC,CAAC,EAAO,IAAQ,CAAC,aAAa,EAAE,EAAM,QAAQ,CAAC,YAAY,EAAE,EAAM,EAAE;AAAG,EAAE,EAAM,IAAI,CAAA,CAAE,EAC1F,IAAI,CAAC,eAGJ,EAAiB,GACjB,GAAuB,EAAoB,IAAI,IAAI,CACrD,EAAiB,CAAC;AAAA;AAAA;AAC1B,EAAE,oBAAoB;;uGAEgF,AAAC,EAGjG,IAAM,EAAW,CACf,CACE,KAAM,SACN,QAAS,CAAC;;;;;;;;;;;;;oCAagB,CAAC,AAC7B,EACA,CACE,KAAM,OACN,QAAS,CAAC,kCAAkC,EAAE,EAAc,MAAM,CAAC;;;AAG7E,EAAE,EAAA,EAAkB,eAAe;;;AAGnC,EAAE,MAAM;;;;;;;yFAO8E,CAAC,AAC/E,EACD,CAEG,EAAS,MAAM,CAAA,EAAA,EAAA,cAAc,AAAd,EAAe,EAAU,CAC1C,MAAO,cACP,YAAa,GACb,WAAY,KACZ,MAAO,GACP,kBAAmB,GACnB,iBAAkB,EACpB,GAGA,GAFA,CAEI,CAFK,EAAO,IAAI,GACL,yBAAyB,IAAI,CAAC,IAAW,EAAO,MAAM,CAAG,IAC5D,CACV,IAAM,EAAa,EAAU,KAAK,CAAC,EAAE,GAAG,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,EAAE,EAAE,EAAE,QAAQ,CAAC,QAAQ,EAAE,EAAE,KAAK,CAAC,OAAO,CAAC,GAAG,GAAG,EAAE,EAAE,IAAI,CAAC,SAAS,CAAC,EAAE,KAAK,OAAO,CAAC,OAAO,KAAA,EAAO,EAAE,IAAI,CAAC,MAAM,CAAC,IAAI,MAAM,GAAA,CAAI,EAAE,IAAI,CAAC,MACtL,EAAS,CAAC;;;AAEN,EAAE,WAAW;;2GAE4E,CAAC,AAChG,CACA,MAAO,QACL,aACA,EACA,QAAS,EAAU,KAAK,CAAC,EAAG,GAAG,GAAG,CAAC,IAAK,AAAC,CACvC,SAAU,EAAE,QAAQ,CACpB,KAAM,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAO,MACjC,MAAO,EAAE,KAAK,CAAC,OAAO,CAAC,GACzB,CAAC,CACH,CACF,CAAE,MAAO,EAAO,CACd,QAAQ,KAAK,CAAC,sEAAuE,GAErF,IAAI,EAAS,CAAC,cAAc,EAAE,EAAc,MAAM,CAAC;AAAA;AAAwB,CAAC,CAG5E,GAFA,GAAU,CAAC,iBAAiB,EAAE,EAAa,QAAQ,CAAC;AAAM,EAAE,EAAa,IAAI,CAAC;AAAA;AAAI,CAAC,CAE/E,EAAU,MAAM,CAAG,EAAG,CACxB,IAAM,EAAY,EAAU,KAAK,CAAC,EAAG,GAAG,MAAM,CAAC,GAAK,EAAE,MAAM,GAAK,EAAa,MAAM,EAChF,EAAU,MAAM,CAAG,GAAG,CACxB,GAAU,CAAC;AAAgD,CAAC,CAC5D,EAAU,OAAO,CAAC,CAAC,EAAO,KACxB,GAAU,CAAC;AAAA,CAAG,EAAE,EAAM,EAAE,MAAM,EAAE,EAAM,QAAQ,CAAC;AAAI,EAAE,EAAM,IAAI,CAAC,SAAS,CAAC,EAAG,KAAK;AAAK,CAAC,AAC1F,GAEJ,CAEA,IAAM,EAAa,KAAK,GAAG,CAAsB,GAArB,EAAa,KAAK,CAAO,GAErD,MAAO,CACL,OAAQ,EAAO,IAAI,GACnB,aACA,QAAS,EAAU,KAAK,CAAC,EAAG,GAAG,GAAG,CAAC,IAAK,AAAC,CACvC,SAAU,EAAE,QAAQ,CACpB,KAAM,EAAE,IAAI,CAAC,SAAS,CAAC,EAAG,KAAO,MACjC,MAAO,EAAE,KAAK,CAAC,OAAO,CAAC,GACzB,CAAC,CACH,CACF,CACF,CACF,CAeO,SAAS,IACd,IAAM,EAAY,MAAM,IAAI,CAAC,EAAc,MAAM,IAEjD,MAAO,CACL,eAAgB,EAAc,IAAI,CAClC,WAAY,EAAU,MAAM,CAAC,CAAC,EAAK,IAAQ,GAAO,EAAI,CAAL,GAAS,CAAC,KAAK,CAAC,OAAO,MAAM,GAAI,CAAC,CAAG,GACtF,YAAa,EAAU,MAAM,CAAC,CAAC,EAAK,IAAQ,GAAO,EAAI,CAAL,KAAW,EAAE,SAAU,CAAC,CAAG,GAC7E,UAAW,MAAM,IAAI,CAAC,EAAc,OAAO,IAAI,GAAG,CAAC,CAAC,CAAC,EAAQ,EAAI,GAAK,CAAC,QACrE,EACA,MAAO,MAAM,IAAI,CAAC,EAAc,IAAI,IAAI,OAAO,CAAC,GAChD,SAAU,EAAI,QAAQ,EAAE,UAAY,EAAI,QAAQ,EAAE,kBAAoB,UACtE,UAAW,EAAI,IAAI,CAAC,KAAK,CAAC,OAAO,MAAM,CACvC,WAAY,EAAI,MAAM,EAAE,QAAU,EAClC,SAAU,EAAI,QAAQ,EAAE,SAC1B,CAAC,CACH,CACF,mSCjwBA,IAAA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,QACA,EAAA,EAAA,CAAA,CAAA,qBAQe,eAAe,EAAQ,CAAG,CAAE,CAAG,EAC5C,GAAmB,QAAQ,CAAvB,EAAI,MAAM,CACZ,OAAO,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAAE,MAAO,oBAAqB,GAG5D,GAAI,CACF,IAAM,GAAW,CAAQ,QAAQ,GAAG,CAAC,MAAM,CACrC,EAAc,EAAW,OAAO,QAAQ,GAAG,CAAC,aAAa,EAAI,IAAM,IACnE,EAAY,EAAW,OAAO,QAAQ,GAAG,CAAC,gBAAgB,EAAI,GAAK,GAG1D,QAAQ,GAAG,CAAC,MAAM,EAAY,CAAT,CAAS,OAAE,CAAC,MAAM,GACtD,IAAM,EAAY,QAAQ,GAAG,CAAC,MAAM,CAAG,OAAS,EAAA,OAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,GAAI,UAAW,OAGhF,CAAC,QAAQ,GAAG,CAAC,MAAM,EAAK,EAAD,AAAC,OAAE,CAAC,UAAU,CAAC,IACxC,EAAA,MADoD,CAClD,CAAC,SAAS,CAAC,EAAW,CAAE,WAAW,CAAK,GAG5C,IAAM,EAAO,CAAA,EAAA,EAAA,OAAA,AAAU,EAAC,WACtB,EACA,gBAAgB,EAEhB,YAA2B,KAAd,EAAqB,KAClC,WAAW,CACb,GAEM,CAAC,EAAQ,EAAM,CAAG,MAAM,IAAI,QAAQ,CAAC,EAAS,KAClD,EAAK,KAAK,CAAC,EAAK,CAAC,EAAK,EAAQ,KACxB,EAAK,EAAO,GACX,EAAQ,CAAC,EAAQ,EAAM,CAC9B,EACF,GAEM,EAAY,MAAM,OAAO,CAAC,EAAM,KAAK,EAAI,EAAM,KAAK,CAAG,CAAC,EAAM,KAAK,CAAC,CAAC,MAAM,CAAC,SAElF,GAAI,CAAC,GAAkC,GAAG,CAAxB,EAAU,MAAM,CAChC,OAAO,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAAE,MAAO,sBAAuB,GAG9D,GAAI,EAAU,MAAM,CAAG,EACrB,OAAO,EADyB,AACrB,MAAM,CAAC,KAAK,IAAI,CAAC,CAC1B,MAAO,CAAC,6CAA6C,EAAE,EAAU,MAAM,CAAC,GAAG,EAAE,EAAA,CAAW,CACxF,QAAS,EACL,CAAC,eAAe,EAAE,EAAU,kEAAkE,CAAC,CAC/F,CAAC,kBAAkB,EAAE,EAAU,gBAAgB,CAAC,CACpD,MAAO,CACT,GAIF,IAAK,IAAM,KAAK,EAAW,CACzB,IAAM,EAAO,EAAE,IAAI,GAAK,CAAD,CAAG,QAAQ,EAAI,EAAA,OAAE,CAAC,UAAU,CAAC,EAAE,QAAQ,EAAI,EAAA,OAAE,CAAC,QAAQ,CAAC,EAAE,QAAQ,EAAE,IAAI,EAAG,CAAC,CAClG,GAAI,EAAqB,KAAd,EAAqB,KAC9B,CADoC,MAC7B,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAC1B,MAAO,CAAC,oBAAoB,EAAE,CAAC,EAAQ,KAAD,EAAY,AAAJ,CAAK,CAAE,OAAO,CAAC,GAAG,KAAK,EAAE,EAAY,EAAE,CAAC,CACtF,QAAS,EACL,CAAC,uKAAoK,CAAC,CACtK,CAAC,sDAAsD,CAAC,CAC5D,QAAS,CACX,EAEJ,CAGA,IAAM,EAAc,MAAO,IACzB,GAAI,CAEF,IAMI,EAAM,EANJ,EAAS,EAAA,OAAE,CAAC,YAAY,CAAC,EAAK,QAAQ,EACtC,EAAW,EAAK,gBAAgB,EAAI,EAAK,WAAW,CACpD,EAAW,EAAK,QAAQ,EAAI,2BAKlC,GAAI,CACF,IAAM,EAAS,MAAM,CAAA,EAAA,EAAA,uBAAA,AAAuB,EAAC,EAAQ,EAAU,EAAU,EAAK,QAAQ,EACtF,EAAO,EAAO,IAAI,CAClB,EAAW,EAAO,QAAQ,EAAI,CAAC,CAEjC,CAAE,MAAO,EAAc,CAErB,OADA,QAAQ,KAAK,CAAC,CAAC,2BAA2B,EAAE,EAAS,CAAC,CAAC,CAAE,GAClD,UACL,EACA,SAAS,EACT,MAAO,CAAC,yBAAyB,EAAE,EAAa,OAAO,CAAA,CACzD,AAD2D,CAE7D,CAEA,GAAI,CAAC,GAA+B,GAAG,CAA1B,EAAK,IAAI,GAAG,MAAM,CAE7B,OADA,QAAQ,IAAI,CAAC,CAAC,uBAAuB,EAAE,EAAA,CAAU,EAC1C,UACL,EACA,QAAS,GACT,MAAO,qCACT,EAIF,IAAM,EAAS,CAAA,EAAA,EAAA,EAAM,AAAN,IAMT,EAAc,MAAM,CAAA,EAAA,EAAA,aAAA,AAAa,EAAC,EAAQ,EAAM,CACpD,GAAG,CAAQ,CACX,iBAAkB,EAClB,oBACA,EACA,WAAY,IAAI,OAAO,WAAW,GAClC,KAAM,EAAO,MAAM,AACrB,GAKA,GAAI,CACF,EAAA,OAAE,CAAC,UAAU,CAAC,EAAK,QAAQ,CAC7B,CAAE,MAAO,EAAa,CACpB,QAAQ,IAAI,CAAC,uCAAwC,EACvD,CAEA,MAAO,QACL,WACA,EACA,SAAS,EACT,UAAW,EAAY,SAAS,CAChC,WAAY,EAAY,UAAU,CAClC,MAAO,EAAS,KAAK,EAAI,EACzB,KAAM,EAAO,MAAM,AACrB,CACF,CAAE,MAAO,EAAW,CAElB,OADA,QAAQ,KAAK,CAAC,6BAA8B,GACrC,CACL,SAAU,EAAK,gBAAgB,EAAI,EAAK,WAAW,CACnD,SAAS,EACT,MAAO,EAAU,OAAO,EAAI,iCAC9B,CACF,CACF,EAGM,EAAa,EAAW,EAAI,EAC5B,EAAU,EAAE,CAElB,IAAK,IAAI,EAAI,EAAG,EAAI,EAAU,MAAM,CAAE,GAAK,EAAY,CACrD,IAAM,EAAQ,EAAU,KAAK,CAAC,EAAG,EAAI,GAC/B,EAAe,MAAM,QAAQ,GAAG,CAAC,EAAM,GAAG,CAAC,IACjD,EAAQ,IAAI,IAAI,EAClB,CAEA,IAAM,EAAe,EAAQ,MAAM,CAAC,GAAK,EAAE,OAAO,EAAE,MAAM,CAK1D,OAAO,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAC1B,QAAS,EAAe,EACxB,MAAO,EACP,QAAS,CAAA,EAAG,EAAa,6BAA6B,CAAC,AACzD,EACF,CAAE,MAAO,EAAO,CAEd,OADA,QAAQ,KAAK,CAAC,gBAAiB,GACxB,EAAI,MAAM,CAAC,KAAK,IAAI,CAAC,CAC1B,MAAO,gCACP,QAAS,EAAM,OAAO,AACxB,EACF,CACF,8CA/KsB,CACpB,IAAK,CACH,YAAY,CACd,CACF,2ECTA,IAAA,EAA0B,EAAwB,CAAzCA,AAAyC,CAAA,CAAA,OAClD,AADkB,EACQ,EAAyB,CAA1CC,AAA0C,CAAA,EADzB,AACyB,MAAjC,AAElB,EAAoC,EAAA,CAA3BC,AAA2B,CAAA,EAFV,MAI1B,EAAiC,EAAA,CAAxBC,AAAwB,CAAA,IAFL,AAEd,GAF4E,CAK1F,EAAwC,EALJ,AAKI,AAHlB,CAGkB,CAAA,EAA5BC,MACZ,EAAoC,AAJH,EAIG,CAAA,AAA3BC,CAA0D,EADzC,IAE1B,EADkB,AACa,EADXC,AAC6C,CAAxDC,AAAwD,CAAA,KAFzB,CACZ,EAG5B,EAA+B,EAA2B,CAFnC,AAEdC,AAAiD,CAHtB,AAGsB,EAFO,KAAlC,EAE2B,IAAnC,QAAQ,8BAGhBL,EAAAA,KAAAA,EAAMC,EAAU,WAAU,AAG5BK,EAAAA,CAAAA,EAASN,EAAAA,KAAAA,EAAMC,EAAU,UAGhCM,AAHyC,EAG3B,IAAIR,EAAAA,mBAAAA,CAAoB,CAC1CS,WAAY,CACVC,KAAMX,EAAAA,SAAAA,CAAUY,SAAS,CACzBC,KAAM,4BACNC,SAAU,4BAEVC,WAAY,GACZC,SAAU,EACZ,WACAb,EACAc,QAAqBG,CAAZF,EAAoC,MAA5BC,GAAG,CAACC,CACrBC,IADiD,eACc,CAA3CH,CACtB,GAEO,IAHuBC,GAAG,CAACG,OAGZC,EACpBC,CAAoB,CACpBC,CAAmB,CACnBC,CAEC,EAEGjB,EAAYkB,KAAK,EAAE,EAVoC,CAWzDpB,EAAAA,cAAAA,EAAeiB,EAAK,+BAAgCN,QAAQU,MAAM,CAACC,MAAM,IAE3E,IAAIC,EAAU,4BAMZA,EAAUA,EAAQE,OAAO,CAAC,WAAY,KAAO,IAG/C,IAAMC,EAAgB,MAAMxB,EAAYyB,OAAO,CAACV,EAAKC,EAAK,SAAEK,CAAQ,GAEpE,GAAI,CAACG,EAAe,CAClBR,EAAIU,UAAU,CAAG,IACjBV,EAAIW,GAAG,CAAC,eACK,MAAbV,CAAa,CAATW,IAAS,KAAA,EAAbX,EAAIW,SAAS,CAAA,IAAA,CAAbX,EAAgBY,QAAQC,OAAO,IAC/B,MACF,CAEA,GAAM,OAAEC,CAAK,QAAEC,CAAM,mBAAEC,CAAiB,qBAAEC,CAAmB,CAAE,CAC7DV,EAEF,GAAI,CACF,IAAMW,EAASpB,EAAIoB,MAAM,EAAI,MACvBC,EAAAA,CAAAA,EAASzC,EAAAA,SAAAA,IAET0C,EAAaD,EAAOE,kBAAkB,GACtCC,EACJvC,EAAYwC,6BAA6B,CAACC,IAAI,CAACzC,GAE3C0C,EAAoB,MAAOC,GAC/B3C,EACG4C,MAAM,CAAC7B,EAAKC,EAAK,CAChBe,MAAO,CACL,GAAGA,CAAK,CACR,GAAGC,CAAM,AACX,SACAA,EACAa,2BAAAA,CACGC,CAD0BrC,CAC1BqC,CACHC,MAFqCrC,GAAG,AACJ,CAAjCoC,SACqCG,CAApBD,AAAoBC,EACxCC,KADoE,CAAxCzC,QAAQC,CACpCwC,CACGC,CAFoC,AACtB1C,AACd0C,CAFqCF,CAEb,AAG3BG,MAJyB1C,GAAG,CACzByC,GAGWlB,EAAkBoB,OAAO,CACvCC,gBAAgB,EAChBC,IAAKvD,EAAYkB,KAAK,CACtBd,KAAM,4BAENoD,kBAAkB,CAAEtB,MAAAA,EAAAA,KAAAA,EAAAA,EAAqBuB,UAAU,CAEnDC,QAAS,CAAC,GAAGC,IACXpB,EAAexB,KAAQ4C,EAC3B,GACCC,OAAO,CAAC,KACP,GAAI,CAACjB,EAAM,OAEXA,EAAKkB,aAAa,CAAC,CACjB,mBAAoB7C,EAAIU,UAAU,CAClC,YAAY,CACd,GAEA,IAAMoC,EAAqB1B,EAAO2B,qBAAqB,GAEvD,GAAI,CAACD,EACH,OAGF,GACEA,EAAmBE,GAAG,CAAC,EALA,kBAMvBnE,EAAAA,cAAAA,CAAeoE,aAAa,CAC5B,YACAC,QAAQC,IAAI,CACV,CAAC,2BAA2B,EAAEL,EAAmBE,GAAG,CAClD,kBACA,qEAAqE,CAAC,EAK5E,IAAMI,EAAQN,EAAmBE,GAAG,CAAC,cACrC,GAAII,EAAO,CACT,IAAMC,EAAO,CAAA,EAAGlC,EAAO,CAAC,EAAEiC,EAAAA,CAAO,CAEjCzB,EAAKkB,aAAa,CAAC,CACjB,aAAcO,EACd,aAAcA,EACd,iBAAkBC,CACpB,GACA1B,EAAK2B,UAAU,CAACD,EAClB,MACE1B,CADK,CACA2B,UAAU,CAAC,CAAA,EAAGnC,EAAO,CAAC,EAAEd,EAAAA,CAAS,CAE1C,GAIAgB,EACF,MAAMK,EAAkBL,EADV,CAGd,MAAMD,EAAOmC,qBAAqB,CAACxD,EAAIyD,OAAO,CAAE,IAC9CpC,EAAOqC,KAAK,CACV5E,EAAAA,cAAAA,CAAeoE,aAAa,CAC5B,CACES,SAAU,CAAA,EAAGvC,EAAO,CAAC,EAAEd,EAAAA,CAAS,CAChCnB,KAAMN,EAAAA,QAAAA,CAAS+E,MAAM,CACrBC,WAAY,CACV,cAAezC,EACf,cAAepB,EAAI8D,GACrB,AADwB,CAE1B,EACAnC,GAIR,CAAE,MAAOoC,EAAK,CAEZ,GAAI9E,EAAYkB,KAAK,CACnB,CADqB,KACf4D,KAIRxF,EAAAA,SAAAA,EAAU0B,EAAwB,IAAK,wBACzC,QAAU,CAIRC,AAAa,OAAA,CAATW,IAAS,KAAA,EAAbX,EAAIW,SAAS,CAAA,IAAA,CAAbX,EAAgBY,QAAQC,OAAO,GACjC,CACF","ignoreList":[3]}