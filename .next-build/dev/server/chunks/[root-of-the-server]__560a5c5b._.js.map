{
  "version": 3,
  "sources": [],
  "sections": [
    {"offset": {"line": 62, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/jurit/OneDrive/Desktop/sito%20upscale/lib/openai.js"],"sourcesContent":["// OpenAI API integration with official SDK\r\nimport OpenAI from 'openai';\r\n\r\nconst openai = new OpenAI({\r\n  apiKey: process.env.OPENAI_API_KEY,\r\n});\r\n\r\n// Generate embeddings for text\r\nexport async function generateEmbedding(text) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const response = await openai.embeddings.create({\r\n      model: 'text-embedding-3-small',\r\n      input: text.substring(0, 8000), // Limit input size\r\n    });\r\n\r\n    return response.data[0].embedding;\r\n  } catch (error) {\r\n    console.error('Error generating embedding:', error);\r\n    throw new Error(`Failed to generate embedding: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Generate embeddings in batch for an array of texts\r\nexport async function generateEmbeddingsBatch(texts) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  if (!Array.isArray(texts) || texts.length === 0) return [];\r\n\r\n  try {\r\n    const response = await openai.embeddings.create({\r\n      model: 'text-embedding-3-small',\r\n      input: texts.map(t => (t || '').toString().substring(0, 8000)),\r\n    });\r\n\r\n    return response.data.map(d => d.embedding);\r\n  } catch (error) {\r\n    console.error('Error generating batch embeddings:', error);\r\n    throw new Error(`Failed to generate batch embeddings: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Chat completion using OpenAI GPT models\r\nexport async function chatCompletion(messages, options = {}) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const response = await openai.chat.completions.create({\r\n      model: options.model || 'gpt-4o-mini', // Fast and affordable\r\n      messages: messages,\r\n      temperature: options.temperature || 0.7,\r\n      max_tokens: options.max_tokens || 1000,\r\n      top_p: options.top_p || 1,\r\n      frequency_penalty: options.frequency_penalty || 0,\r\n      presence_penalty: options.presence_penalty || 0,\r\n    });\r\n\r\n    return response.choices[0].message.content;\r\n  } catch (error) {\r\n    console.error('Error in chat completion:', error);\r\n    \r\n    // Handle specific OpenAI errors\r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 500) {\r\n      throw new Error('Errore del server OpenAI. Riprova più tardi.');\r\n    }\r\n    \r\n    throw new Error(`Errore nella comunicazione con OpenAI: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Generate summary\r\nexport async function generateSummary(text, maxLength = 200) {\r\n  const messages = [\r\n    {\r\n      role: 'system',\r\n      content: 'You are a helpful assistant that creates concise summaries.',\r\n    },\r\n    {\r\n      role: 'user',\r\n      content: `Summarize the following text in ${maxLength} words or less:\\n\\n${text}`,\r\n    },\r\n  ];\r\n\r\n  return await chatCompletion(messages, { temperature: 0.5, max_tokens: 300 });\r\n}\r\n\r\n// Generate tags\r\nexport async function generateTags(text, count = 5) {\r\n  const messages = [\r\n    {\r\n      role: 'system',\r\n      content: 'You are a helpful assistant that generates relevant tags for documents. Return only comma-separated tags, no explanations.',\r\n    },\r\n    {\r\n      role: 'user',\r\n      content: `Generate ${count} relevant tags for this document:\\n\\n${text.substring(0, 2000)}`,\r\n    },\r\n  ];\r\n\r\n  const response = await chatCompletion(messages, { temperature: 0.3, max_tokens: 100 });\r\n  \r\n  return response\r\n    .split(',')\r\n    .map(tag => tag.trim().toLowerCase())\r\n    .filter(tag => tag.length > 0)\r\n    .slice(0, count);\r\n}\r\n\r\n// Classify document\r\nexport async function classifyDocument(text) {\r\n  const categories = [\r\n    'contract', 'invoice', 'report', 'presentation', \r\n    'spreadsheet', 'image', 'code', 'email', 'article', 'other'\r\n  ];\r\n\r\n  const messages = [\r\n    {\r\n      role: 'system',\r\n      content: `You are a document classifier. Classify the document into one or more of these categories: ${categories.join(', ')}. Return only category names, comma-separated.`,\r\n    },\r\n    {\r\n      role: 'user',\r\n      content: `Classify this document:\\n\\n${text.substring(0, 1000)}`,\r\n    },\r\n  ];\r\n\r\n  const response = await chatCompletion(messages, { temperature: 0.2, max_tokens: 50 });\r\n  \r\n  return response\r\n    .split(',')\r\n    .map(cat => cat.trim().toLowerCase())\r\n    .filter(cat => categories.includes(cat));\r\n}\r\n\r\n// Vision API - Analizza immagini come ChatGPT\r\nexport async function analyzeImageWithVision(imageBuffer, imageMimeType, query = 'Cosa contiene questa immagine? Descrivi tutto ciò che vedi.') {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    // Converti il buffer in base64\r\n    const base64Image = imageBuffer.toString('base64');\r\n    \r\n    const response = await openai.chat.completions.create({\r\n      model: 'gpt-4o', // GPT-4o supporta vision\r\n      messages: [\r\n        {\r\n          role: 'system',\r\n          content: 'Sei un assistente AI esperto nell\\'analisi di immagini. Descrivi in dettaglio tutto ciò che vedi nell\\'immagine, inclusi testo, oggetti, persone, scene, colori e qualsiasi altro dettaglio rilevante. Rispondi sempre in italiano.'\r\n        },\r\n        {\r\n          role: 'user',\r\n          content: [\r\n            {\r\n              type: 'text',\r\n              text: query\r\n            },\r\n            {\r\n              type: 'image_url',\r\n              image_url: {\r\n                url: `data:${imageMimeType};base64,${base64Image}`,\r\n                detail: 'high'\r\n              }\r\n            }\r\n          ]\r\n        }\r\n      ],\r\n      max_tokens: 2000,\r\n      temperature: 0.2\r\n    });\r\n\r\n    return response.choices[0].message.content;\r\n  } catch (error) {\r\n    console.error('Error in vision API:', error);\r\n    \r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 400 && error.message?.includes('image')) {\r\n      throw new Error('Formato immagine non supportato o immagine troppo grande.');\r\n    }\r\n    \r\n    throw new Error(`Errore nell'analisi dell'immagine: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Estrazione testo da PDF con OpenAI Responses API (gpt-4o) usando input_file\r\n// Ritorna SOLO la stringa di testo estratto (no IDs, no oggetti)\r\nexport async function extractTextFromPdfWithOpenAI(filePath) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  const fs = await import('fs');\r\n  \r\n  let uploadedFile = null;\r\n  try {\r\n    console.log('Caricamento PDF su OpenAI (Responses API):', filePath);\r\n    \r\n    // 1) Carica il file su OpenAI come user_data\r\n    uploadedFile = await openai.files.create({\r\n      file: fs.createReadStream(filePath),\r\n      purpose: 'user_data'\r\n    });\r\n\r\n    console.log('File caricato su OpenAI:', uploadedFile.id);\r\n\r\n    // 2) Richiesta al modello GPT-4o per estrazione testo dal file caricato\r\n    const response = await openai.responses.create({\r\n      model: 'gpt-4o',\r\n      input: [\r\n        {\r\n          role: 'user',\r\n          content: [\r\n            { type: 'input_text', text: 'Estrai tutto il testo e le informazioni rilevanti da questo documento. Rispondi SOLO con il testo estratto, senza commenti.' },\r\n            { type: 'input_file', file_id: uploadedFile.id }\r\n          ]\r\n        }\r\n      ],\r\n      max_output_tokens: 8000,\r\n      temperature: 0.1\r\n    });\r\n\r\n    // 3) Prendi solo testo\r\n    const extractedText = (response.output_text || '').toString().trim();\r\n    console.log(`Testo estratto da PDF: ${extractedText.length} caratteri`);\r\n    \r\n    if (!extractedText) {\r\n      throw new Error('Nessun testo estratto dal PDF');\r\n    }\r\n\r\n    return extractedText;\r\n\r\n  } catch (error) {\r\n    console.error('Error in PDF text extraction (Responses API):', error);\r\n    \r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 400) {\r\n      throw new Error('Errore nell\\'analisi del PDF con Responses API. Il file potrebbe essere troppo grande o danneggiato.');\r\n    }\r\n    \r\n    throw new Error(`Errore nell'estrazione del testo PDF: ${error.message}`);\r\n  } finally {\r\n    // 4) Prova a rimuovere il file caricato (se l'SDK lo supporta)\r\n    try {\r\n      if (uploadedFile && uploadedFile.id) {\r\n        if (openai.files?.delete) {\r\n          await openai.files.delete(uploadedFile.id);\r\n        } else if (openai.files?.del) {\r\n          await openai.files.del(uploadedFile.id);\r\n        }\r\n        console.log('File rimosso da OpenAI:', uploadedFile.id);\r\n      }\r\n    } catch (delError) {\r\n      console.warn('Errore rimozione file da OpenAI (ignorato):', delError?.message || delError);\r\n    }\r\n  }\r\n}\r\n\r\n// DALL-E 3 - Get image URL only (faster, for streaming)\r\nexport async function getImageUrlFromDALLE(prompt, options = {}) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const size = options.size || '1024x1024';\r\n    const quality = options.quality || 'standard';\r\n    const style = options.style || 'vivid';\r\n\r\n    const response = await openai.images.generate({\r\n      model: 'dall-e-3',\r\n      prompt: prompt,\r\n      size: size,\r\n      quality: quality,\r\n      style: style,\r\n      n: 1,\r\n    });\r\n\r\n    const imageUrl = response.data[0]?.url;\r\n    if (!imageUrl) {\r\n      throw new Error('Nessuna immagine generata da DALL-E');\r\n    }\r\n\r\n    return imageUrl;\r\n  } catch (error) {\r\n    console.error('Error getting image URL from DALL-E:', error);\r\n    console.error('Error details:', {\r\n      status: error.status,\r\n      statusText: error.statusText,\r\n      message: error.message,\r\n      code: error.code,\r\n      response: error.response?.data || error.response\r\n    });\r\n    \r\n    if (error.status === 401) {\r\n      throw new Error('Chiave API OpenAI non valida. Verifica la configurazione.');\r\n    } else if (error.status === 429) {\r\n      throw new Error('Limite di rate raggiunto. Riprova tra qualche secondo.');\r\n    } else if (error.status === 400) {\r\n      const errorMessage = error.message || error.response?.data?.error?.message || 'Prompt non valido o contenuto non consentito';\r\n      throw new Error(`Errore nella generazione: ${errorMessage}`);\r\n    } else if (error.code === 'ENOTFOUND' || error.code === 'ECONNREFUSED') {\r\n      throw new Error('Errore di connessione con OpenAI. Verifica la tua connessione internet.');\r\n    }\r\n    \r\n    throw new Error(`Errore nella generazione dell'immagine: ${error.message || 'Errore sconosciuto'}`);\r\n  }\r\n}\r\n\r\n// DALL-E 3 - Generazione immagini (download completo, per backward compatibility)\r\nexport async function generateImageWithDALLE(prompt, options = {}) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    const imageUrl = await getImageUrlFromDALLE(prompt, options);\r\n\r\n    // Download the image and return as buffer\r\n    const imageResponse = await fetch(imageUrl);\r\n    if (!imageResponse.ok) {\r\n      const errorText = await imageResponse.text().catch(() => 'Unknown error');\r\n      throw new Error(`Errore nel download dell'immagine generata: ${imageResponse.status} ${imageResponse.statusText}. ${errorText}`);\r\n    }\r\n\r\n    const arrayBuffer = await imageResponse.arrayBuffer();\r\n    return Buffer.from(arrayBuffer);\r\n  } catch (error) {\r\n    // Re-throw errors from getImageUrlFromDALLE\r\n    throw error;\r\n  }\r\n}\r\n\r\n// DALL-E 3 - Upscale/Miglioramento immagine usando variante\r\nexport async function upscaleImageWithDALLE(imageBuffer, imageMimeType, enhancementPrompt = null) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    // 1. Analizza l'immagine con Vision API per creare un prompt descrittivo\r\n    const analysisPrompt = enhancementPrompt || 'Descrivi in dettaglio questa immagine, includendo tutti i dettagli visivi, colori, composizione, stile e qualità. La descrizione sarà usata per creare una versione migliorata ad alta risoluzione.';\r\n    \r\n    const imageDescription = await analyzeImageWithVision(\r\n      imageBuffer, \r\n      imageMimeType, \r\n      analysisPrompt\r\n    );\r\n\r\n    // 2. Crea un prompt per DALL-E che migliora l'immagine\r\n    const enhancementPromptText = `Crea una versione migliorata e ad alta risoluzione di questa immagine: ${imageDescription}. Mantieni fedeltà ai dettagli originali ma migliora la qualità, la nitidezza e la risoluzione.`;\r\n\r\n    // 3. Genera immagine migliorata con DALL-E 3 in alta risoluzione\r\n    const enhancedImageBuffer = await generateImageWithDALLE(enhancementPromptText, {\r\n      size: '1792x1024', // Formato landscape per alta risoluzione\r\n      quality: 'hd',\r\n      style: 'natural'\r\n    });\r\n\r\n    return enhancedImageBuffer;\r\n  } catch (error) {\r\n    console.error('Error upscaling image with DALL-E:', error);\r\n    throw new Error(`Errore nel miglioramento dell'immagine: ${error.message}`);\r\n  }\r\n}\r\n\r\n// Enhance existing image quality using AI analysis + sharp processing\r\nexport async function enhanceImageQualityWithAI(imageBuffer, imageMimeType) {\r\n  if (!process.env.OPENAI_API_KEY) {\r\n    throw new Error('OPENAI_API_KEY is not configured. Please set it in your environment variables.');\r\n  }\r\n\r\n  try {\r\n    // Use Vision API to analyze image quality issues\r\n    const analysisPrompt = `Analyze this image and identify specific quality issues that need improvement. Focus on:\r\n1. Noise level (low/medium/high)\r\n2. Sharpness (blurry/sharp)\r\n3. Color accuracy (washed out/vibrant)\r\n4. Artifacts (compression artifacts, pixelation)\r\n5. Overall quality issues\r\n\r\nRespond with a JSON object: {\"noise\": \"low|medium|high\", \"sharpness\": \"blurry|moderate|sharp\", \"color\": \"washed|normal|vibrant\", \"artifacts\": \"none|minor|major\", \"recommendations\": \"brief description\"}`;\r\n    \r\n    const analysisResult = await analyzeImageWithVision(\r\n      imageBuffer, \r\n      imageMimeType, \r\n      analysisPrompt\r\n    );\r\n\r\n    // Parse analysis result\r\n    let analysis = {\r\n      noise: 'medium',\r\n      sharpness: 'moderate',\r\n      color: 'normal',\r\n      artifacts: 'none'\r\n    };\r\n\r\n    try {\r\n      // Try to parse JSON from analysis\r\n      const jsonMatch = analysisResult.match(/\\{[\\s\\S]*\\}/);\r\n      if (jsonMatch) {\r\n        const parsed = JSON.parse(jsonMatch[0]);\r\n        analysis = { ...analysis, ...parsed };\r\n      }\r\n    } catch (parseError) {\r\n      console.warn('Could not parse AI analysis, using defaults');\r\n    }\r\n\r\n    // Apply targeted enhancements using sharp based on AI analysis\r\n    const sharp = (await import('sharp')).default;\r\n    let enhanced = sharp(imageBuffer, { sequentialRead: true });\r\n\r\n    // Apply denoising if needed\r\n    if (analysis.noise === 'high' || analysis.noise === 'medium') {\r\n      enhanced = enhanced.median(analysis.noise === 'high' ? 3 : 2);\r\n    }\r\n\r\n    // Apply sharpening based on analysis\r\n    if (analysis.sharpness === 'blurry') {\r\n      enhanced = enhanced.sharpen({\r\n        sigma: 2.0,\r\n        m1: 1.0,\r\n        m2: 0.5,\r\n        x1: 3,\r\n        y2: 3,\r\n        y3: 3\r\n      });\r\n    } else if (analysis.sharpness === 'moderate') {\r\n      enhanced = enhanced.sharpen({\r\n        sigma: 1.0,\r\n        m1: 0.7,\r\n        m2: 0.4\r\n      });\r\n    }\r\n\r\n    // Enhance color if needed\r\n    if (analysis.color === 'washed') {\r\n      enhanced = enhanced.modulate({\r\n        saturation: 1.15,\r\n        brightness: 1.05\r\n      }).linear(1.05, -(128 * 0.05)); // Slight contrast boost\r\n    }\r\n\r\n    // Remove compression artifacts\r\n    if (analysis.artifacts === 'major' || analysis.artifacts === 'minor') {\r\n      enhanced = enhanced.png({\r\n        quality: 100,\r\n        compressionLevel: 6,\r\n        adaptiveFiltering: true\r\n      });\r\n    } else {\r\n      // Keep original format but with high quality\r\n      if (imageMimeType === 'image/jpeg' || imageMimeType === 'image/jpg') {\r\n        enhanced = enhanced.jpeg({\r\n          quality: 98,\r\n          mozjpeg: true,\r\n          trellisQuantisation: true,\r\n          overshootDeringing: true\r\n        });\r\n      } else {\r\n        enhanced = enhanced.png({\r\n          quality: 100,\r\n          compressionLevel: 6\r\n        });\r\n      }\r\n    }\r\n\r\n    const enhancedBuffer = await enhanced.toBuffer();\r\n    return enhancedBuffer;\r\n  } catch (error) {\r\n    console.error('Error enhancing image quality with AI:', error);\r\n    // Return original buffer if enhancement fails\r\n    return imageBuffer;\r\n  }\r\n}\r\n"],"names":[],"mappings":"AAAA,2CAA2C;;;;;;;;;;;;;;;;;;;;;;;;;;;AAC3C;;;;;;AAEA,MAAM,SAAS,IAAI,uHAAM,CAAC;IACxB,QAAQ,QAAQ,GAAG,CAAC,cAAc;AACpC;AAGO,eAAe,kBAAkB,IAAI;IAC1C,IAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,EAAE;QAC/B,MAAM,IAAI,MAAM;IAClB;IAEA,IAAI;QACF,MAAM,WAAW,MAAM,OAAO,UAAU,CAAC,MAAM,CAAC;YAC9C,OAAO;YACP,OAAO,KAAK,SAAS,CAAC,GAAG;QAC3B;QAEA,OAAO,SAAS,IAAI,CAAC,EAAE,CAAC,SAAS;IACnC,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,+BAA+B;QAC7C,MAAM,IAAI,MAAM,CAAC,8BAA8B,EAAE,MAAM,OAAO,EAAE;IAClE;AACF;AAGO,eAAe,wBAAwB,KAAK;IACjD,IAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,EAAE;QAC/B,MAAM,IAAI,MAAM;IAClB;IAEA,IAAI,CAAC,MAAM,OAAO,CAAC,UAAU,MAAM,MAAM,KAAK,GAAG,OAAO,EAAE;IAE1D,IAAI;QACF,MAAM,WAAW,MAAM,OAAO,UAAU,CAAC,MAAM,CAAC;YAC9C,OAAO;YACP,OAAO,MAAM,GAAG,CAAC,CAAA,IAAK,CAAC,KAAK,EAAE,EAAE,QAAQ,GAAG,SAAS,CAAC,GAAG;QAC1D;QAEA,OAAO,SAAS,IAAI,CAAC,GAAG,CAAC,CAAA,IAAK,EAAE,SAAS;IAC3C,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,sCAAsC;QACpD,MAAM,IAAI,MAAM,CAAC,qCAAqC,EAAE,MAAM,OAAO,EAAE;IACzE;AACF;AAGO,eAAe,eAAe,QAAQ,EAAE,UAAU,CAAC,CAAC;IACzD,IAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,EAAE;QAC/B,MAAM,IAAI,MAAM;IAClB;IAEA,IAAI;QACF,MAAM,WAAW,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACpD,OAAO,QAAQ,KAAK,IAAI;YACxB,UAAU;YACV,aAAa,QAAQ,WAAW,IAAI;YACpC,YAAY,QAAQ,UAAU,IAAI;YAClC,OAAO,QAAQ,KAAK,IAAI;YACxB,mBAAmB,QAAQ,iBAAiB,IAAI;YAChD,kBAAkB,QAAQ,gBAAgB,IAAI;QAChD;QAEA,OAAO,SAAS,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO;IAC5C,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,6BAA6B;QAE3C,gCAAgC;QAChC,IAAI,MAAM,MAAM,KAAK,KAAK;YACxB,MAAM,IAAI,MAAM;QAClB,OAAO,IAAI,MAAM,MAAM,KAAK,KAAK;YAC/B,MAAM,IAAI,MAAM;QAClB,OAAO,IAAI,MAAM,MAAM,KAAK,KAAK;YAC/B,MAAM,IAAI,MAAM;QAClB;QAEA,MAAM,IAAI,MAAM,CAAC,uCAAuC,EAAE,MAAM,OAAO,EAAE;IAC3E;AACF;AAGO,eAAe,gBAAgB,IAAI,EAAE,YAAY,GAAG;IACzD,MAAM,WAAW;QACf;YACE,MAAM;YACN,SAAS;QACX;QACA;YACE,MAAM;YACN,SAAS,CAAC,gCAAgC,EAAE,UAAU,mBAAmB,EAAE,MAAM;QACnF;KACD;IAED,OAAO,MAAM,eAAe,UAAU;QAAE,aAAa;QAAK,YAAY;IAAI;AAC5E;AAGO,eAAe,aAAa,IAAI,EAAE,QAAQ,CAAC;IAChD,MAAM,WAAW;QACf;YACE,MAAM;YACN,SAAS;QACX;QACA;YACE,MAAM;YACN,SAAS,CAAC,SAAS,EAAE,MAAM,qCAAqC,EAAE,KAAK,SAAS,CAAC,GAAG,OAAO;QAC7F;KACD;IAED,MAAM,WAAW,MAAM,eAAe,UAAU;QAAE,aAAa;QAAK,YAAY;IAAI;IAEpF,OAAO,SACJ,KAAK,CAAC,KACN,GAAG,CAAC,CAAA,MAAO,IAAI,IAAI,GAAG,WAAW,IACjC,MAAM,CAAC,CAAA,MAAO,IAAI,MAAM,GAAG,GAC3B,KAAK,CAAC,GAAG;AACd;AAGO,eAAe,iBAAiB,IAAI;IACzC,MAAM,aAAa;QACjB;QAAY;QAAW;QAAU;QACjC;QAAe;QAAS;QAAQ;QAAS;QAAW;KACrD;IAED,MAAM,WAAW;QACf;YACE,MAAM;YACN,SAAS,CAAC,2FAA2F,EAAE,WAAW,IAAI,CAAC,MAAM,8CAA8C,CAAC;QAC9K;QACA;YACE,MAAM;YACN,SAAS,CAAC,2BAA2B,EAAE,KAAK,SAAS,CAAC,GAAG,OAAO;QAClE;KACD;IAED,MAAM,WAAW,MAAM,eAAe,UAAU;QAAE,aAAa;QAAK,YAAY;IAAG;IAEnF,OAAO,SACJ,KAAK,CAAC,KACN,GAAG,CAAC,CAAA,MAAO,IAAI,IAAI,GAAG,WAAW,IACjC,MAAM,CAAC,CAAA,MAAO,WAAW,QAAQ,CAAC;AACvC;AAGO,eAAe,uBAAuB,WAAW,EAAE,aAAa,EAAE,QAAQ,6DAA6D;IAC5I,IAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,EAAE;QAC/B,MAAM,IAAI,MAAM;IAClB;IAEA,IAAI;QACF,+BAA+B;QAC/B,MAAM,cAAc,YAAY,QAAQ,CAAC;QAEzC,MAAM,WAAW,MAAM,OAAO,IAAI,CAAC,WAAW,CAAC,MAAM,CAAC;YACpD,OAAO;YACP,UAAU;gBACR;oBACE,MAAM;oBACN,SAAS;gBACX;gBACA;oBACE,MAAM;oBACN,SAAS;wBACP;4BACE,MAAM;4BACN,MAAM;wBACR;wBACA;4BACE,MAAM;4BACN,WAAW;gCACT,KAAK,CAAC,KAAK,EAAE,cAAc,QAAQ,EAAE,aAAa;gCAClD,QAAQ;4BACV;wBACF;qBACD;gBACH;aACD;YACD,YAAY;YACZ,aAAa;QACf;QAEA,OAAO,SAAS,OAAO,CAAC,EAAE,CAAC,OAAO,CAAC,OAAO;IAC5C,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,wBAAwB;QAEtC,IAAI,MAAM,MAAM,KAAK,KAAK;YACxB,MAAM,IAAI,MAAM;QAClB,OAAO,IAAI,MAAM,MAAM,KAAK,KAAK;YAC/B,MAAM,IAAI,MAAM;QAClB,OAAO,IAAI,MAAM,MAAM,KAAK,OAAO,MAAM,OAAO,EAAE,SAAS,UAAU;YACnE,MAAM,IAAI,MAAM;QAClB;QAEA,MAAM,IAAI,MAAM,CAAC,mCAAmC,EAAE,MAAM,OAAO,EAAE;IACvE;AACF;AAIO,eAAe,6BAA6B,QAAQ;IACzD,IAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,EAAE;QAC/B,MAAM,IAAI,MAAM;IAClB;IAEA,MAAM,KAAK;IAEX,IAAI,eAAe;IACnB,IAAI;QACF,QAAQ,GAAG,CAAC,8CAA8C;QAE1D,6CAA6C;QAC7C,eAAe,MAAM,OAAO,KAAK,CAAC,MAAM,CAAC;YACvC,MAAM,GAAG,gBAAgB,CAAC;YAC1B,SAAS;QACX;QAEA,QAAQ,GAAG,CAAC,4BAA4B,aAAa,EAAE;QAEvD,wEAAwE;QACxE,MAAM,WAAW,MAAM,OAAO,SAAS,CAAC,MAAM,CAAC;YAC7C,OAAO;YACP,OAAO;gBACL;oBACE,MAAM;oBACN,SAAS;wBACP;4BAAE,MAAM;4BAAc,MAAM;wBAA8H;wBAC1J;4BAAE,MAAM;4BAAc,SAAS,aAAa,EAAE;wBAAC;qBAChD;gBACH;aACD;YACD,mBAAmB;YACnB,aAAa;QACf;QAEA,uBAAuB;QACvB,MAAM,gBAAgB,CAAC,SAAS,WAAW,IAAI,EAAE,EAAE,QAAQ,GAAG,IAAI;QAClE,QAAQ,GAAG,CAAC,CAAC,uBAAuB,EAAE,cAAc,MAAM,CAAC,UAAU,CAAC;QAEtE,IAAI,CAAC,eAAe;YAClB,MAAM,IAAI,MAAM;QAClB;QAEA,OAAO;IAET,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,iDAAiD;QAE/D,IAAI,MAAM,MAAM,KAAK,KAAK;YACxB,MAAM,IAAI,MAAM;QAClB,OAAO,IAAI,MAAM,MAAM,KAAK,KAAK;YAC/B,MAAM,IAAI,MAAM;QAClB,OAAO,IAAI,MAAM,MAAM,KAAK,KAAK;YAC/B,MAAM,IAAI,MAAM;QAClB;QAEA,MAAM,IAAI,MAAM,CAAC,sCAAsC,EAAE,MAAM,OAAO,EAAE;IAC1E,SAAU;QACR,+DAA+D;QAC/D,IAAI;YACF,IAAI,gBAAgB,aAAa,EAAE,EAAE;gBACnC,IAAI,OAAO,KAAK,EAAE,QAAQ;oBACxB,MAAM,OAAO,KAAK,CAAC,MAAM,CAAC,aAAa,EAAE;gBAC3C,OAAO,IAAI,OAAO,KAAK,EAAE,KAAK;oBAC5B,MAAM,OAAO,KAAK,CAAC,GAAG,CAAC,aAAa,EAAE;gBACxC;gBACA,QAAQ,GAAG,CAAC,2BAA2B,aAAa,EAAE;YACxD;QACF,EAAE,OAAO,UAAU;YACjB,QAAQ,IAAI,CAAC,+CAA+C,UAAU,WAAW;QACnF;IACF;AACF;AAGO,eAAe,qBAAqB,MAAM,EAAE,UAAU,CAAC,CAAC;IAC7D,IAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,EAAE;QAC/B,MAAM,IAAI,MAAM;IAClB;IAEA,IAAI;QACF,MAAM,OAAO,QAAQ,IAAI,IAAI;QAC7B,MAAM,UAAU,QAAQ,OAAO,IAAI;QACnC,MAAM,QAAQ,QAAQ,KAAK,IAAI;QAE/B,MAAM,WAAW,MAAM,OAAO,MAAM,CAAC,QAAQ,CAAC;YAC5C,OAAO;YACP,QAAQ;YACR,MAAM;YACN,SAAS;YACT,OAAO;YACP,GAAG;QACL;QAEA,MAAM,WAAW,SAAS,IAAI,CAAC,EAAE,EAAE;QACnC,IAAI,CAAC,UAAU;YACb,MAAM,IAAI,MAAM;QAClB;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,wCAAwC;QACtD,QAAQ,KAAK,CAAC,kBAAkB;YAC9B,QAAQ,MAAM,MAAM;YACpB,YAAY,MAAM,UAAU;YAC5B,SAAS,MAAM,OAAO;YACtB,MAAM,MAAM,IAAI;YAChB,UAAU,MAAM,QAAQ,EAAE,QAAQ,MAAM,QAAQ;QAClD;QAEA,IAAI,MAAM,MAAM,KAAK,KAAK;YACxB,MAAM,IAAI,MAAM;QAClB,OAAO,IAAI,MAAM,MAAM,KAAK,KAAK;YAC/B,MAAM,IAAI,MAAM;QAClB,OAAO,IAAI,MAAM,MAAM,KAAK,KAAK;YAC/B,MAAM,eAAe,MAAM,OAAO,IAAI,MAAM,QAAQ,EAAE,MAAM,OAAO,WAAW;YAC9E,MAAM,IAAI,MAAM,CAAC,0BAA0B,EAAE,cAAc;QAC7D,OAAO,IAAI,MAAM,IAAI,KAAK,eAAe,MAAM,IAAI,KAAK,gBAAgB;YACtE,MAAM,IAAI,MAAM;QAClB;QAEA,MAAM,IAAI,MAAM,CAAC,wCAAwC,EAAE,MAAM,OAAO,IAAI,sBAAsB;IACpG;AACF;AAGO,eAAe,uBAAuB,MAAM,EAAE,UAAU,CAAC,CAAC;IAC/D,IAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,EAAE;QAC/B,MAAM,IAAI,MAAM;IAClB;IAEA,IAAI;QACF,MAAM,WAAW,MAAM,qBAAqB,QAAQ;QAEpD,0CAA0C;QAC1C,MAAM,gBAAgB,MAAM,MAAM;QAClC,IAAI,CAAC,cAAc,EAAE,EAAE;YACrB,MAAM,YAAY,MAAM,cAAc,IAAI,GAAG,KAAK,CAAC,IAAM;YACzD,MAAM,IAAI,MAAM,CAAC,4CAA4C,EAAE,cAAc,MAAM,CAAC,CAAC,EAAE,cAAc,UAAU,CAAC,EAAE,EAAE,WAAW;QACjI;QAEA,MAAM,cAAc,MAAM,cAAc,WAAW;QACnD,OAAO,OAAO,IAAI,CAAC;IACrB,EAAE,OAAO,OAAO;QACd,4CAA4C;QAC5C,MAAM;IACR;AACF;AAGO,eAAe,sBAAsB,WAAW,EAAE,aAAa,EAAE,oBAAoB,IAAI;IAC9F,IAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,EAAE;QAC/B,MAAM,IAAI,MAAM;IAClB;IAEA,IAAI;QACF,yEAAyE;QACzE,MAAM,iBAAiB,qBAAqB;QAE5C,MAAM,mBAAmB,MAAM,uBAC7B,aACA,eACA;QAGF,uDAAuD;QACvD,MAAM,wBAAwB,CAAC,uEAAuE,EAAE,iBAAiB,+FAA+F,CAAC;QAEzN,iEAAiE;QACjE,MAAM,sBAAsB,MAAM,uBAAuB,uBAAuB;YAC9E,MAAM;YACN,SAAS;YACT,OAAO;QACT;QAEA,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,sCAAsC;QACpD,MAAM,IAAI,MAAM,CAAC,wCAAwC,EAAE,MAAM,OAAO,EAAE;IAC5E;AACF;AAGO,eAAe,0BAA0B,WAAW,EAAE,aAAa;IACxE,IAAI,CAAC,QAAQ,GAAG,CAAC,cAAc,EAAE;QAC/B,MAAM,IAAI,MAAM;IAClB;IAEA,IAAI;QACF,iDAAiD;QACjD,MAAM,iBAAiB,CAAC;;;;;;;yMAO6K,CAAC;QAEtM,MAAM,iBAAiB,MAAM,uBAC3B,aACA,eACA;QAGF,wBAAwB;QACxB,IAAI,WAAW;YACb,OAAO;YACP,WAAW;YACX,OAAO;YACP,WAAW;QACb;QAEA,IAAI;YACF,kCAAkC;YAClC,MAAM,YAAY,eAAe,KAAK,CAAC;YACvC,IAAI,WAAW;gBACb,MAAM,SAAS,KAAK,KAAK,CAAC,SAAS,CAAC,EAAE;gBACtC,WAAW;oBAAE,GAAG,QAAQ;oBAAE,GAAG,MAAM;gBAAC;YACtC;QACF,EAAE,OAAO,YAAY;YACnB,QAAQ,IAAI,CAAC;QACf;QAEA,+DAA+D;QAC/D,MAAM,QAAQ,CAAC,wFAAqB,EAAE,OAAO;QAC7C,IAAI,WAAW,MAAM,aAAa;YAAE,gBAAgB;QAAK;QAEzD,4BAA4B;QAC5B,IAAI,SAAS,KAAK,KAAK,UAAU,SAAS,KAAK,KAAK,UAAU;YAC5D,WAAW,SAAS,MAAM,CAAC,SAAS,KAAK,KAAK,SAAS,IAAI;QAC7D;QAEA,qCAAqC;QACrC,IAAI,SAAS,SAAS,KAAK,UAAU;YACnC,WAAW,SAAS,OAAO,CAAC;gBAC1B,OAAO;gBACP,IAAI;gBACJ,IAAI;gBACJ,IAAI;gBACJ,IAAI;gBACJ,IAAI;YACN;QACF,OAAO,IAAI,SAAS,SAAS,KAAK,YAAY;YAC5C,WAAW,SAAS,OAAO,CAAC;gBAC1B,OAAO;gBACP,IAAI;gBACJ,IAAI;YACN;QACF;QAEA,0BAA0B;QAC1B,IAAI,SAAS,KAAK,KAAK,UAAU;YAC/B,WAAW,SAAS,QAAQ,CAAC;gBAC3B,YAAY;gBACZ,YAAY;YACd,GAAG,MAAM,CAAC,MAAM,CAAE,MAAM,OAAQ,wBAAwB;QAC1D;QAEA,+BAA+B;QAC/B,IAAI,SAAS,SAAS,KAAK,WAAW,SAAS,SAAS,KAAK,SAAS;YACpE,WAAW,SAAS,GAAG,CAAC;gBACtB,SAAS;gBACT,kBAAkB;gBAClB,mBAAmB;YACrB;QACF,OAAO;YACL,6CAA6C;YAC7C,IAAI,kBAAkB,gBAAgB,kBAAkB,aAAa;gBACnE,WAAW,SAAS,IAAI,CAAC;oBACvB,SAAS;oBACT,SAAS;oBACT,qBAAqB;oBACrB,oBAAoB;gBACtB;YACF,OAAO;gBACL,WAAW,SAAS,GAAG,CAAC;oBACtB,SAAS;oBACT,kBAAkB;gBACpB;YACF;QACF;QAEA,MAAM,iBAAiB,MAAM,SAAS,QAAQ;QAC9C,OAAO;IACT,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,0CAA0C;QACxD,8CAA8C;QAC9C,OAAO;IACT;AACF"}},
    {"offset": {"line": 524, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/jurit/OneDrive/Desktop/sito%20upscale/lib/documentAI.js"],"sourcesContent":["// Sistema AI completo per analisi documenti con OpenAI GPT-4\r\nimport mammoth from 'mammoth';\r\nimport * as XLSX from 'xlsx';\r\nimport { chatCompletion } from './openai.js';\r\n\r\n// pdf-parse ha problemi ESM/CJS con Turbopack, usiamo solo pdfjs-dist\r\n\r\n// Storage in-memory per i documenti caricati (in produzione si può usare database)\r\nconst documentStore = new Map(); // { fileId: { text, chunks, metadata } }\r\n\r\n/**\r\n * Estrae testo da un documento\r\n * @param {Buffer} buffer - Buffer del file\r\n * @param {string} mimeType - Tipo MIME del file\r\n * @param {string} filename - Nome del file\r\n * @param {string} [filepath] - Percorso opzionale del file (utile per OCR)\r\n */\r\nexport async function extractTextFromDocument(buffer, mimeType, filename, filepath = null) {\r\n  try {\r\n    let text = '';\r\n    let metadata = {\r\n      filename,\r\n      mimeType,\r\n      pages: 0,\r\n      wordCount: 0,\r\n    };\r\n\r\n    if (mimeType === 'application/pdf' || filename.toLowerCase().endsWith('.pdf')) {\r\n      // PDF: usa OpenAI file upload + GPT extraction (tutto lato server OpenAI)\r\n      const { extractTextFromPdfWithOpenAI } = await import('./openai.js');\r\n      console.log(`Analizzando PDF con OpenAI file upload: ${filename}`);\r\n      \r\n      // Salva temporaneamente il file per l'upload\r\n      const fs = await import('fs');\r\n      const path = await import('path');\r\n      const os = await import('os');\r\n      \r\n      const tempDir = os.tmpdir();\r\n      const tempFilePath = path.join(tempDir, `temp_${Date.now()}_${filename}`);\r\n      \r\n      try {\r\n        // Scrivi il buffer su file temporaneo\r\n        fs.writeFileSync(tempFilePath, buffer);\r\n        \r\n        // Estrai testo con OpenAI (file upload -> GPT risponde con SOLO testo)\r\n        text = await extractTextFromPdfWithOpenAI(tempFilePath);\r\n        \r\n        // Assicurati che sia una stringa pulita\r\n        text = (text || \"\").toString().trim();\r\n        metadata.analysisMethod = 'openai-file-upload';\r\n        \r\n        if (!text || text.length === 0) {\r\n          throw new Error('Nessun testo estratto dal PDF tramite OpenAI');\r\n        }\r\n        \r\n        console.log(`PDF analizzato con OpenAI: ${text.length} caratteri estratti`);\r\n      } finally {\r\n        // Pulisci file temporaneo\r\n        try {\r\n          if (fs.existsSync(tempFilePath)) {\r\n            fs.unlinkSync(tempFilePath);\r\n          }\r\n        } catch (cleanupError) {\r\n          console.warn('Errore pulizia file temporaneo:', cleanupError);\r\n        }\r\n      }\r\n    }\r\n    else if (mimeType.includes('wordprocessingml') || filename.toLowerCase().endsWith('.docx')) {\r\n      const result = await mammoth.extractRawText({ buffer });\r\n      text = result.value;\r\n      \r\n      // Pulisci il testo\r\n      text = text.replace(/\\s+/g, ' ').trim();\r\n    }\r\n    else if (mimeType.includes('spreadsheet') || filename.toLowerCase().match(/\\.(xlsx|xls|csv)$/i)) {\r\n      const workbook = XLSX.read(buffer, { type: 'buffer' });\r\n      const sheets = workbook.SheetNames;\r\n      \r\n      // Estrai testo da tutte le celle\r\n      const allText = [];\r\n      for (const sheetName of sheets) {\r\n        const sheet = workbook.Sheets[sheetName];\r\n        const sheetData = XLSX.utils.sheet_to_json(sheet, { header: 1, defval: '' });\r\n        \r\n        for (const row of sheetData) {\r\n          if (Array.isArray(row)) {\r\n            const rowText = row.filter(cell => cell && cell.toString().trim()).join(' ');\r\n            if (rowText.trim()) {\r\n              allText.push(`[${sheetName}] ${rowText}`);\r\n            }\r\n          }\r\n        }\r\n      }\r\n      \r\n      text = allText.join('\\n');\r\n    }\r\n    else if (mimeType.startsWith('text/') || filename.toLowerCase().endsWith('.txt')) {\r\n      text = buffer.toString('utf-8');\r\n    }\r\n    else if (mimeType.startsWith('image/') || filename.toLowerCase().match(/\\.(png|jpg|jpeg|gif|webp|bmp|tif|tiff|heic|heif)$/i)) {\r\n      // Usa OpenAI Vision API come ChatGPT (più intelligente) + OCR come fallback\r\n      try {\r\n        const { analyzeImageWithVision } = await import('./openai.js');\r\n        console.log(`Analizzando immagine con OpenAI Vision API: ${filename}`);\r\n        \r\n        try {\r\n          // Prova prima con OpenAI Vision API (come ChatGPT)\r\n          const visionText = await analyzeImageWithVision(\r\n            buffer, \r\n            mimeType,\r\n            'Analizza questa immagine in dettaglio. Descrivi tutto ciò che vedi, incluso qualsiasi testo presente, oggetti, persone, scene, colori e dettagli rilevanti. Se c\\'è del testo, trascrivilo accuratamente.'\r\n          );\r\n          \r\n          text = visionText;\r\n          console.log(`Vision API completato: ${text.length} caratteri estratti`);\r\n          \r\n          // Aggiungi metadata per indicare che è stato usato Vision API\r\n          metadata.analysisMethod = 'openai-vision';\r\n        } catch (visionError) {\r\n          console.log('Vision API fallito, provo con OCR:', visionError.message);\r\n          \r\n          // Fallback a OCR tradizionale\r\n          const Tesseract = (await import('tesseract.js')).default;\r\n          const imageSource = filepath || buffer;\r\n          \r\n          try {\r\n            const result = await Tesseract.recognize(imageSource, 'ita+eng', {\r\n              logger: (m) => {\r\n                if (m.status === 'recognizing text') {\r\n                  console.log(`OCR Progress: ${Math.round(m.progress * 100)}%`);\r\n                }\r\n              }\r\n            });\r\n            \r\n            text = result.data.text.trim();\r\n            metadata.analysisMethod = 'ocr-tesseract';\r\n          } catch (ocrError) {\r\n            // Se anche OCR fallisce, prova con createWorker\r\n            console.log('OCR semplice fallito, provo con createWorker:', ocrError.message);\r\n            \r\n            const worker = await Tesseract.createWorker('ita+eng', 1, {\r\n              logger: (m) => {\r\n                if (m.status === 'recognizing text') {\r\n                  console.log(`OCR Progress: ${Math.round(m.progress * 100)}%`);\r\n                }\r\n              }\r\n            });\r\n            \r\n            try {\r\n              const result = await worker.recognize(imageSource);\r\n              text = result.data.text.trim();\r\n              metadata.analysisMethod = 'ocr-tesseract-worker';\r\n            } finally {\r\n              await worker.terminate();\r\n            }\r\n          }\r\n        }\r\n        \r\n        if (!text || text.length === 0) {\r\n          throw new Error('Nessun contenuto estratto dall\\'immagine. L\\'immagine potrebbe essere vuota o non contenere testo leggibile.');\r\n        }\r\n        \r\n        console.log(`Analisi immagine completata: ${text.length} caratteri estratti (metodo: ${metadata.analysisMethod || 'unknown'})`);\r\n      } catch (imageError) {\r\n        console.error('Errore analisi immagine completo:', imageError);\r\n        throw new Error(`Errore nell'analisi dell'immagine: ${imageError.message}`);\r\n      }\r\n    }\r\n    else {\r\n      throw new Error(`Tipo di file non supportato: ${mimeType}`);\r\n    }\r\n\r\n    if (!text || text.trim().length === 0) {\r\n      throw new Error('Nessun testo estratto dal documento');\r\n    }\r\n\r\n    metadata.wordCount = text.split(/\\s+/).length;\r\n\r\n    return { text, metadata };\r\n  } catch (error) {\r\n    console.error('Errore estrazione testo:', error);\r\n    throw new Error(`Errore nell'estrazione del testo: ${error.message}`);\r\n  }\r\n}\r\n\r\n/**\r\n * Divide il testo in chunk intelligenti per la ricerca semantica\r\n * Genera anche embeddings per ogni chunk (ricerca semantica vera)\r\n */\r\nexport async function createTextChunks(text, chunkSize = 1000, overlap = 200) {\r\n  const sentences = text.split(/[.!?]+\\s+/).filter(s => s.trim().length > 10);\r\n  const chunks = [];\r\n  \r\n  let currentChunk = '';\r\n  let currentLength = 0;\r\n\r\n  for (const sentence of sentences) {\r\n    const sentenceLength = sentence.length;\r\n    \r\n    if (currentLength + sentenceLength > chunkSize && currentChunk.trim()) {\r\n      // Salva il chunk corrente\r\n      chunks.push({\r\n        text: currentChunk.trim(),\r\n        startIndex: text.indexOf(currentChunk.trim()),\r\n        endIndex: text.indexOf(currentChunk.trim()) + currentChunk.length,\r\n      });\r\n\r\n      // Crea nuovo chunk con overlap (ultime parole del chunk precedente)\r\n      const words = currentChunk.split(/\\s+/);\r\n      const overlapWords = words.slice(-Math.floor(overlap / 10));\r\n      currentChunk = overlapWords.join(' ') + ' ' + sentence + ' ';\r\n      currentLength = currentChunk.length;\r\n    } else {\r\n      currentChunk += sentence + '. ';\r\n      currentLength += sentenceLength + 2;\r\n    }\r\n  }\r\n\r\n  // Aggiungi l'ultimo chunk\r\n  if (currentChunk.trim()) {\r\n    chunks.push({\r\n      text: currentChunk.trim(),\r\n      startIndex: text.indexOf(currentChunk.trim()),\r\n      endIndex: text.length,\r\n    });\r\n  }\r\n\r\n  const finalChunks = chunks.length > 0 ? chunks : [{ text: text.trim(), startIndex: 0, endIndex: text.length }];\r\n  \r\n  // Genera embeddings per i chunk in batch per ridurre latenza\r\n  const { generateEmbeddingsBatch } = await import('./openai.js');\r\n\r\n  try {\r\n    // Processa in lotti per evitare payload troppo grandi\r\n    const BATCH_SIZE = 16;\r\n    for (let i = 0; i < finalChunks.length; i += BATCH_SIZE) {\r\n      const batch = finalChunks.slice(i, i + BATCH_SIZE);\r\n      const embeddings = await generateEmbeddingsBatch(batch.map(c => c.text));\r\n      embeddings.forEach((emb, idx) => {\r\n        batch[idx].embedding = emb;\r\n      });\r\n    }\r\n  } catch (embError) {\r\n    console.warn('Batch embeddings failed, falling back to per-chunk:', embError.message);\r\n    const { generateEmbedding } = await import('./openai.js');\r\n    for (const chunk of finalChunks) {\r\n      try {\r\n        chunk.embedding = await generateEmbedding(chunk.text);\r\n      } catch (err) {\r\n        console.warn('Errore generazione embedding per chunk:', err.message);\r\n        chunk.embedding = null;\r\n      }\r\n    }\r\n  }\r\n  \r\n  return finalChunks;\r\n}\r\n\r\n/**\r\n * Calcola cosine similarity tra due vettori di embedding\r\n */\r\nfunction cosineSimilarity(vecA, vecB) {\r\n  if (!vecA || !vecB || vecA.length !== vecB.length) return 0;\r\n  \r\n  const dot = vecA.reduce((sum, val, i) => sum + val * vecB[i], 0);\r\n  const magA = Math.sqrt(vecA.reduce((sum, val) => sum + val * val, 0));\r\n  const magB = Math.sqrt(vecB.reduce((sum, val) => sum + val * val, 0));\r\n  \r\n  return dot / (magA * magB);\r\n}\r\n\r\n/**\r\n * Calcola TF-IDF per ricerca semantica semplice (fallback se embedding non disponibile)\r\n */\r\nfunction calculateTFIDF(text, query) {\r\n  const textWords = text.toLowerCase().split(/\\W+/).filter(w => w.length > 2);\r\n  const queryWords = query.toLowerCase().split(/\\W+/).filter(w => w.length > 2);\r\n  \r\n  if (queryWords.length === 0) return 0;\r\n\r\n  let score = 0;\r\n  const textWordCount = {};\r\n  textWords.forEach(word => {\r\n    textWordCount[word] = (textWordCount[word] || 0) + 1;\r\n  });\r\n\r\n  queryWords.forEach(queryWord => {\r\n    const wordCount = textWordCount[queryWord] || 0;\r\n    if (wordCount > 0) {\r\n      // TF: frequenza del termine nel documento\r\n      const tf = wordCount / textWords.length;\r\n      // IDF: inversa della frequenza (più raro = più importante)\r\n      const idf = Math.log(textWords.length / (wordCount + 1)) + 1;\r\n      score += tf * idf;\r\n    }\r\n  });\r\n\r\n  return score / queryWords.length;\r\n}\r\n\r\n/**\r\n * Ricerca semantica nel documento usando embeddings (cosine similarity)\r\n * Fallback a TF-IDF se embeddings non disponibili\r\n */\r\nexport async function semanticSearch(documentText, chunks, query, topK = 5) {\r\n  if (!chunks || chunks.length === 0) {\r\n    return [];\r\n  }\r\n\r\n  // Genera embedding per la query\r\n  const { generateEmbedding } = await import('./openai.js');\r\n  let queryEmbedding = null;\r\n  \r\n  try {\r\n    queryEmbedding = await generateEmbedding(query);\r\n  } catch (embError) {\r\n    console.warn('Errore generazione embedding query, uso TF-IDF:', embError);\r\n  }\r\n\r\n  // Calcola score per ogni chunk\r\n  const scoredChunks = chunks.map((chunk, index) => {\r\n    let semanticScore = 0;\r\n    \r\n    // Usa cosine similarity se embeddings disponibili\r\n    if (queryEmbedding && chunk.embedding) {\r\n      semanticScore = cosineSimilarity(queryEmbedding, chunk.embedding);\r\n    } else {\r\n      // Fallback a TF-IDF\r\n      semanticScore = calculateTFIDF(chunk.text, query) / 10; // Normalizza per essere simile a cosine\r\n    }\r\n    \r\n    // Bonus per match esatti\r\n    const lowerChunk = chunk.text.toLowerCase();\r\n    const lowerQuery = query.toLowerCase();\r\n    let exactMatchBonus = 0;\r\n    if (lowerChunk.includes(lowerQuery)) {\r\n      exactMatchBonus = 0.1;\r\n    }\r\n    \r\n    // Bonus per parole chiave comuni\r\n    const queryWords = query.toLowerCase().split(/\\W+/).filter(w => w.length > 2);\r\n    const matchingWords = queryWords.filter(word => lowerChunk.includes(word)).length;\r\n    const keywordBonus = (matchingWords / queryWords.length) * 0.05;\r\n\r\n    const totalScore = semanticScore + exactMatchBonus + keywordBonus;\r\n\r\n    return {\r\n      ...chunk,\r\n      score: totalScore,\r\n      index,\r\n    };\r\n  });\r\n\r\n  // Ordina per score e ritorna i top K (anche con score bassi)\r\n  const sortedChunks = scoredChunks\r\n    .sort((a, b) => b.score - a.score)\r\n    .slice(0, topK);\r\n  \r\n  console.log('Top chunk scores:', sortedChunks.map(c => c.score.toFixed(4)));\r\n  \r\n  // Ritorna anche risultati con score bassi (meglio di niente)\r\n  return sortedChunks.filter(chunk => chunk.score >= 0);\r\n}\r\n\r\n/**\r\n * Genera risposta intelligente basata sul contenuto del documento usando OpenAI GPT-4\r\n * @param {string} query - Domanda dell'utente\r\n * @param {Array} relevantChunks - Chunk rilevanti dal documento\r\n * @param {string} documentText - Testo completo del documento\r\n * @param {string} conversationContext - Contesto della conversazione (opzionale)\r\n */\r\nexport async function generateAnswer(query, relevantChunks, documentText, conversationContext = '', documentMetadata = {}) {\r\n  if (!relevantChunks || relevantChunks.length === 0) {\r\n    return {\r\n      answer: \"Non ho trovato informazioni rilevanti nel documento per rispondere alla tua domanda. Prova a formulare la domanda in modo diverso o carica un documento più pertinente.\",\r\n      confidence: 0,\r\n      sources: [],\r\n    };\r\n  }\r\n\r\n  // Combina i chunk più rilevanti - SOLO TESTO (no oggetti, no IDs)\r\n  const combinedContext = relevantChunks\r\n    .map((chunk, idx) => `[Sezione ${idx + 1}]\\n${chunk.text}`)\r\n    .join('\\n\\n---\\n\\n');\r\n\r\n  // Usa OpenAI GPT-4 per generare una risposta intelligente\r\n  const confidence = Math.min(relevantChunks[0].score * 10, 1.0);\r\n  \r\n  try {\r\n    // Costruisci il prompt con contesto della conversazione se disponibile\r\n    let contextSection = '';\r\n    if (conversationContext && conversationContext.trim()) {\r\n      contextSection = `\\n\\n**CONTESTO DELLA CONVERSAZIONE PRECEDENTE:**\r\n${conversationContext}\r\n\r\nUsa questo contesto per capire meglio la domanda e fornire una risposta coerente con la conversazione.`;\r\n    }\r\n\r\n    const messages = [\r\n      {\r\n        role: 'system',\r\n        content: `Sei un assistente AI esperto nell'analisi di documenti. Segui un ragionamento interno SILENTE (non mostrarlo) con i passi: 1) Identifica concetti chiave 2) Seleziona parti rilevanti 3) Sintetizza relazioni 4) Verifica contraddizioni o assenze 5) Struttura risposta finale. Poi produci SOLO l'output formattato.\r\n\r\nOBIETTIVI:\r\n1. Analisi accurata delle sezioni fornite\r\n2. Risposta logica e coerente basata esclusivamente sul contenuto\r\n3. Struttura chiara e professionale in italiano\r\n4. Citazione delle fonti/Sezioni rilevanti\r\n5. Nessuna invenzione: se manca l'informazione, dichiaralo e suggerisci cosa servirebbe\r\n\r\nFORMATTA LA RISPOSTA CON LE SEZIONI (usa markdown semplice):\r\n**Risposta**: sintesi principale diretta alla domanda.\r\n**Dettagli**: approfondisci punti chiave organizzati.\r\n**Fonti**: elenco puntato con sezione e breve estratto.\r\n**Limiti**: cosa non è presente o ambiguo.\r\n**Suggerimenti**: eventuali passi successivi o chiarimenti da richiedere.\r\n\r\nRegole:\r\n- Non includere il ragionamento interno.\r\n- Non scusarti a meno che il contenuto sia realmente assente.\r\n- Mantieni tono professionale, conciso ma completo.`\r\n      },\r\n      {\r\n        role: 'user',\r\n        content: `Analizza il seguente contenuto estratto dal documento e rispondi alla domanda dell'utente in modo completo e accurato.\r\n\r\n**CONTENUTO DEL DOCUMENTO:**\r\n${combinedContext}${contextSection}\r\n\r\n**DOMANDA DELL'UTENTE:**\r\n${query}\r\n\r\n**ISTRUZIONI:**\r\n- Rispondi basandoti SOLO sul contenuto fornito sopra\r\n- Se la risposta richiede informazioni non presenti, dillo chiaramente\r\n- Cita o fai riferimento alle sezioni rilevanti quando possibile\r\n- Fornisci una risposta completa e ben strutturata\r\n- Considera il contesto della conversazione se fornito per una risposta più pertinente`\r\n      }\r\n    ];\r\n    \r\n    let answer = await chatCompletion(messages, {\r\n      model: 'gpt-4o-mini', // Modello veloce e economico\r\n      temperature: 0.2, // Bassa temperatura per risposte più accurate e consistenti\r\n      max_tokens: 1200, // Aumentato per risposte più complete\r\n      top_p: 0.9,\r\n      frequency_penalty: 0.1, // Riduce ripetizioni\r\n      presence_penalty: 0.1 // Incentiva varietà\r\n    });\r\n    answer = answer.trim();\r\n    // Post-processing: se il modello ha prodotto solo una frase debole/apologetica, arricchisci con estratti\r\n    const isWeak = /mi dispiace|non posso/i.test(answer) && answer.length < 120;\r\n    if (isWeak) {\r\n      const enriched = `**Risposta**: Informazioni limitate nel testo fornito.\r\n**Dettagli**:\\n${relevantChunks.slice(0,3).map(c=>'- '+c.text.substring(0,200).replace(/\\n+/g,' ')+ (c.text.length>200?'...':'' )).join('\\n')}\\n**Fonti**:\\n${relevantChunks.map((c,i)=>`- Sezione ${i+1} (score ${c.score.toFixed(3)})`).join('\\n')}\\n**Limiti**: Il documento sembra contenere testo estremamente breve o generico.\\n**Suggerimenti**: Carica un documento più esteso oppure specifica meglio la domanda.`;\r\n      answer = enriched;\r\n    }\r\n    return {\r\n      answer,\r\n      confidence,\r\n      sources: relevantChunks.map(c => ({\r\n        filename: documentMetadata?.originalFilename || documentMetadata?.filename || 'Documento',\r\n        text: c.text.substring(0, 150) + '...',\r\n        score: c.score.toFixed(3),\r\n      })),\r\n    };\r\n  } catch (error) {\r\n    console.error('Errore nella generazione della risposta con OpenAI:', error);\r\n    // Fallback a risposta semplice se OpenAI fallisce\r\n    const contextText = relevantChunks[0].text;\r\n    return {\r\n      answer: `Basandomi sul documento:\\n\\n${contextText}\\n\\n${relevantChunks.length > 1 ? '\\nInformazioni aggiuntive:\\n' + relevantChunks.slice(1, 3).map((c, i) => `• ${c.text.substring(0, 200)}...`).join('\\n') : ''}`,\r\n      confidence,\r\n      sources: relevantChunks.map(c => ({\r\n        filename: documentMetadata?.originalFilename || documentMetadata?.filename || 'Documento',\r\n        text: c.text.substring(0, 150) + '...',\r\n        score: c.score.toFixed(3),\r\n      })),\r\n    };\r\n  }\r\n}\r\n\r\n/**\r\n * Salva documento nello storage (con embeddings per ricerca semantica)\r\n */\r\nexport async function storeDocument(fileId, text, metadata = {}) {\r\n  console.log(`storeDocument called for ${fileId}, text length: ${text.length}`);\r\n  \r\n  const chunks = await createTextChunks(text);\r\n  \r\n  console.log(`Created ${chunks.length} chunks for document ${fileId}`);\r\n  \r\n  const documentData = {\r\n    text,\r\n    chunks,\r\n    metadata: {\r\n      ...metadata,\r\n      filename: metadata.filename || metadata.originalFilename || 'Unknown',\r\n      storedAt: new Date().toISOString(),\r\n      chunkCount: chunks.length,\r\n    },\r\n  };\r\n  \r\n  documentStore.set(fileId, documentData);\r\n  \r\n  console.log(`Document ${fileId} stored. Store size now: ${documentStore.size}`);\r\n  console.log(`Store keys:`, Array.from(documentStore.keys()));\r\n\r\n  return {\r\n    fileId,\r\n    chunkCount: chunks.length,\r\n    wordCount: text.split(/\\s+/).length,\r\n  };\r\n}\r\n\r\n/**\r\n * Recupera documento dallo storage\r\n */\r\nexport function getDocument(fileId) {\r\n  return documentStore.get(fileId);\r\n}\r\n\r\n/**\r\n * Rimuovi documento dallo storage\r\n */\r\nexport function removeDocument(fileId) {\r\n  return documentStore.delete(fileId);\r\n}\r\n\r\n/**\r\n * Cerca in tutti i documenti (async per embeddings)\r\n */\r\nexport async function searchAllDocuments(query, fileIds = null) {\r\n  console.log('searchAllDocuments called with query:', query, 'fileIds:', fileIds);\r\n  console.log('documentStore size:', documentStore.size);\r\n  console.log('documentStore keys:', Array.from(documentStore.keys()));\r\n  \r\n  const documents = fileIds && fileIds.length > 0\r\n    ? fileIds.map(id => {\r\n        const data = documentStore.get(id);\r\n        console.log(`Looking for fileId ${id}:`, data ? 'found' : 'NOT FOUND');\r\n        return { id, data };\r\n      }).filter(d => d.data)\r\n    : Array.from(documentStore.entries()).map(([id, data]) => {\r\n        console.log(`Document ${id}:`, data ? 'found' : 'NOT FOUND');\r\n        return { id, data };\r\n      });\r\n\r\n  console.log(`Found ${documents.length} documents to search`);\r\n\r\n  if (documents.length === 0) {\r\n    console.log('No documents found to search in');\r\n    return [];\r\n  }\r\n\r\n  const allResults = [];\r\n\r\n  for (const { id, data } of documents) {\r\n    if (!data || !data.chunks || !data.chunks.length) {\r\n      console.log(`Document ${id} has no chunks, skipping`);\r\n      continue;\r\n    }\r\n\r\n    console.log(`Searching in document ${id} (${data.chunks.length} chunks)`);\r\n    const results = await semanticSearch(data.text, data.chunks, query, 5);\r\n    \r\n    if (results.length > 0) {\r\n      console.log(`Found ${results.length} relevant chunks in document ${id}`);\r\n      allResults.push({\r\n        fileId: id,\r\n        filename: data.metadata?.originalFilename || data.metadata?.filename || 'Unknown',\r\n        results,\r\n        topScore: results[0].score,\r\n      });\r\n    } else {\r\n      console.log(`No relevant chunks found in document ${id}`);\r\n    }\r\n  }\r\n\r\n  console.log(`Total search results: ${allResults.length}`);\r\n\r\n  // Ordina per score migliore\r\n  return allResults.sort((a, b) => b.topScore - a.topScore);\r\n}\r\n\r\n/**\r\n * Genera risposta combinando risultati da più documenti usando OpenAI\r\n * @param {string} query - Domanda dell'utente\r\n * @param {Array} searchResults - Risultati della ricerca nei documenti\r\n * @param {string} conversationContext - Contesto della conversazione (opzionale)\r\n */\r\nexport async function generateMultiDocumentAnswer(query, searchResults, conversationContext = '') {\r\n  if (!searchResults || searchResults.length === 0) {\r\n    return {\r\n      answer: \"Non ho trovato informazioni rilevanti nei documenti caricati. Prova a formulare la domanda in modo diverso o carica documenti più pertinenti.\",\r\n      confidence: 0,\r\n      sources: [],\r\n    };\r\n  }\r\n\r\n  // Prendi i chunk migliori da tutti i documenti\r\n  const topChunks = searchResults\r\n    .flatMap(fileResult => \r\n      fileResult.results.map(r => ({\r\n        ...r,\r\n        filename: fileResult.filename,\r\n        fileId: fileResult.fileId,\r\n      }))\r\n    )\r\n    .sort((a, b) => b.score - a.score)\r\n    .slice(0, 5);\r\n\r\n  if (topChunks.length === 0) {\r\n    return {\r\n      answer: \"Non ho trovato informazioni sufficienti per rispondere.\",\r\n      confidence: 0,\r\n      sources: [],\r\n    };\r\n  }\r\n\r\n  // Genera risposta combinata usando OpenAI\r\n  const primaryChunk = topChunks[0];\r\n  const document = getDocument(primaryChunk.fileId);\r\n  \r\n  if (searchResults.length === 1) {\r\n    // Un solo documento - usa generateAnswer con metadata per filename\r\n    return await generateAnswer(query, topChunks, document.text, conversationContext, document.metadata || {});\r\n  } else {\r\n    // Multiple documenti - combina informazioni da più fonti\r\n    const confidence = Math.min(primaryChunk.score * 10, 1.0);\r\n    \r\n    try {\r\n      // Combina SOLO testo dai documenti (no file IDs, no oggetti)\r\n      const combinedContext = topChunks\r\n        .map((chunk, idx) => `[Documento: \"${chunk.filename}\" - Sezione ${idx + 1}]\\n${chunk.text}`)\r\n        .join('\\n\\n---\\n\\n');\r\n      \r\n      // Costruisci il prompt con contesto della conversazione se disponibile\r\n      let contextSection = '';\r\n      if (conversationContext && conversationContext.trim()) {\r\n        contextSection = `\\n\\n**CONTESTO DELLA CONVERSAZIONE PRECEDENTE:**\r\n${conversationContext}\r\n\r\nUsa questo contesto per capire meglio la domanda e fornire una risposta coerente con la conversazione.`;\r\n      }\r\n\r\n      const messages = [\r\n        {\r\n          role: 'system',\r\n          content: `Sei un assistente AI esperto nell'analisi di documenti multipli. Usa ragionamento interno SILENTE (non mostrarlo) seguendo: 1) Mappa concetti per documento 2) Trova sovrapposizioni/contrasti 3) Sintetizza 4) Valuta completezza 5) Struttura output. Non mostrare i passi.\r\n\r\nFORMATTA OUTPUT:\r\n**Risposta** (sintesi diretta alla domanda)\r\n**Analisi** (integrazione logica tra documenti, relazioni, eventuali differenze)\r\n**Fonti** (elenco: Documento – breve estratto pertinente)\r\n**Limiti** (informazioni mancanti, contraddizioni non risolte)\r\n**Suggerimenti** (cosa potrebbe aiutare o prossimi passi)\r\n\r\nRegole:\r\n- Non inventare contenuto\r\n- Non scusarti salvo assenza totale di informazioni\r\n- Cita il nome del documento per ogni informazione specifica\r\n- Indica contraddizioni se presenti.`\r\n        },\r\n        {\r\n          role: 'user',\r\n          content: `Analizza il contenuto estratto da ${searchResults.length} documenti diversi e rispondi alla domanda dell'utente sintetizzando le informazioni rilevanti.\r\n\r\n**CONTENUTO DAI DOCUMENTI:**\r\n${combinedContext}${contextSection}\r\n\r\n**DOMANDA DELL'UTENTE:**\r\n${query}\r\n\r\n**ISTRUZIONI:**\r\n- Combina informazioni da tutti i documenti rilevanti\r\n- Cita sempre il nome del documento quando fai riferimento a informazioni specifiche\r\n- Se ci sono informazioni correlate in più documenti, integrale in modo coerente\r\n- Fornisci una risposta completa che risponda alla domanda utilizzando tutte le fonti pertinenti\r\n- Considera il contesto della conversazione se fornito per una risposta più pertinente`\r\n        }\r\n      ];\r\n      \r\n      let answer = await chatCompletion(messages, {\r\n        model: 'gpt-4o-mini',\r\n        temperature: 0.2,\r\n        max_tokens: 1500, // Aumentato per risposte multi-documento più complete\r\n        top_p: 0.9,\r\n        frequency_penalty: 0.1,\r\n        presence_penalty: 0.1\r\n      });\r\n      answer = answer.trim();\r\n      const isWeak = /mi dispiace|non posso/i.test(answer) && answer.length < 140;\r\n      if (isWeak) {\r\n        const enrichment = topChunks.slice(0,5).map((c,i)=>`- ${c.filename} [score ${c.score.toFixed(3)}]: ${c.text.substring(0,160).replace(/\\n+/g,' ')}${c.text.length>160?'...':''}`).join('\\n');\r\n        answer = `**Risposta**: Informazioni limitate ma estratte dai documenti.\r\n**Analisi**: I contenuti disponibili sono molto brevi; non emergono argomentazioni complesse.\r\n**Fonti**:\\n${enrichment}\r\n**Limiti**: Poca profondità; serve testo aggiuntivo.\r\n**Suggerimenti**: Carica versioni più complete dei documenti o specifica una domanda più dettagliata.`;\r\n      }\r\n      return {\r\n        answer,\r\n        confidence,\r\n        sources: topChunks.slice(0, 3).map(c => ({\r\n          filename: c.filename,\r\n          text: c.text.substring(0, 100) + '...',\r\n          score: c.score.toFixed(3),\r\n        })),\r\n      };\r\n    } catch (error) {\r\n      console.error('Errore nella generazione della risposta multi-documento con OpenAI:', error);\r\n      // Fallback\r\n      let answer = `Basandomi sui ${searchResults.length} documenti caricati:\\n\\n`;\r\n      answer += `**Dal documento \"${primaryChunk.filename}\":**\\n${primaryChunk.text}\\n\\n`;\r\n      \r\n      if (topChunks.length > 1) {\r\n        const otherDocs = topChunks.slice(1, 3).filter(c => c.fileId !== primaryChunk.fileId);\r\n        if (otherDocs.length > 0) {\r\n          answer += `**Informazioni correlate da altri documenti:**\\n`;\r\n          otherDocs.forEach((chunk, idx) => {\r\n            answer += `\\n[${idx + 1}] Da \"${chunk.filename}\":\\n${chunk.text.substring(0, 200)}...\\n`;\r\n          });\r\n        }\r\n      }\r\n      \r\n      const confidence = Math.min(primaryChunk.score * 10, 1.0);\r\n      \r\n      return {\r\n        answer: answer.trim(),\r\n        confidence,\r\n        sources: topChunks.slice(0, 3).map(c => ({\r\n          filename: c.filename,\r\n          text: c.text.substring(0, 100) + '...',\r\n          score: c.score.toFixed(3),\r\n        })),\r\n      };\r\n    }\r\n  }\r\n}\r\n\r\n/**\r\n * Ottieni tutti i documenti con i loro ID\r\n */\r\nexport function getAllDocuments() {\r\n  return Array.from(documentStore.entries()).map(([fileId, doc]) => ({\r\n    fileId,\r\n    ...doc\r\n  }));\r\n}\r\n\r\n/**\r\n * Ottieni statistiche sui documenti caricati\r\n */\r\nexport function getDocumentStats() {\r\n  const documents = Array.from(documentStore.values());\r\n  \r\n  return {\r\n    totalDocuments: documentStore.size,\r\n    totalWords: documents.reduce((sum, doc) => sum + (doc.text.split(/\\s+/).length || 0), 0),\r\n    totalChunks: documents.reduce((sum, doc) => sum + (doc.chunks?.length || 0), 0),\r\n    documents: Array.from(documentStore.entries()).map(([fileId, doc]) => ({\r\n      fileId,\r\n      index: Array.from(documentStore.keys()).indexOf(fileId),\r\n      filename: doc.metadata?.filename || doc.metadata?.originalFilename || 'Unknown',\r\n      wordCount: doc.text.split(/\\s+/).length,\r\n      chunkCount: doc.chunks?.length || 0,\r\n      storedAt: doc.metadata?.storedAt,\r\n    })),\r\n  };\r\n}\r\n\r\n"],"names":[],"mappings":"AAAA,6DAA6D;;;;;;;;;;;;;;;;;;;;;;;;;AAC7D;AACA;AACA;;;;;;;;AAEA,sEAAsE;AAEtE,mFAAmF;AACnF,MAAM,gBAAgB,IAAI,OAAO,yCAAyC;AASnE,eAAe,wBAAwB,MAAM,EAAE,QAAQ,EAAE,QAAQ,EAAE,WAAW,IAAI;IACvF,IAAI;QACF,IAAI,OAAO;QACX,IAAI,WAAW;YACb;YACA;YACA,OAAO;YACP,WAAW;QACb;QAEA,IAAI,aAAa,qBAAqB,SAAS,WAAW,GAAG,QAAQ,CAAC,SAAS;YAC7E,0EAA0E;YAC1E,MAAM,EAAE,4BAA4B,EAAE,GAAG;YACzC,QAAQ,GAAG,CAAC,CAAC,wCAAwC,EAAE,UAAU;YAEjE,6CAA6C;YAC7C,MAAM,KAAK;YACX,MAAM,OAAO;YACb,MAAM,KAAK;YAEX,MAAM,UAAU,GAAG,MAAM;YACzB,MAAM,eAAe,KAAK,IAAI,CAAC,SAAS,CAAC,KAAK,EAAE,KAAK,GAAG,GAAG,CAAC,EAAE,UAAU;YAExE,IAAI;gBACF,sCAAsC;gBACtC,GAAG,aAAa,CAAC,cAAc;gBAE/B,uEAAuE;gBACvE,OAAO,MAAM,6BAA6B;gBAE1C,wCAAwC;gBACxC,OAAO,CAAC,QAAQ,EAAE,EAAE,QAAQ,GAAG,IAAI;gBACnC,SAAS,cAAc,GAAG;gBAE1B,IAAI,CAAC,QAAQ,KAAK,MAAM,KAAK,GAAG;oBAC9B,MAAM,IAAI,MAAM;gBAClB;gBAEA,QAAQ,GAAG,CAAC,CAAC,2BAA2B,EAAE,KAAK,MAAM,CAAC,mBAAmB,CAAC;YAC5E,SAAU;gBACR,0BAA0B;gBAC1B,IAAI;oBACF,IAAI,GAAG,UAAU,CAAC,eAAe;wBAC/B,GAAG,UAAU,CAAC;oBAChB;gBACF,EAAE,OAAO,cAAc;oBACrB,QAAQ,IAAI,CAAC,mCAAmC;gBAClD;YACF;QACF,OACK,IAAI,SAAS,QAAQ,CAAC,uBAAuB,SAAS,WAAW,GAAG,QAAQ,CAAC,UAAU;YAC1F,MAAM,SAAS,MAAM,kHAAO,CAAC,cAAc,CAAC;gBAAE;YAAO;YACrD,OAAO,OAAO,KAAK;YAEnB,mBAAmB;YACnB,OAAO,KAAK,OAAO,CAAC,QAAQ,KAAK,IAAI;QACvC,OACK,IAAI,SAAS,QAAQ,CAAC,kBAAkB,SAAS,WAAW,GAAG,KAAK,CAAC,uBAAuB;YAC/F,MAAM,WAAW,yGAAS,CAAC,QAAQ;gBAAE,MAAM;YAAS;YACpD,MAAM,SAAS,SAAS,UAAU;YAElC,iCAAiC;YACjC,MAAM,UAAU,EAAE;YAClB,KAAK,MAAM,aAAa,OAAQ;gBAC9B,MAAM,QAAQ,SAAS,MAAM,CAAC,UAAU;gBACxC,MAAM,YAAY,0GAAU,CAAC,aAAa,CAAC,OAAO;oBAAE,QAAQ;oBAAG,QAAQ;gBAAG;gBAE1E,KAAK,MAAM,OAAO,UAAW;oBAC3B,IAAI,MAAM,OAAO,CAAC,MAAM;wBACtB,MAAM,UAAU,IAAI,MAAM,CAAC,CAAA,OAAQ,QAAQ,KAAK,QAAQ,GAAG,IAAI,IAAI,IAAI,CAAC;wBACxE,IAAI,QAAQ,IAAI,IAAI;4BAClB,QAAQ,IAAI,CAAC,CAAC,CAAC,EAAE,UAAU,EAAE,EAAE,SAAS;wBAC1C;oBACF;gBACF;YACF;YAEA,OAAO,QAAQ,IAAI,CAAC;QACtB,OACK,IAAI,SAAS,UAAU,CAAC,YAAY,SAAS,WAAW,GAAG,QAAQ,CAAC,SAAS;YAChF,OAAO,OAAO,QAAQ,CAAC;QACzB,OACK,IAAI,SAAS,UAAU,CAAC,aAAa,SAAS,WAAW,GAAG,KAAK,CAAC,uDAAuD;YAC5H,4EAA4E;YAC5E,IAAI;gBACF,MAAM,EAAE,sBAAsB,EAAE,GAAG;gBACnC,QAAQ,GAAG,CAAC,CAAC,4CAA4C,EAAE,UAAU;gBAErE,IAAI;oBACF,mDAAmD;oBACnD,MAAM,aAAa,MAAM,uBACvB,QACA,UACA;oBAGF,OAAO;oBACP,QAAQ,GAAG,CAAC,CAAC,uBAAuB,EAAE,KAAK,MAAM,CAAC,mBAAmB,CAAC;oBAEtE,8DAA8D;oBAC9D,SAAS,cAAc,GAAG;gBAC5B,EAAE,OAAO,aAAa;oBACpB,QAAQ,GAAG,CAAC,sCAAsC,YAAY,OAAO;oBAErE,8BAA8B;oBAC9B,MAAM,YAAY,CAAC,sGAA4B,EAAE,OAAO;oBACxD,MAAM,cAAc,YAAY;oBAEhC,IAAI;wBACF,MAAM,SAAS,MAAM,UAAU,SAAS,CAAC,aAAa,WAAW;4BAC/D,QAAQ,CAAC;gCACP,IAAI,EAAE,MAAM,KAAK,oBAAoB;oCACnC,QAAQ,GAAG,CAAC,CAAC,cAAc,EAAE,KAAK,KAAK,CAAC,EAAE,QAAQ,GAAG,KAAK,CAAC,CAAC;gCAC9D;4BACF;wBACF;wBAEA,OAAO,OAAO,IAAI,CAAC,IAAI,CAAC,IAAI;wBAC5B,SAAS,cAAc,GAAG;oBAC5B,EAAE,OAAO,UAAU;wBACjB,gDAAgD;wBAChD,QAAQ,GAAG,CAAC,iDAAiD,SAAS,OAAO;wBAE7E,MAAM,SAAS,MAAM,UAAU,YAAY,CAAC,WAAW,GAAG;4BACxD,QAAQ,CAAC;gCACP,IAAI,EAAE,MAAM,KAAK,oBAAoB;oCACnC,QAAQ,GAAG,CAAC,CAAC,cAAc,EAAE,KAAK,KAAK,CAAC,EAAE,QAAQ,GAAG,KAAK,CAAC,CAAC;gCAC9D;4BACF;wBACF;wBAEA,IAAI;4BACF,MAAM,SAAS,MAAM,OAAO,SAAS,CAAC;4BACtC,OAAO,OAAO,IAAI,CAAC,IAAI,CAAC,IAAI;4BAC5B,SAAS,cAAc,GAAG;wBAC5B,SAAU;4BACR,MAAM,OAAO,SAAS;wBACxB;oBACF;gBACF;gBAEA,IAAI,CAAC,QAAQ,KAAK,MAAM,KAAK,GAAG;oBAC9B,MAAM,IAAI,MAAM;gBAClB;gBAEA,QAAQ,GAAG,CAAC,CAAC,6BAA6B,EAAE,KAAK,MAAM,CAAC,6BAA6B,EAAE,SAAS,cAAc,IAAI,UAAU,CAAC,CAAC;YAChI,EAAE,OAAO,YAAY;gBACnB,QAAQ,KAAK,CAAC,qCAAqC;gBACnD,MAAM,IAAI,MAAM,CAAC,mCAAmC,EAAE,WAAW,OAAO,EAAE;YAC5E;QACF,OACK;YACH,MAAM,IAAI,MAAM,CAAC,6BAA6B,EAAE,UAAU;QAC5D;QAEA,IAAI,CAAC,QAAQ,KAAK,IAAI,GAAG,MAAM,KAAK,GAAG;YACrC,MAAM,IAAI,MAAM;QAClB;QAEA,SAAS,SAAS,GAAG,KAAK,KAAK,CAAC,OAAO,MAAM;QAE7C,OAAO;YAAE;YAAM;QAAS;IAC1B,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,4BAA4B;QAC1C,MAAM,IAAI,MAAM,CAAC,kCAAkC,EAAE,MAAM,OAAO,EAAE;IACtE;AACF;AAMO,eAAe,iBAAiB,IAAI,EAAE,YAAY,IAAI,EAAE,UAAU,GAAG;IAC1E,MAAM,YAAY,KAAK,KAAK,CAAC,aAAa,MAAM,CAAC,CAAA,IAAK,EAAE,IAAI,GAAG,MAAM,GAAG;IACxE,MAAM,SAAS,EAAE;IAEjB,IAAI,eAAe;IACnB,IAAI,gBAAgB;IAEpB,KAAK,MAAM,YAAY,UAAW;QAChC,MAAM,iBAAiB,SAAS,MAAM;QAEtC,IAAI,gBAAgB,iBAAiB,aAAa,aAAa,IAAI,IAAI;YACrE,0BAA0B;YAC1B,OAAO,IAAI,CAAC;gBACV,MAAM,aAAa,IAAI;gBACvB,YAAY,KAAK,OAAO,CAAC,aAAa,IAAI;gBAC1C,UAAU,KAAK,OAAO,CAAC,aAAa,IAAI,MAAM,aAAa,MAAM;YACnE;YAEA,oEAAoE;YACpE,MAAM,QAAQ,aAAa,KAAK,CAAC;YACjC,MAAM,eAAe,MAAM,KAAK,CAAC,CAAC,KAAK,KAAK,CAAC,UAAU;YACvD,eAAe,aAAa,IAAI,CAAC,OAAO,MAAM,WAAW;YACzD,gBAAgB,aAAa,MAAM;QACrC,OAAO;YACL,gBAAgB,WAAW;YAC3B,iBAAiB,iBAAiB;QACpC;IACF;IAEA,0BAA0B;IAC1B,IAAI,aAAa,IAAI,IAAI;QACvB,OAAO,IAAI,CAAC;YACV,MAAM,aAAa,IAAI;YACvB,YAAY,KAAK,OAAO,CAAC,aAAa,IAAI;YAC1C,UAAU,KAAK,MAAM;QACvB;IACF;IAEA,MAAM,cAAc,OAAO,MAAM,GAAG,IAAI,SAAS;QAAC;YAAE,MAAM,KAAK,IAAI;YAAI,YAAY;YAAG,UAAU,KAAK,MAAM;QAAC;KAAE;IAE9G,6DAA6D;IAC7D,MAAM,EAAE,uBAAuB,EAAE,GAAG;IAEpC,IAAI;QACF,sDAAsD;QACtD,MAAM,aAAa;QACnB,IAAK,IAAI,IAAI,GAAG,IAAI,YAAY,MAAM,EAAE,KAAK,WAAY;YACvD,MAAM,QAAQ,YAAY,KAAK,CAAC,GAAG,IAAI;YACvC,MAAM,aAAa,MAAM,wBAAwB,MAAM,GAAG,CAAC,CAAA,IAAK,EAAE,IAAI;YACtE,WAAW,OAAO,CAAC,CAAC,KAAK;gBACvB,KAAK,CAAC,IAAI,CAAC,SAAS,GAAG;YACzB;QACF;IACF,EAAE,OAAO,UAAU;QACjB,QAAQ,IAAI,CAAC,uDAAuD,SAAS,OAAO;QACpF,MAAM,EAAE,iBAAiB,EAAE,GAAG;QAC9B,KAAK,MAAM,SAAS,YAAa;YAC/B,IAAI;gBACF,MAAM,SAAS,GAAG,MAAM,kBAAkB,MAAM,IAAI;YACtD,EAAE,OAAO,KAAK;gBACZ,QAAQ,IAAI,CAAC,2CAA2C,IAAI,OAAO;gBACnE,MAAM,SAAS,GAAG;YACpB;QACF;IACF;IAEA,OAAO;AACT;AAEA;;CAEC,GACD,SAAS,iBAAiB,IAAI,EAAE,IAAI;IAClC,IAAI,CAAC,QAAQ,CAAC,QAAQ,KAAK,MAAM,KAAK,KAAK,MAAM,EAAE,OAAO;IAE1D,MAAM,MAAM,KAAK,MAAM,CAAC,CAAC,KAAK,KAAK,IAAM,MAAM,MAAM,IAAI,CAAC,EAAE,EAAE;IAC9D,MAAM,OAAO,KAAK,IAAI,CAAC,KAAK,MAAM,CAAC,CAAC,KAAK,MAAQ,MAAM,MAAM,KAAK;IAClE,MAAM,OAAO,KAAK,IAAI,CAAC,KAAK,MAAM,CAAC,CAAC,KAAK,MAAQ,MAAM,MAAM,KAAK;IAElE,OAAO,MAAM,CAAC,OAAO,IAAI;AAC3B;AAEA;;CAEC,GACD,SAAS,eAAe,IAAI,EAAE,KAAK;IACjC,MAAM,YAAY,KAAK,WAAW,GAAG,KAAK,CAAC,OAAO,MAAM,CAAC,CAAA,IAAK,EAAE,MAAM,GAAG;IACzE,MAAM,aAAa,MAAM,WAAW,GAAG,KAAK,CAAC,OAAO,MAAM,CAAC,CAAA,IAAK,EAAE,MAAM,GAAG;IAE3E,IAAI,WAAW,MAAM,KAAK,GAAG,OAAO;IAEpC,IAAI,QAAQ;IACZ,MAAM,gBAAgB,CAAC;IACvB,UAAU,OAAO,CAAC,CAAA;QAChB,aAAa,CAAC,KAAK,GAAG,CAAC,aAAa,CAAC,KAAK,IAAI,CAAC,IAAI;IACrD;IAEA,WAAW,OAAO,CAAC,CAAA;QACjB,MAAM,YAAY,aAAa,CAAC,UAAU,IAAI;QAC9C,IAAI,YAAY,GAAG;YACjB,0CAA0C;YAC1C,MAAM,KAAK,YAAY,UAAU,MAAM;YACvC,2DAA2D;YAC3D,MAAM,MAAM,KAAK,GAAG,CAAC,UAAU,MAAM,GAAG,CAAC,YAAY,CAAC,KAAK;YAC3D,SAAS,KAAK;QAChB;IACF;IAEA,OAAO,QAAQ,WAAW,MAAM;AAClC;AAMO,eAAe,eAAe,YAAY,EAAE,MAAM,EAAE,KAAK,EAAE,OAAO,CAAC;IACxE,IAAI,CAAC,UAAU,OAAO,MAAM,KAAK,GAAG;QAClC,OAAO,EAAE;IACX;IAEA,gCAAgC;IAChC,MAAM,EAAE,iBAAiB,EAAE,GAAG;IAC9B,IAAI,iBAAiB;IAErB,IAAI;QACF,iBAAiB,MAAM,kBAAkB;IAC3C,EAAE,OAAO,UAAU;QACjB,QAAQ,IAAI,CAAC,mDAAmD;IAClE;IAEA,+BAA+B;IAC/B,MAAM,eAAe,OAAO,GAAG,CAAC,CAAC,OAAO;QACtC,IAAI,gBAAgB;QAEpB,kDAAkD;QAClD,IAAI,kBAAkB,MAAM,SAAS,EAAE;YACrC,gBAAgB,iBAAiB,gBAAgB,MAAM,SAAS;QAClE,OAAO;YACL,oBAAoB;YACpB,gBAAgB,eAAe,MAAM,IAAI,EAAE,SAAS,IAAI,wCAAwC;QAClG;QAEA,yBAAyB;QACzB,MAAM,aAAa,MAAM,IAAI,CAAC,WAAW;QACzC,MAAM,aAAa,MAAM,WAAW;QACpC,IAAI,kBAAkB;QACtB,IAAI,WAAW,QAAQ,CAAC,aAAa;YACnC,kBAAkB;QACpB;QAEA,iCAAiC;QACjC,MAAM,aAAa,MAAM,WAAW,GAAG,KAAK,CAAC,OAAO,MAAM,CAAC,CAAA,IAAK,EAAE,MAAM,GAAG;QAC3E,MAAM,gBAAgB,WAAW,MAAM,CAAC,CAAA,OAAQ,WAAW,QAAQ,CAAC,OAAO,MAAM;QACjF,MAAM,eAAe,AAAC,gBAAgB,WAAW,MAAM,GAAI;QAE3D,MAAM,aAAa,gBAAgB,kBAAkB;QAErD,OAAO;YACL,GAAG,KAAK;YACR,OAAO;YACP;QACF;IACF;IAEA,6DAA6D;IAC7D,MAAM,eAAe,aAClB,IAAI,CAAC,CAAC,GAAG,IAAM,EAAE,KAAK,GAAG,EAAE,KAAK,EAChC,KAAK,CAAC,GAAG;IAEZ,QAAQ,GAAG,CAAC,qBAAqB,aAAa,GAAG,CAAC,CAAA,IAAK,EAAE,KAAK,CAAC,OAAO,CAAC;IAEvE,6DAA6D;IAC7D,OAAO,aAAa,MAAM,CAAC,CAAA,QAAS,MAAM,KAAK,IAAI;AACrD;AASO,eAAe,eAAe,KAAK,EAAE,cAAc,EAAE,YAAY,EAAE,sBAAsB,EAAE,EAAE,mBAAmB,CAAC,CAAC;IACvH,IAAI,CAAC,kBAAkB,eAAe,MAAM,KAAK,GAAG;QAClD,OAAO;YACL,QAAQ;YACR,YAAY;YACZ,SAAS,EAAE;QACb;IACF;IAEA,kEAAkE;IAClE,MAAM,kBAAkB,eACrB,GAAG,CAAC,CAAC,OAAO,MAAQ,CAAC,SAAS,EAAE,MAAM,EAAE,GAAG,EAAE,MAAM,IAAI,EAAE,EACzD,IAAI,CAAC;IAER,0DAA0D;IAC1D,MAAM,aAAa,KAAK,GAAG,CAAC,cAAc,CAAC,EAAE,CAAC,KAAK,GAAG,IAAI;IAE1D,IAAI;QACF,uEAAuE;QACvE,IAAI,iBAAiB;QACrB,IAAI,uBAAuB,oBAAoB,IAAI,IAAI;YACrD,iBAAiB,CAAC;AACxB,EAAE,oBAAoB;;sGAEgF,CAAC;QACnG;QAEA,MAAM,WAAW;YACf;gBACE,MAAM;gBACN,SAAS,CAAC;;;;;;;;;;;;;;;;;;;mDAmBiC,CAAC;YAC9C;YACA;gBACE,MAAM;gBACN,SAAS,CAAC;;;AAGlB,EAAE,kBAAkB,eAAe;;;AAGnC,EAAE,MAAM;;;;;;;sFAO8E,CAAC;YACjF;SACD;QAED,IAAI,SAAS,MAAM,IAAA,wHAAc,EAAC,UAAU;YAC1C,OAAO;YACP,aAAa;YACb,YAAY;YACZ,OAAO;YACP,mBAAmB;YACnB,kBAAkB,IAAI,oBAAoB;QAC5C;QACA,SAAS,OAAO,IAAI;QACpB,yGAAyG;QACzG,MAAM,SAAS,yBAAyB,IAAI,CAAC,WAAW,OAAO,MAAM,GAAG;QACxE,IAAI,QAAQ;YACV,MAAM,WAAW,CAAC;eACT,EAAE,eAAe,KAAK,CAAC,GAAE,GAAG,GAAG,CAAC,CAAA,IAAG,OAAK,EAAE,IAAI,CAAC,SAAS,CAAC,GAAE,KAAK,OAAO,CAAC,QAAO,OAAM,CAAC,EAAE,IAAI,CAAC,MAAM,GAAC,MAAI,QAAM,EAAG,GAAG,IAAI,CAAC,MAAM,cAAc,EAAE,eAAe,GAAG,CAAC,CAAC,GAAE,IAAI,CAAC,UAAU,EAAE,IAAE,EAAE,QAAQ,EAAE,EAAE,KAAK,CAAC,OAAO,CAAC,GAAG,CAAC,CAAC,EAAE,IAAI,CAAC,MAAM,sKAAsK,CAAC;YACtZ,SAAS;QACX;QACA,OAAO;YACL;YACA;YACA,SAAS,eAAe,GAAG,CAAC,CAAA,IAAK,CAAC;oBAChC,UAAU,kBAAkB,oBAAoB,kBAAkB,YAAY;oBAC9E,MAAM,EAAE,IAAI,CAAC,SAAS,CAAC,GAAG,OAAO;oBACjC,OAAO,EAAE,KAAK,CAAC,OAAO,CAAC;gBACzB,CAAC;QACH;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,uDAAuD;QACrE,kDAAkD;QAClD,MAAM,cAAc,cAAc,CAAC,EAAE,CAAC,IAAI;QAC1C,OAAO;YACL,QAAQ,CAAC,4BAA4B,EAAE,YAAY,IAAI,EAAE,eAAe,MAAM,GAAG,IAAI,iCAAiC,eAAe,KAAK,CAAC,GAAG,GAAG,GAAG,CAAC,CAAC,GAAG,IAAM,CAAC,EAAE,EAAE,EAAE,IAAI,CAAC,SAAS,CAAC,GAAG,KAAK,GAAG,CAAC,EAAE,IAAI,CAAC,QAAQ,IAAI;YACpN;YACA,SAAS,eAAe,GAAG,CAAC,CAAA,IAAK,CAAC;oBAChC,UAAU,kBAAkB,oBAAoB,kBAAkB,YAAY;oBAC9E,MAAM,EAAE,IAAI,CAAC,SAAS,CAAC,GAAG,OAAO;oBACjC,OAAO,EAAE,KAAK,CAAC,OAAO,CAAC;gBACzB,CAAC;QACH;IACF;AACF;AAKO,eAAe,cAAc,MAAM,EAAE,IAAI,EAAE,WAAW,CAAC,CAAC;IAC7D,QAAQ,GAAG,CAAC,CAAC,yBAAyB,EAAE,OAAO,eAAe,EAAE,KAAK,MAAM,EAAE;IAE7E,MAAM,SAAS,MAAM,iBAAiB;IAEtC,QAAQ,GAAG,CAAC,CAAC,QAAQ,EAAE,OAAO,MAAM,CAAC,qBAAqB,EAAE,QAAQ;IAEpE,MAAM,eAAe;QACnB;QACA;QACA,UAAU;YACR,GAAG,QAAQ;YACX,UAAU,SAAS,QAAQ,IAAI,SAAS,gBAAgB,IAAI;YAC5D,UAAU,IAAI,OAAO,WAAW;YAChC,YAAY,OAAO,MAAM;QAC3B;IACF;IAEA,cAAc,GAAG,CAAC,QAAQ;IAE1B,QAAQ,GAAG,CAAC,CAAC,SAAS,EAAE,OAAO,yBAAyB,EAAE,cAAc,IAAI,EAAE;IAC9E,QAAQ,GAAG,CAAC,CAAC,WAAW,CAAC,EAAE,MAAM,IAAI,CAAC,cAAc,IAAI;IAExD,OAAO;QACL;QACA,YAAY,OAAO,MAAM;QACzB,WAAW,KAAK,KAAK,CAAC,OAAO,MAAM;IACrC;AACF;AAKO,SAAS,YAAY,MAAM;IAChC,OAAO,cAAc,GAAG,CAAC;AAC3B;AAKO,SAAS,eAAe,MAAM;IACnC,OAAO,cAAc,MAAM,CAAC;AAC9B;AAKO,eAAe,mBAAmB,KAAK,EAAE,UAAU,IAAI;IAC5D,QAAQ,GAAG,CAAC,yCAAyC,OAAO,YAAY;IACxE,QAAQ,GAAG,CAAC,uBAAuB,cAAc,IAAI;IACrD,QAAQ,GAAG,CAAC,uBAAuB,MAAM,IAAI,CAAC,cAAc,IAAI;IAEhE,MAAM,YAAY,WAAW,QAAQ,MAAM,GAAG,IAC1C,QAAQ,GAAG,CAAC,CAAA;QACV,MAAM,OAAO,cAAc,GAAG,CAAC;QAC/B,QAAQ,GAAG,CAAC,CAAC,mBAAmB,EAAE,GAAG,CAAC,CAAC,EAAE,OAAO,UAAU;QAC1D,OAAO;YAAE;YAAI;QAAK;IACpB,GAAG,MAAM,CAAC,CAAA,IAAK,EAAE,IAAI,IACrB,MAAM,IAAI,CAAC,cAAc,OAAO,IAAI,GAAG,CAAC,CAAC,CAAC,IAAI,KAAK;QACjD,QAAQ,GAAG,CAAC,CAAC,SAAS,EAAE,GAAG,CAAC,CAAC,EAAE,OAAO,UAAU;QAChD,OAAO;YAAE;YAAI;QAAK;IACpB;IAEJ,QAAQ,GAAG,CAAC,CAAC,MAAM,EAAE,UAAU,MAAM,CAAC,oBAAoB,CAAC;IAE3D,IAAI,UAAU,MAAM,KAAK,GAAG;QAC1B,QAAQ,GAAG,CAAC;QACZ,OAAO,EAAE;IACX;IAEA,MAAM,aAAa,EAAE;IAErB,KAAK,MAAM,EAAE,EAAE,EAAE,IAAI,EAAE,IAAI,UAAW;QACpC,IAAI,CAAC,QAAQ,CAAC,KAAK,MAAM,IAAI,CAAC,KAAK,MAAM,CAAC,MAAM,EAAE;YAChD,QAAQ,GAAG,CAAC,CAAC,SAAS,EAAE,GAAG,wBAAwB,CAAC;YACpD;QACF;QAEA,QAAQ,GAAG,CAAC,CAAC,sBAAsB,EAAE,GAAG,EAAE,EAAE,KAAK,MAAM,CAAC,MAAM,CAAC,QAAQ,CAAC;QACxE,MAAM,UAAU,MAAM,eAAe,KAAK,IAAI,EAAE,KAAK,MAAM,EAAE,OAAO;QAEpE,IAAI,QAAQ,MAAM,GAAG,GAAG;YACtB,QAAQ,GAAG,CAAC,CAAC,MAAM,EAAE,QAAQ,MAAM,CAAC,6BAA6B,EAAE,IAAI;YACvE,WAAW,IAAI,CAAC;gBACd,QAAQ;gBACR,UAAU,KAAK,QAAQ,EAAE,oBAAoB,KAAK,QAAQ,EAAE,YAAY;gBACxE;gBACA,UAAU,OAAO,CAAC,EAAE,CAAC,KAAK;YAC5B;QACF,OAAO;YACL,QAAQ,GAAG,CAAC,CAAC,qCAAqC,EAAE,IAAI;QAC1D;IACF;IAEA,QAAQ,GAAG,CAAC,CAAC,sBAAsB,EAAE,WAAW,MAAM,EAAE;IAExD,4BAA4B;IAC5B,OAAO,WAAW,IAAI,CAAC,CAAC,GAAG,IAAM,EAAE,QAAQ,GAAG,EAAE,QAAQ;AAC1D;AAQO,eAAe,4BAA4B,KAAK,EAAE,aAAa,EAAE,sBAAsB,EAAE;IAC9F,IAAI,CAAC,iBAAiB,cAAc,MAAM,KAAK,GAAG;QAChD,OAAO;YACL,QAAQ;YACR,YAAY;YACZ,SAAS,EAAE;QACb;IACF;IAEA,+CAA+C;IAC/C,MAAM,YAAY,cACf,OAAO,CAAC,CAAA,aACP,WAAW,OAAO,CAAC,GAAG,CAAC,CAAA,IAAK,CAAC;gBAC3B,GAAG,CAAC;gBACJ,UAAU,WAAW,QAAQ;gBAC7B,QAAQ,WAAW,MAAM;YAC3B,CAAC,IAEF,IAAI,CAAC,CAAC,GAAG,IAAM,EAAE,KAAK,GAAG,EAAE,KAAK,EAChC,KAAK,CAAC,GAAG;IAEZ,IAAI,UAAU,MAAM,KAAK,GAAG;QAC1B,OAAO;YACL,QAAQ;YACR,YAAY;YACZ,SAAS,EAAE;QACb;IACF;IAEA,0CAA0C;IAC1C,MAAM,eAAe,SAAS,CAAC,EAAE;IACjC,MAAM,WAAW,YAAY,aAAa,MAAM;IAEhD,IAAI,cAAc,MAAM,KAAK,GAAG;QAC9B,mEAAmE;QACnE,OAAO,MAAM,eAAe,OAAO,WAAW,SAAS,IAAI,EAAE,qBAAqB,SAAS,QAAQ,IAAI,CAAC;IAC1G,OAAO;QACL,yDAAyD;QACzD,MAAM,aAAa,KAAK,GAAG,CAAC,aAAa,KAAK,GAAG,IAAI;QAErD,IAAI;YACF,6DAA6D;YAC7D,MAAM,kBAAkB,UACrB,GAAG,CAAC,CAAC,OAAO,MAAQ,CAAC,aAAa,EAAE,MAAM,QAAQ,CAAC,YAAY,EAAE,MAAM,EAAE,GAAG,EAAE,MAAM,IAAI,EAAE,EAC1F,IAAI,CAAC;YAER,uEAAuE;YACvE,IAAI,iBAAiB;YACrB,IAAI,uBAAuB,oBAAoB,IAAI,IAAI;gBACrD,iBAAiB,CAAC;AAC1B,EAAE,oBAAoB;;sGAEgF,CAAC;YACjG;YAEA,MAAM,WAAW;gBACf;oBACE,MAAM;oBACN,SAAS,CAAC;;;;;;;;;;;;;oCAagB,CAAC;gBAC7B;gBACA;oBACE,MAAM;oBACN,SAAS,CAAC,kCAAkC,EAAE,cAAc,MAAM,CAAC;;;AAG7E,EAAE,kBAAkB,eAAe;;;AAGnC,EAAE,MAAM;;;;;;;sFAO8E,CAAC;gBAC/E;aACD;YAED,IAAI,SAAS,MAAM,IAAA,wHAAc,EAAC,UAAU;gBAC1C,OAAO;gBACP,aAAa;gBACb,YAAY;gBACZ,OAAO;gBACP,mBAAmB;gBACnB,kBAAkB;YACpB;YACA,SAAS,OAAO,IAAI;YACpB,MAAM,SAAS,yBAAyB,IAAI,CAAC,WAAW,OAAO,MAAM,GAAG;YACxE,IAAI,QAAQ;gBACV,MAAM,aAAa,UAAU,KAAK,CAAC,GAAE,GAAG,GAAG,CAAC,CAAC,GAAE,IAAI,CAAC,EAAE,EAAE,EAAE,QAAQ,CAAC,QAAQ,EAAE,EAAE,KAAK,CAAC,OAAO,CAAC,GAAG,GAAG,EAAE,EAAE,IAAI,CAAC,SAAS,CAAC,GAAE,KAAK,OAAO,CAAC,QAAO,OAAO,EAAE,IAAI,CAAC,MAAM,GAAC,MAAI,QAAM,IAAI,EAAE,IAAI,CAAC;gBACtL,SAAS,CAAC;;YAEN,EAAE,WAAW;;qGAE4E,CAAC;YAChG;YACA,OAAO;gBACL;gBACA;gBACA,SAAS,UAAU,KAAK,CAAC,GAAG,GAAG,GAAG,CAAC,CAAA,IAAK,CAAC;wBACvC,UAAU,EAAE,QAAQ;wBACpB,MAAM,EAAE,IAAI,CAAC,SAAS,CAAC,GAAG,OAAO;wBACjC,OAAO,EAAE,KAAK,CAAC,OAAO,CAAC;oBACzB,CAAC;YACH;QACF,EAAE,OAAO,OAAO;YACd,QAAQ,KAAK,CAAC,uEAAuE;YACrF,WAAW;YACX,IAAI,SAAS,CAAC,cAAc,EAAE,cAAc,MAAM,CAAC,wBAAwB,CAAC;YAC5E,UAAU,CAAC,iBAAiB,EAAE,aAAa,QAAQ,CAAC,MAAM,EAAE,aAAa,IAAI,CAAC,IAAI,CAAC;YAEnF,IAAI,UAAU,MAAM,GAAG,GAAG;gBACxB,MAAM,YAAY,UAAU,KAAK,CAAC,GAAG,GAAG,MAAM,CAAC,CAAA,IAAK,EAAE,MAAM,KAAK,aAAa,MAAM;gBACpF,IAAI,UAAU,MAAM,GAAG,GAAG;oBACxB,UAAU,CAAC,gDAAgD,CAAC;oBAC5D,UAAU,OAAO,CAAC,CAAC,OAAO;wBACxB,UAAU,CAAC,GAAG,EAAE,MAAM,EAAE,MAAM,EAAE,MAAM,QAAQ,CAAC,IAAI,EAAE,MAAM,IAAI,CAAC,SAAS,CAAC,GAAG,KAAK,KAAK,CAAC;oBAC1F;gBACF;YACF;YAEA,MAAM,aAAa,KAAK,GAAG,CAAC,aAAa,KAAK,GAAG,IAAI;YAErD,OAAO;gBACL,QAAQ,OAAO,IAAI;gBACnB;gBACA,SAAS,UAAU,KAAK,CAAC,GAAG,GAAG,GAAG,CAAC,CAAA,IAAK,CAAC;wBACvC,UAAU,EAAE,QAAQ;wBACpB,MAAM,EAAE,IAAI,CAAC,SAAS,CAAC,GAAG,OAAO;wBACjC,OAAO,EAAE,KAAK,CAAC,OAAO,CAAC;oBACzB,CAAC;YACH;QACF;IACF;AACF;AAKO,SAAS;IACd,OAAO,MAAM,IAAI,CAAC,cAAc,OAAO,IAAI,GAAG,CAAC,CAAC,CAAC,QAAQ,IAAI,GAAK,CAAC;YACjE;YACA,GAAG,GAAG;QACR,CAAC;AACH;AAKO,SAAS;IACd,MAAM,YAAY,MAAM,IAAI,CAAC,cAAc,MAAM;IAEjD,OAAO;QACL,gBAAgB,cAAc,IAAI;QAClC,YAAY,UAAU,MAAM,CAAC,CAAC,KAAK,MAAQ,MAAM,CAAC,IAAI,IAAI,CAAC,KAAK,CAAC,OAAO,MAAM,IAAI,CAAC,GAAG;QACtF,aAAa,UAAU,MAAM,CAAC,CAAC,KAAK,MAAQ,MAAM,CAAC,IAAI,MAAM,EAAE,UAAU,CAAC,GAAG;QAC7E,WAAW,MAAM,IAAI,CAAC,cAAc,OAAO,IAAI,GAAG,CAAC,CAAC,CAAC,QAAQ,IAAI,GAAK,CAAC;gBACrE;gBACA,OAAO,MAAM,IAAI,CAAC,cAAc,IAAI,IAAI,OAAO,CAAC;gBAChD,UAAU,IAAI,QAAQ,EAAE,YAAY,IAAI,QAAQ,EAAE,oBAAoB;gBACtE,WAAW,IAAI,IAAI,CAAC,KAAK,CAAC,OAAO,MAAM;gBACvC,YAAY,IAAI,MAAM,EAAE,UAAU;gBAClC,UAAU,IAAI,QAAQ,EAAE;YAC1B,CAAC;IACH;AACF"}},
    {"offset": {"line": 1197, "column": 0}, "map": {"version":3,"sources":["file:///C:/Users/jurit/OneDrive/Desktop/sito%20upscale/pages/api/chat/upload-document.js"],"sourcesContent":["// API per caricare e analizzare documenti\r\nimport formidable from 'formidable';\r\nimport fs from 'fs';\r\nimport path from 'path';\r\nimport { extractTextFromDocument, storeDocument } from '../../../lib/documentAI.js';\r\nimport { v4 as uuidv4 } from 'uuid';\r\n\r\nexport const config = {\r\n  api: {\r\n    bodyParser: false,\r\n  },\r\n};\r\n\r\nexport default async function handler(req, res) {\r\n  if (req.method !== 'POST') {\r\n    return res.status(405).json({ error: 'Method not allowed' });\r\n  }\r\n\r\n  try {\r\n    const isVercel = Boolean(process.env.VERCEL);\r\n    const MAX_FILE_MB = isVercel ? Number(process.env.VERCEL_MAX_MB || 25) : 200;\r\n    const MAX_FILES = isVercel ? Number(process.env.VERCEL_MAX_FILES || 5) : 10;\r\n\r\n    const uploadDir = path.join(process.cwd(), 'uploads', 'chat');\r\n    if (!fs.existsSync(uploadDir)) {\r\n      fs.mkdirSync(uploadDir, { recursive: true });\r\n    }\r\n\r\n    const form = formidable({\r\n      uploadDir,\r\n      keepExtensions: true,\r\n      // Imposta limite massimo per file in base all'ambiente\r\n      maxFileSize: MAX_FILE_MB * 1024 * 1024,\r\n      multiples: true,\r\n    });\r\n\r\n    const [fields, files] = await new Promise((resolve, reject) => {\r\n      form.parse(req, (err, fields, files) => {\r\n        if (err) reject(err);\r\n        else resolve([fields, files]);\r\n      });\r\n    });\r\n\r\n    const fileArray = Array.isArray(files.files) ? files.files : [files.files].filter(Boolean);\r\n    \r\n    if (!fileArray || fileArray.length === 0) {\r\n      return res.status(400).json({ error: 'Nessun file caricato' });\r\n    }\r\n\r\n    if (fileArray.length > MAX_FILES) {\r\n      return res.status(400).json({\r\n        error: `Numero massimo di file per analisi superato: ${fileArray.length} > ${MAX_FILES}`,\r\n        details: isVercel\r\n          ? `Limite Vercel: ${MAX_FILES} file per richiesta (riduci o usa caricamento diretto su storage).`\r\n          : `Carica al massimo ${MAX_FILES} file per volta.`,\r\n        limit: MAX_FILES,\r\n      });\r\n    }\r\n\r\n    // Verifica dimensione file (utile per errori di payload su Vercel)\r\n    for (const f of fileArray) {\r\n      const size = f.size || (f.filepath && fs.existsSync(f.filepath) ? fs.statSync(f.filepath).size : 0);\r\n      if (size > MAX_FILE_MB * 1024 * 1024) {\r\n        return res.status(413).json({\r\n          error: `File troppo grande: ${(size / (1024 * 1024)).toFixed(1)}MB > ${MAX_FILE_MB}MB`,\r\n          details: isVercel\r\n            ? `Le funzioni serverless Vercel hanno un limite di payload. Usa file più piccoli, carica direttamente su storage (Vercel Blob/S3) o esegui in ambiente non serverless.`\r\n            : `Riduci la dimensione del file o carica meno contenuti.`,\r\n          limitMB: MAX_FILE_MB,\r\n        });\r\n      }\r\n    }\r\n\r\n    // Processa i file in parallelo per velocità (max 3 alla volta)\r\n    const processFile = async (file) => {\r\n      try {\r\n        // Leggi il file come buffer\r\n        const buffer = fs.readFileSync(file.filepath);\r\n        const filename = file.originalFilename || file.newFilename;\r\n        const mimeType = file.mimetype || 'application/octet-stream';\r\n\r\n        // Estrai testo dal documento usando pdfjs-dist, mammoth, xlsx, ecc.\r\n        console.log(`Processing file: ${filename} (${mimeType})`);\r\n        let text, metadata;\r\n        try {\r\n          const result = await extractTextFromDocument(buffer, mimeType, filename, file.filepath);\r\n          text = result.text;\r\n          metadata = result.metadata || {};\r\n          console.log(`Extracted text length: ${text ? text.length : 0} characters`);\r\n        } catch (extractError) {\r\n          console.error(`Error extracting text from ${filename}:`, extractError);\r\n          return {\r\n            filename,\r\n            success: false,\r\n            error: `Errore estrazione testo: ${extractError.message}`,\r\n          };\r\n        }\r\n\r\n        if (!text || text.trim().length === 0) {\r\n          console.warn(`No text extracted from ${filename}`);\r\n          return {\r\n            filename,\r\n            success: false,\r\n            error: 'Nessun testo estratto dal documento',\r\n          };\r\n        }\r\n\r\n        // Genera ID unico per il file\r\n        const fileId = uuidv4();\r\n\r\n        console.log(`Storing document ${fileId} with filename ${filename}`);\r\n        console.log(`Text length: ${text.length} characters`);\r\n\r\n        // Salva nello store in-memory con embeddings (async)\r\n        const storeResult = await storeDocument(fileId, text, {\r\n          ...metadata,\r\n          originalFilename: filename,\r\n          filename,\r\n          mimeType,\r\n          uploadedAt: new Date().toISOString(),\r\n          size: buffer.length,\r\n        });\r\n\r\n        console.log(`Document ${fileId} stored in memory with ${storeResult.chunkCount} chunks and embeddings`);\r\n\r\n        // Pulisci il file temporaneo\r\n        try {\r\n          fs.unlinkSync(file.filepath);\r\n        } catch (unlinkError) {\r\n          console.warn('Errore eliminazione file temporaneo:', unlinkError);\r\n        }\r\n\r\n        return {\r\n          fileId,\r\n          filename,\r\n          success: true,\r\n          wordCount: storeResult.wordCount,\r\n          chunkCount: storeResult.chunkCount,\r\n          pages: metadata.pages || 0,\r\n          size: buffer.length,\r\n        };\r\n      } catch (fileError) {\r\n        console.error('Errore processamento file:', fileError);\r\n        return {\r\n          filename: file.originalFilename || file.newFilename,\r\n          success: false,\r\n          error: fileError.message || 'Errore durante il processamento',\r\n        };\r\n      }\r\n    };\r\n\r\n    // Processa tutti i file (riduci concorrenza su Vercel per evitare timeout)\r\n    const BATCH_SIZE = isVercel ? 1 : 3;\r\n    const results = [];\r\n    \r\n    for (let i = 0; i < fileArray.length; i += BATCH_SIZE) {\r\n      const batch = fileArray.slice(i, i + BATCH_SIZE);\r\n      const batchResults = await Promise.all(batch.map(processFile));\r\n      results.push(...batchResults);\r\n    }\r\n\r\n    const successCount = results.filter(r => r.success).length;\r\n\r\n    console.log(`Upload completed: ${successCount} successful out of ${results.length} total files`);\r\n    console.log('Results:', JSON.stringify(results, null, 2));\r\n\r\n    return res.status(200).json({\r\n      success: successCount > 0,\r\n      files: results,\r\n      message: `${successCount} file analizzati con successo`,\r\n    });\r\n  } catch (error) {\r\n    console.error('Upload error:', error);\r\n    return res.status(500).json({\r\n      error: 'Errore durante il caricamento',\r\n      details: error.message,\r\n    });\r\n  }\r\n}\r\n\r\n"],"names":[],"mappings":"AAAA,0CAA0C;;;;;;;AAC1C;AACA;AACA;AACA;AACA;;;;;;;;;;;;AAEO,MAAM,SAAS;IACpB,KAAK;QACH,YAAY;IACd;AACF;AAEe,eAAe,QAAQ,GAAG,EAAE,GAAG;IAC5C,IAAI,IAAI,MAAM,KAAK,QAAQ;QACzB,OAAO,IAAI,MAAM,CAAC,KAAK,IAAI,CAAC;YAAE,OAAO;QAAqB;IAC5D;IAEA,IAAI;QACF,MAAM,WAAW,QAAQ,QAAQ,GAAG,CAAC,MAAM;QAC3C,MAAM,cAAc,WAAW,OAAO,QAAQ,GAAG,CAAC,aAAa,IAAI,MAAM;QACzE,MAAM,YAAY,WAAW,OAAO,QAAQ,GAAG,CAAC,gBAAgB,IAAI,KAAK;QAEzE,MAAM,YAAY,4GAAI,CAAC,IAAI,CAAC,QAAQ,GAAG,IAAI,WAAW;QACtD,IAAI,CAAC,wGAAE,CAAC,UAAU,CAAC,YAAY;YAC7B,wGAAE,CAAC,SAAS,CAAC,WAAW;gBAAE,WAAW;YAAK;QAC5C;QAEA,MAAM,OAAO,IAAA,+HAAU,EAAC;YACtB;YACA,gBAAgB;YAChB,uDAAuD;YACvD,aAAa,cAAc,OAAO;YAClC,WAAW;QACb;QAEA,MAAM,CAAC,QAAQ,MAAM,GAAG,MAAM,IAAI,QAAQ,CAAC,SAAS;YAClD,KAAK,KAAK,CAAC,KAAK,CAAC,KAAK,QAAQ;gBAC5B,IAAI,KAAK,OAAO;qBACX,QAAQ;oBAAC;oBAAQ;iBAAM;YAC9B;QACF;QAEA,MAAM,YAAY,MAAM,OAAO,CAAC,MAAM,KAAK,IAAI,MAAM,KAAK,GAAG;YAAC,MAAM,KAAK;SAAC,CAAC,MAAM,CAAC;QAElF,IAAI,CAAC,aAAa,UAAU,MAAM,KAAK,GAAG;YACxC,OAAO,IAAI,MAAM,CAAC,KAAK,IAAI,CAAC;gBAAE,OAAO;YAAuB;QAC9D;QAEA,IAAI,UAAU,MAAM,GAAG,WAAW;YAChC,OAAO,IAAI,MAAM,CAAC,KAAK,IAAI,CAAC;gBAC1B,OAAO,CAAC,6CAA6C,EAAE,UAAU,MAAM,CAAC,GAAG,EAAE,WAAW;gBACxF,SAAS,WACL,CAAC,eAAe,EAAE,UAAU,kEAAkE,CAAC,GAC/F,CAAC,kBAAkB,EAAE,UAAU,gBAAgB,CAAC;gBACpD,OAAO;YACT;QACF;QAEA,mEAAmE;QACnE,KAAK,MAAM,KAAK,UAAW;YACzB,MAAM,OAAO,EAAE,IAAI,IAAI,CAAC,EAAE,QAAQ,IAAI,wGAAE,CAAC,UAAU,CAAC,EAAE,QAAQ,IAAI,wGAAE,CAAC,QAAQ,CAAC,EAAE,QAAQ,EAAE,IAAI,GAAG,CAAC;YAClG,IAAI,OAAO,cAAc,OAAO,MAAM;gBACpC,OAAO,IAAI,MAAM,CAAC,KAAK,IAAI,CAAC;oBAC1B,OAAO,CAAC,oBAAoB,EAAE,CAAC,OAAO,CAAC,OAAO,IAAI,CAAC,EAAE,OAAO,CAAC,GAAG,KAAK,EAAE,YAAY,EAAE,CAAC;oBACtF,SAAS,WACL,CAAC,oKAAoK,CAAC,GACtK,CAAC,sDAAsD,CAAC;oBAC5D,SAAS;gBACX;YACF;QACF;QAEA,+DAA+D;QAC/D,MAAM,cAAc,OAAO;YACzB,IAAI;gBACF,4BAA4B;gBAC5B,MAAM,SAAS,wGAAE,CAAC,YAAY,CAAC,KAAK,QAAQ;gBAC5C,MAAM,WAAW,KAAK,gBAAgB,IAAI,KAAK,WAAW;gBAC1D,MAAM,WAAW,KAAK,QAAQ,IAAI;gBAElC,oEAAoE;gBACpE,QAAQ,GAAG,CAAC,CAAC,iBAAiB,EAAE,SAAS,EAAE,EAAE,SAAS,CAAC,CAAC;gBACxD,IAAI,MAAM;gBACV,IAAI;oBACF,MAAM,SAAS,MAAM,IAAA,qIAAuB,EAAC,QAAQ,UAAU,UAAU,KAAK,QAAQ;oBACtF,OAAO,OAAO,IAAI;oBAClB,WAAW,OAAO,QAAQ,IAAI,CAAC;oBAC/B,QAAQ,GAAG,CAAC,CAAC,uBAAuB,EAAE,OAAO,KAAK,MAAM,GAAG,EAAE,WAAW,CAAC;gBAC3E,EAAE,OAAO,cAAc;oBACrB,QAAQ,KAAK,CAAC,CAAC,2BAA2B,EAAE,SAAS,CAAC,CAAC,EAAE;oBACzD,OAAO;wBACL;wBACA,SAAS;wBACT,OAAO,CAAC,yBAAyB,EAAE,aAAa,OAAO,EAAE;oBAC3D;gBACF;gBAEA,IAAI,CAAC,QAAQ,KAAK,IAAI,GAAG,MAAM,KAAK,GAAG;oBACrC,QAAQ,IAAI,CAAC,CAAC,uBAAuB,EAAE,UAAU;oBACjD,OAAO;wBACL;wBACA,SAAS;wBACT,OAAO;oBACT;gBACF;gBAEA,8BAA8B;gBAC9B,MAAM,SAAS,IAAA,8GAAM;gBAErB,QAAQ,GAAG,CAAC,CAAC,iBAAiB,EAAE,OAAO,eAAe,EAAE,UAAU;gBAClE,QAAQ,GAAG,CAAC,CAAC,aAAa,EAAE,KAAK,MAAM,CAAC,WAAW,CAAC;gBAEpD,qDAAqD;gBACrD,MAAM,cAAc,MAAM,IAAA,2HAAa,EAAC,QAAQ,MAAM;oBACpD,GAAG,QAAQ;oBACX,kBAAkB;oBAClB;oBACA;oBACA,YAAY,IAAI,OAAO,WAAW;oBAClC,MAAM,OAAO,MAAM;gBACrB;gBAEA,QAAQ,GAAG,CAAC,CAAC,SAAS,EAAE,OAAO,uBAAuB,EAAE,YAAY,UAAU,CAAC,sBAAsB,CAAC;gBAEtG,6BAA6B;gBAC7B,IAAI;oBACF,wGAAE,CAAC,UAAU,CAAC,KAAK,QAAQ;gBAC7B,EAAE,OAAO,aAAa;oBACpB,QAAQ,IAAI,CAAC,wCAAwC;gBACvD;gBAEA,OAAO;oBACL;oBACA;oBACA,SAAS;oBACT,WAAW,YAAY,SAAS;oBAChC,YAAY,YAAY,UAAU;oBAClC,OAAO,SAAS,KAAK,IAAI;oBACzB,MAAM,OAAO,MAAM;gBACrB;YACF,EAAE,OAAO,WAAW;gBAClB,QAAQ,KAAK,CAAC,8BAA8B;gBAC5C,OAAO;oBACL,UAAU,KAAK,gBAAgB,IAAI,KAAK,WAAW;oBACnD,SAAS;oBACT,OAAO,UAAU,OAAO,IAAI;gBAC9B;YACF;QACF;QAEA,2EAA2E;QAC3E,MAAM,aAAa,WAAW,IAAI;QAClC,MAAM,UAAU,EAAE;QAElB,IAAK,IAAI,IAAI,GAAG,IAAI,UAAU,MAAM,EAAE,KAAK,WAAY;YACrD,MAAM,QAAQ,UAAU,KAAK,CAAC,GAAG,IAAI;YACrC,MAAM,eAAe,MAAM,QAAQ,GAAG,CAAC,MAAM,GAAG,CAAC;YACjD,QAAQ,IAAI,IAAI;QAClB;QAEA,MAAM,eAAe,QAAQ,MAAM,CAAC,CAAA,IAAK,EAAE,OAAO,EAAE,MAAM;QAE1D,QAAQ,GAAG,CAAC,CAAC,kBAAkB,EAAE,aAAa,mBAAmB,EAAE,QAAQ,MAAM,CAAC,YAAY,CAAC;QAC/F,QAAQ,GAAG,CAAC,YAAY,KAAK,SAAS,CAAC,SAAS,MAAM;QAEtD,OAAO,IAAI,MAAM,CAAC,KAAK,IAAI,CAAC;YAC1B,SAAS,eAAe;YACxB,OAAO;YACP,SAAS,GAAG,aAAa,6BAA6B,CAAC;QACzD;IACF,EAAE,OAAO,OAAO;QACd,QAAQ,KAAK,CAAC,iBAAiB;QAC/B,OAAO,IAAI,MAAM,CAAC,KAAK,IAAI,CAAC;YAC1B,OAAO;YACP,SAAS,MAAM,OAAO;QACxB;IACF;AACF"}}]
}